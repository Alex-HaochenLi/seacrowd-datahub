{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fb7df-e22f-4512-be01-50f8788d2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from nusacrowd import NusantaraMetadata, NusantaraConfigHelper, NusantaraMetadataHelper\n",
    "from nusacrowd.utils.constants import Tasks, TASK_TO_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5ceeab-64f3-4afb-8539-de28ae08dc20",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset smsa (/home/samuel/.cache/huggingface/datasets/smsa/smsa_nusantara_text/1.0.0/75dac0cd43d6209d8adf37537e99e00ba3791bcc74250d08523137e992f351cb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve SMSA\n",
      "[NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='smsa_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='SMSA Nusantara schema', schema='nusantara_text', subset_id='smsa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cb1fffa2264aa8a4ec3d0e5ba55da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 11000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})]\n",
      "Source datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/barasa/barasa.py', dataset_name='barasa', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='barasa_source', version=1.0.0, data_dir=None, data_files=None, description='Barasa source schema', schema='source', subset_id='barasa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version=None, source_version='1.0.0', citation='@inproceedings{baccianella-etal-2010-sentiwordnet,\\n    title = \"{S}enti{W}ord{N}et 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining\",\\n    author = \"Baccianella, Stefano  and\\n      Esuli, Andrea  and\\n      Sebastiani, Fabrizio\",\\n    booktitle = \"Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}\\'10)\",\\n    month = may,\\n    year = \"2010\",\\n    address = \"Valletta, Malta\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2010/pdf/769_Paper.pdf\",\\n    abstract = \"In this work we present SENTIWORDNET 3.0, a lexical resource explicitly devised for supporting sentiment classification and opinion mining applications. SENTIWORDNET 3.0 is an improved version of SENTIWORDNET 1.0, a lexical resource publicly available for research purposes, now currently licensed to more than 300 research groups and used in a variety of research projects worldwide. Both SENTIWORDNET 1.0 and 3.0 are the result of automatically annotating all WORDNET synsets according to their degrees of positivity, negativity, and neutrality. SENTIWORDNET 1.0 and 3.0 differ (a) in the versions of WORDNET which they annotate (WORDNET 2.0 and 3.0, respectively), (b) in the algorithm used for automatically annotating WORDNET, which now includes (additionally to the previous semi-supervised learning step) a random-walk step for refining the scores. We here discuss SENTIWORDNET 3.0, especially focussing on the improvements concerning aspect (b) that it embodies with respect to version 1.0. We also report the results of evaluating SENTIWORDNET 3.0 against a fragment of WORDNET 3.0 manually annotated for positivity, negativity, and neutrality; these results indicate accuracy improvements of about 20{\\\\%} with respect to SENTIWORDNET 1.0.\",\\n}\\n\\n@misc{moeljadi_2016,\\n    title={Neocl/Barasa: Indonesian SentiWordNet},\\n    url={https://github.com/neocl/barasa},\\n    journal={GitHub},\\n    author={Moeljadi, David},\\n    year={2016}, month={Mar}\\n}\\n', description='The Barasa dataset is an Indonesian SentiWordNet for sentiment analysis.\\nFor each term, the pair (POS,ID) uniquely identifies a WordNet (3.0) synset and there are PosScore and NegScore to show the positivity and negativity of the term.\\nThe objectivity score can be calculated as: ObjScore = 1 - (PosScore + NegScore).\\n', homepage='https://github.com/neocl/barasa', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id source schema', schema='source', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset for Javanese and Indonesian translation generated from the verse-aligned Bible parallel corpus with the same split setting. In terms of size, both the Su ↔ Id and Jv ↔ Id datasets are much smaller compared to the En ↔ Id dataset, because there are Bible chapters for which translations are available for Indonesian, albeit not for the local languages.', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id source schema', schema='source', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/casa/casa.py', dataset_name='casa', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='casa_source', version=1.0.0, data_dir=None, data_files=None, description='CASA source schema', schema='source', subset_id='casa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@INPROCEEDINGS{8629181,\\n    author={Ilmania, Arfinda and Abdurrahman and Cahyawijaya, Samuel and Purwarianti, Ayu},\\n    booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n    title={Aspect Detection and Sentiment Classification Using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis},\\n    year={2018},\\n    volume={},\\n    number={},\\n    pages={62-67},\\n    doi={10.1109/IALP.2018.8629181\\n}\\n', description='\\nCASA: An aspect-based sentiment analysis dataset consisting of around a thousand car reviews collected from multiple Indonesian online automobile platforms (Ilmania et al., 2018).\\nThe dataset covers six aspects of car quality.\\nWe define the task to be a multi-label classification task,\\nwhere each label represents a sentiment for a single aspect with three possible values: positive, negative, and neutral.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for ind language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for jav language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for sun language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cod/cod.py', dataset_name='cod', tasks=[<Tasks.DIALOGUE_SYSTEM: 'DS'>], languages=['ind'], config=NusantaraConfig(name='cod_source', version=1.0.0, data_dir=None, data_files=None, description='Cross-lingual Outline-based Dialogue (COD) source schema', schema='source', subset_id='cod'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@article{majewska2022cross,\\n  title={Cross-lingual dialogue dataset creation via outline-based generation},\\n  author={Majewska, Olga and Razumovskaia, Evgeniia and Ponti, Edoardo Maria and Vuli{'c}, Ivan and Korhonen, Anna},\\n  journal={arXiv preprint arXiv:2201.13405},\\n  year={2022}\\n}\\n\", description='Cross-lingual Outline-based Dialogue (COD) is a dataset comprised of manually generated, localized, and cross-lingually aligned Task-Oriented-Dialogue (TOD) data that served as the source of dialogue prompts.\\nCOD enables natural language understanding, dialogue state tracking, and end-to-end dialogue modeling and evaluation.\\nMajewska et al. (2022) create COD using a novel outline-based annotation pipeline for multilingual TOD by Majewska et al. (2022).\\nEnglish Schema-Guided Dialogue (SGD; Shah et al., 2018; Rastogi et al., 2020) dataset is automatically sampled and mapped into outlines. The outlines are then paraphrased and adapted to the local target domain by human subjects.\\n', homepage='https://github.com/cambridgeltl/COD', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/code_mixed_jv_id/code_mixed_jv_id.py', dataset_name='code_mixed_jv_id', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>, <Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['jav', 'ind'], config=NusantaraConfig(name='code_mixed_jv_id_source', version=1.0.0, data_dir=None, data_files=None, description='code_mixed_jv_id source schema for Javanese and Indonesian', schema='source', subset_id='code_mixed_source'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{Tho_2021,\\n  doi = {10.1088/1742-6596/1869/1/012084},\\n  url = {https://doi.org/10.1088/1742-6596/1869/1/012084},\\n  year = 2021,\\n  month = {apr},\\n  publisher = {{IOP} Publishing},\\n  volume = {1869},\\n  number = {1},\\n  pages = {012084},\\n  author = {C Tho and Y Heryadi and L Lukas and A Wibowo},\\n  title = {Code-mixed sentiment analysis of Indonesian language and Javanese language using Lexicon based approach},\\n  journal = {Journal of Physics: Conference Series},\\n  abstract = {Nowadays mixing one language with another language either in\\n  spoken or written communication has become a common practice for bilingual\\n  speakers in daily conversation as well as in social media. Lexicon based\\n  approach is one of the approaches in extracting the sentiment analysis. This\\n  study is aimed to compare two lexicon models which are SentiNetWord and VADER\\n  in extracting the polarity of the code-mixed sentences in Indonesian language\\n  and Javanese language. 3,963 tweets were gathered from two accounts that\\n  provide code-mixed tweets. Pre-processing such as removing duplicates,\\n  translating to English, filter special characters, transform lower case and\\n  filter stop words were conducted on the tweets. Positive and negative word\\n  score from lexicon model was then calculated using simple mathematic formula\\n  in order to classify the polarity. By comparing with the manual labelling,\\n  the result showed that SentiNetWord perform better than VADER in negative\\n  sentiments. However, both of the lexicon model did not perform well in\\n  neutral and positive sentiments. On overall performance, VADER showed better\\n  performance than SentiNetWord. This study showed that the reason for the\\n  misclassified was that most of Indonesian language and Javanese language\\n  consist of words that were considered as positive in both Lexicon model.}\\n}\\n', description='Sentiment analysis and machine translation data for Javanese and Indonesian.\\n', homepage='https://iopscience.iop.org/article/10.1088/1742-6596/1869/1/012084', license='cc_by_3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks=[<Tasks.SPEECH_TO_TEXT_TRANSLATION: 'STTT'>, <Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_ind_eng_source', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for source from ind to eng', schema='source', subset_id='co_vo_st2_ind_eng'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks=[<Tasks.SPEECH_TO_TEXT_TRANSLATION: 'STTT'>, <Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_eng_ind_source', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for source from eng to ind', schema='source', subset_id='co_vo_st2_eng_ind'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cvss/cvss.py', dataset_name='cvss', tasks=[<Tasks.SPEECH_TO_SPEECH_TRANSLATION: 'S2ST'>], languages=['ind', 'eng'], config=NusantaraConfig(name='cvss_c_source', version=1.0.0, data_dir=None, data_files=None, description=\"CVSS source schema, all translation speeches are in a single canonical speaker's voice\", schema='source', subset_id='cvss_c'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{jia2022cvss,\\n    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},\\n    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},\\n    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},\\n    pages={6691--6703},\\n    year={2022}\\n}\\n', description='CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\\ncovering sentence-level parallel speech-to-speech translation pairs from 21\\nlanguages into English.\\n', homepage='https://github.com/google-research-datasets/cvss', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cvss/cvss.py', dataset_name='cvss', tasks=[<Tasks.SPEECH_TO_SPEECH_TRANSLATION: 'S2ST'>], languages=['ind', 'eng'], config=NusantaraConfig(name='cvss_t_source', version=1.0.0, data_dir=None, data_files=None, description='CVSS source schema, translation speeches are in voices transferred from the corresponding source speeches', schema='source', subset_id='cvss_t'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{jia2022cvss,\\n    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},\\n    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},\\n    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},\\n    pages={6691--6703},\\n    year={2022}\\n}\\n', description='CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\\ncovering sentence-level parallel speech-to-speech translation pairs from 21\\nlanguages into English.\\n', homepage='https://github.com/google-research-datasets/cvss', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emot/emot.py', dataset_name='emot', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emot_source', version=1.0.0, data_dir=None, data_files=None, description='EmoT source schema', schema='source', subset_id='emot'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emotcmt_source', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT source schema', schema='source', subset_id='emotcmt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emotion_id_opinion/emotion_id_opinion.py', dataset_name='emotion_id_opinion', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emotion_id_opinion_source', version=1.0.0, data_dir=None, data_files=None, description='EmoIdOpinion source schema', schema='source', subset_id='emotion_id_opinion'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@article{RICCOSAN2022108465,\\ntitle = {Emotion dataset from Indonesian public opinion},\\njournal = {Data in Brief},\\nvolume = {43},\\npages = {108465},\\nyear = {2022},\\nissn = {2352-3409},\\ndoi = {https://doi.org/10.1016/j.dib.2022.108465},\\nurl = {https://www.sciencedirect.com/science/article/pii/S2352340922006588},\\nauthor = { Riccosan and Karen Etania Saputra and Galih Dea Pratama and Andry Chowanda},\\nkeywords = {Emotion classification, Dataset, Tweet, Indonesia},\\nabstract = {An opinion is a type of judgment or a person's point of view about something. Twitter is a popular social media platform that includes a lot of public opinions and would be a suitable location to mine data in text form. With its vast population and active Twitter user base, Indonesia has the potential to be a source of opinion data mining. An opinion may be processed and result in the form of a person's emotional response towards something, such as whether they like, hate, love, or are happy about it. Upon that basis, a dataset of Indonesian-language tweets conveying public opinion on various topics was formed. The fact that there are only limited publicly available emotions text datasets in the Indonesian language supports our basis in this research to form our emotion dataset. The gathered data was cleaned and normalized in the pre-processing stage to the necessary form for study on the task of classifying emotions in Indonesian. The data collected is annotated with six emotional labels: anger, fear, joy, love, sad, and neutral.}\\n}\\n\", description=\"Emotion ID Opinion is a dataset of Indonesian-language tweets conveying public opinion on a variety of topics.\\nIt comtains 7080 indunesian tweets and a person's emotion response towards each tweet.\\nThe data is annotated with six emotional labels, namely anger, fear, joy, love, sad, and neutral.\\n\", homepage='https://github.com/Ricco48/Emotion-Dataset-from-Indonesian-Public-Opinion', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/facqa/facqa.py', dataset_name='facqa', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='facqa_source', version=1.0.0, data_dir=None, data_files=None, description='FacQA source schema', schema='source', subset_id='facqa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@inproceedings{purwarianti2007machine,\\n  title={A Machine Learning Approach for Indonesian Question Answering System},\\n  author={Ayu Purwarianti, Masatoshi Tsuchiya, and Seiichi Nakagawa},\\n  booktitle={Proceedings of Artificial Intelligence and Applications },\\n  pages={573--578},\\n  year={2007}\\n}\\n', description='\\nFacQA: The goal of the FacQA dataset is to find the answer to a question from a provided short passage from a news article.\\nEach row in the FacQA dataset consists of a question, a short passage, and a label phrase, which can be found inside the\\ncorresponding short passage. There are six categories of questions: date, location, name,\\norganization, person, and quantitative.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/hoasa/hoasa.py', dataset_name='hoasa', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='hoasa_source', version=1.0.0, data_dir=None, data_files=None, description='HoASA source schema', schema='source', subset_id='hoasa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@inproceedings{azhar2019multi,\\n  title={Multi-label Aspect Categorization with Convolutional Neural Networks and Extreme Gradient Boosting},\\n  author={A. N. Azhar, M. L. Khodra, and A. P. Sutiono}\\n  booktitle={Proceedings of the 2019 International Conference on Electrical Engineering and Informatics (ICEEI)},\\n  pages={35--40},\\n  year={2019}\\n}\\n', description='\\nHoASA: An aspect-based sentiment analysis dataset consisting of hotel reviews collected from the hotel aggregator platform, AiryRooms.\\nThe dataset covers ten different aspects of hotel quality. Similar to the CASA dataset, each review is labeled with a single sentiment label for each aspect.\\nThere are four possible sentiment classes for each sentiment label:\\npositive, negative, neutral, and positive-negative.\\nThe positivenegative label is given to a review that contains multiple sentiments of the same aspect but for different objects (e.g., cleanliness of bed and toilet).\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_abusive_source', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive source schema', schema='source', subset_id='id_abusive'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_abusive_news_comment/id_abusive_news_comment.py', dataset_name='id_abusive_news_comment', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_abusive_news_comment_source', version=1.0.0, data_dir=None, data_files=None, description='Abusive Online News Comment source schema', schema='source', subset_id='id_abusive_news_comment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{9034620,  author={Kiasati Desrul, Dhamir Raniah and Romadhony, Ade},  booktitle={2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)},   title={Abusive Language Detection on Indonesian Online News Comments},   year={2019},  volume={},  number={},  pages={320-325},  doi={10.1109/ISRITI48646.2019.9034620}}\\n', description=\"Abusive language is an expression used by a person with insulting delivery of any person's aspect.\\nIn the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse.\\nAn abusive language detection system is important to prevent the negative effect of such comments.\\nThis dataset contains 3184 samples of Indonesian online news comments with 3 labels.\\n\", homepage='https://github.com/dhamirdesrul/Indonesian-Online-News-Comments', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_clickbait_source', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID source schema', schema='source', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_frog_story/id_frog_story.py', dataset_name='id_frog_story', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='id_frog_story_source', version=1.0.0, data_dir=None, data_files=None, description='IdFrogStory source schema', schema='source', subset_id='id_frog_story'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{FrogStorytelling,\\n  author=\"Moeljadi, David\",\\n  title=\"Usage of Indonesian Possessive Verbal Predicates : A Statistical Analysis Based on Storytelling Survey\",\\n  journal=\"Tokyo University Linguistic Papers\",\\n  ISSN=\"1345-8663\",\\n  publisher=\"東京大学大学院人文社会系研究科・文学部言語学研究室\",\\n  year=\"2014\",\\n  month=\"sep\",\\n  volume=\"35\",\\n  number=\"\",\\n  pages=\"155-176\",\\n  URL=\"https://ci.nii.ac.jp/naid/120005525793/en/\",\\n  DOI=\"info:doi/10.15083/00027472\",\\n}\\n', description='Indonesian Frog Storytelling Corpus\\nIndonesian written and spoken corpus, based on the twenty-eight pictures. (http://compling.hss.ntu.edu.sg/who/david/corpus/pictures.pdf)\\n', homepage='https://github.com/matbahasa/corpus-frog-storytelling', license='Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_google_play_review/id_google_play_review.py', dataset_name='id_google_play_review', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_google_play_review_source', version=1.0.0, data_dir=None, data_files=None, description='id_google_play_review source schema', schema='source', subset_id='id_google_play_review'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={Jakartaresearch/google-play-review · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/jakartaresearch/google-play-review},\\n   author={Research, Jakarta AI}\\n} \\n', description='Indonesian Google Play Review, dataset scrapped from e-commerce app on Google Play for sentiment analysis.\\nTotal number of data: 10041 (train: 7028, validation: 3012). Provided by Jakarta AI Research.\\n', homepage='https://github.com/jakartaresearch/hf-datasets/tree/main/google-play-review/google-play-review', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_google_play_review/id_google_play_review.py', dataset_name='id_google_play_review', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_google_play_review_posneg_source', version=1.0.0, data_dir=None, data_files=None, description='id_google_play_review source schema', schema='source', subset_id='id_google_play_review_posneg'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={Jakartaresearch/google-play-review · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/jakartaresearch/google-play-review},\\n   author={Research, Jakarta AI}\\n} \\n', description='Indonesian Google Play Review, dataset scrapped from e-commerce app on Google Play for sentiment analysis.\\nTotal number of data: 10041 (train: 7028, validation: 3012). Provided by Jakarta AI Research.\\n', homepage='https://github.com/jakartaresearch/hf-datasets/tree/main/google-play-review/google-play-review', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_hatespeech_source', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech source schema', schema='source', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hoax_news/id_hoax_news.py', dataset_name='id_hoax_news', tasks=[<Tasks.HOAX_NEWS_CLASSIFICATION: 'HNC'>], languages=['ind'], config=NusantaraConfig(name='id_hoax_news_source', version=1.0.0, data_dir=None, data_files=None, description='Hoax News source schema', schema='source', subset_id='id_hoax_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8265649,  author={Pratiwi, Inggrid Yanuar Risca and Asmara, Rosa Andrie and Rahutomo, Faisal},  booktitle={2017 11th International Conference on Information & Communication Technology and System (ICTS)},   title={Study of hoax news detection using naïve bayes classifier in Indonesian language},   year={2017},  volume={},  number={},  pages={73-78},  doi={10.1109/ICTS.2017.8265649}}\\n', description='This research proposes to build an automatic hoax news detection and collects 250 pages of hoax and valid news articles in Indonesian language.\\nEach data sample is annotated by three reviewers and the final taggings are obtained by voting of those three reviewers.\\n', homepage='https://data.mendeley.com/datasets/p3hfgr5j3m/1', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hsd_nofaaulia/id_hsd_nofaaulia.py', dataset_name='id_hsd_nofaaulia', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_hsd_nofaaulia_source', version=1.0.0, data_dir=None, data_files=None, description='id_hsd_nofaaulia source schema', schema='source', subset_id='id_hsd_nofaaulia'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@inproceedings{10.1145/3330482.3330491,\\nauthor = {Aulia, Nofa and Budi, Indra},\\ntitle = {Hate Speech Detection on Indonesian Long Text Documents Using Machine Learning Approach},\\nyear = {2019},\\nisbn = {9781450361064},\\npublisher = {Association for Computing Machinery},\\naddress = {New York, NY, USA},\\nurl = {https://doi.org/10.1145/3330482.3330491},\\ndoi = {10.1145/3330482.3330491},\\nabstract = {Due to the growth of hate speech on social media in recent years, it is important to understand this issue. An automatic hate speech detection system is needed to help to counter this problem. There have been many studies on detecting hate speech in short documents like Twitter data. But to our knowledge, research on long documents is rare, we suppose that the difficulty is increasing due to the possibility of the message of the text may be hidden. In this research, we explore in detecting hate speech on Indonesian long documents using machine learning approach. We build a new Indonesian hate speech dataset from Facebook. The experiment showed that the best performance obtained by Support Vector Machine (SVM) as its classifier algorithm using TF-IDF, char quad-gram, word unigram, and lexicon features that yield f1-score of 85%.},\\nbooktitle = {Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence},\\npages = {164–169},\\nnumpages = {6},\\nkeywords = {machine learning, SVM, long documents, hate speech detection},\\nlocation = {Bali, Indonesia},\\nseries = {ICCAI '19}\\n}\\n\", description='There have been many studies on detecting hate speech in short documents like Twitter data. But to our knowledge, research on long documents is rare, we suppose that the difficulty is increasing due to the possibility of the message of the text may be hidden. In this research, we explore in detecting hate speech on Indonesian long documents using machine learning approach. We build a new Indonesian hate speech dataset from Facebook.\\n', homepage='https://dl.acm.org/doi/10.1145/3330482.3330491', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_source', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS source schema', schema='source', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_source', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT source schema', schema='source', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_qqp/id_qqp.py', dataset_name='id_qqp', tasks=[<Tasks.PARAPHRASING: 'PARA'>], languages=['ind'], config=NusantaraConfig(name='id_qqp_source', version=1.0.0, data_dir=None, data_files=None, description='ID QQP source schema', schema='source', subset_id='id_qqp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{quoraFirstQuora,\\n\\tauthor = {},\\n\\ttitle = {{F}irst {Q}uora {D}ataset {R}elease: {Q}uestion {P}airs --- quoradata.quora.com},\\n\\thowpublished = {https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs},\\n\\tyear = 2017,\\n\\tnote = {Online},\\n}\\n', description='Quora Question Pairs (QQP) dataset consists of over 400,000 question pairs, \\nand each question pair is annotated with a binary value indicating whether \\nthe two questions are paraphrase of each other. This dataset is translated \\nversion of QQP to Indonesian Language.\\n', homepage='https://github.com/louisowen6/quora_paraphrasing_id', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_short_answer_grading/id_short_answer_grading.py', dataset_name='id_short_answer_grading', tasks=[<Tasks.SHORT_ANSWER_GRADING: 'SAG'>], languages=['ind'], config=NusantaraConfig(name='id_short_answer_grading_source', version=1.0.0, data_dir=None, data_files=None, description='id_short_answer_grading source schema', schema='source', subset_id='id_short_answer_grading'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{\\n    JLK,\\n    author = {Muh Haidir and Ayu Purwarianti},\\n    title = { Short Answer Grading Using Contextual Word Embedding and Linear Regression},\\n    journal = {Jurnal Linguistik Komputasional},\\n    volume = {3},\\n    number = {2},\\n    year = {2020},\\n    keywords = {},\\n    abstract = {Abstract—One of the obstacles in an efficient MOOC is the evaluation of student answers, including the short answer grading which requires large effort from instructors to conduct it manually.\\n                Thus, NLP research in short answer grading has been conducted in order to support the automation, using several techniques such as rule\\n                and machine learning based. Here, we’ve conducted experiments on deep learning based short answer grading to compare the answer\\n                representation and answer assessment method. In the answer representation, we compared word embedding and sentence embedding models\\n                such as BERT, and its modification. In the answer assessment method, we use linear regression. There are 2 datasets that we used, available\\n                English short answer grading dataset with 80 questions and 2442 to get the best configuration for model and Indonesian short answer grading\\n                dataset with 36 questions and 9165 short answers as testing data. Here, we’ve collected Indonesian short answers for Biology and Geography\\n                subjects from 534 respondents where the answer grading was done by 7 experts. The best root mean squared error for both dataset was achieved\\n                by using BERT pretrained, 0.880 for English dataset dan 1.893 for Indonesian dataset.},\\n    issn = {2621-9336},\\tpages = {54--61},\\tdoi = {10.26418/jlk.v3i2.38},\\n    url = {https://inacl.id/journal/index.php/jlk/article/view/38}\\n}', description='Indonesian short answers for Biology and Geography subjects from 534 respondents where the answer grading was done by 7 experts.', homepage='https://github.com/AgeMagi/tugas-akhir', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_stance/id_stance.py', dataset_name='id_stance', tasks=[<Tasks.TEXTUAL_ENTAILMENT: 'TE'>], languages=['ind'], config=NusantaraConfig(name='id_stance_source', version=1.0.0, data_dir=None, data_files=None, description='IdStance source schema', schema='source', subset_id='id_stance'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629144,  \\n  author={R. {Jannati} and R. {Mahendra} and C. W. {Wardhana} and M. {Adriani}},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  title={Stance Classification Towards Political Figures on Blog Writing},\\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={96-101},\\n}\\n', description=\"Stance Classification Towards Political Figures on Blog Writing.\\nThis dataset contains dataset from the second research, which is combined from the first research and new dataset.\\nThe dataset consist of 337 data, about five target and every target have 1 different event.\\nTwo label are used: 'For' and 'Againts'.\\n1. For - the text that is created by author is support the target in an event\\n2. Against - the text that is created by author is oppose the target in an event\\n\", homepage='https://github.com/reneje/id_stance_dataset_article-Stance-Classification-Towards-Political-Figures-on-Blog-Writing', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_sts/id_sts.py', dataset_name='id_sts', tasks=[<Tasks.SEMANTIC_SIMILARITY: 'STS'>], languages=['ind'], config=NusantaraConfig(name='id_sts_source', version=1.0.0, data_dir=None, data_files=None, description='ID_STS source schema', schema='source', subset_id='id_sts'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n', description='SemEval is a series of international natural language processing (NLP) research workshops whose mission is\\nto advance the current state of the art in semantic analysis and to help create high-quality annotated datasets in a\\nrange of increasingly challenging problems in natural language semantics. This is a translated version of SemEval Dataset\\nfrom 2012-2016 for Semantic Textual Similarity Task to Indonesian language.\\n', homepage='https://github.com/ahmadizzan/sts-indo', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_jav_ind_source', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel source schema for jav to ind and ind to jav', schema='source', subset_id='id_wiki_parallel_jav_ind'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_min_ind_source', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel source schema for min to ind and ind to min', schema='source', subset_id='id_wiki_parallel_min_ind'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_sun_ind_source', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel source schema for sun to ind and ind to sun', schema='source', subset_id='id_wiki_parallel_sun_ind'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_source', version=1.0.0, data_dir=None, data_files=None, description='identic source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_id_source', version=1.0.0, data_dir=None, data_files=None, description='identic source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_en_source', version=1.0.0, data_dir=None, data_files=None, description='identic source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_raw_source', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC raw source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_tokenized_source', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC tokenized source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind', 'eng'], config=NusantaraConfig(name='identic_noclitic_source', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC noclitic source schema', schema='source', subset_id='identic'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='idk_mrc_source', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC with source schema', schema='source', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_trans_squad_source', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (trans_squad) with source schema', schema='source', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_tydiqa_source', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (tydiqa) with source schema', schema='source', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_model_gen_source', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (model_gen) with source schema', schema='source', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_human_filt_source', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (human_filt) with source schema', schema='source', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_source', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI source schema', schema='source', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/imdb_jv/imdb_jv.py', dataset_name='imdb_jv', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='imdb_jv_source', version=1.0.0, data_dir=None, data_files=None, description='imdb_jv source schema', schema='source', subset_id='imdb_jv'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wongso2021causal,\\n  title={Causal and masked language modeling of Javanese language using transformer-based architectures},\\n  author={Wongso, Wilson and Setiawan, David Samuel and Suhartono, Derwin},\\n  booktitle={2021 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={1--7},\\n  year={2021},\\n  organization={IEEE}\\n}\\n', description='Javanese Imdb Movie Reviews Dataset is a Javanese version of the IMDb Movie Reviews dataset by translating the original English dataset to Javanese.\\n', homepage='https://huggingface.co/datasets/w11wo/imdb-javanese', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo4b/indo4b.py', dataset_name='indo4b', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='indo4b_source', version='1.0.0', data_dir=None, data_files=None, description='Indo4B source schema', schema='source', subset_id='indo4b'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @inproceedings{wilie-etal-2020-indonlu,\\n        title = \"{I}ndo{NLU}: Benchmark and Resources for Evaluating {I}ndonesian \\n            Natural Language Understanding\",\\n        author = \"Wilie, Bryan  and\\n          Vincentio, Karissa  and\\n          Winata, Genta Indra  and\\n          Cahyawijaya, Samuel  and\\n          Li, Xiaohong  and\\n          Lim, Zhi Yuan  and\\n          Soleman, Sidik  and\\n          Mahendra, Rahmad  and\\n          Fung, Pascale  and\\n          Bahar, Syafri  and\\n          Purwarianti, Ayu\",\\n        booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the \\n                Association for Computational Linguistics and the 10th International Joint \\n                Conference on Natural Language Processing\",\\n        month = dec,\\n        year = \"2020\",\\n        address = \"Suzhou, China\",\\n        publisher = \"Association for Computational Linguistics\",\\n        url = \"https://aclanthology.org/2020.aacl-main.85\",\\n        pages = \"843--857\",\\n        abstract = \"Although Indonesian is known to be the fourth most frequently used language \\n            over the internet, the research progress on this language in natural language processing (NLP) \\n            is slow-moving due to a lack of available resources. In response, we introduce the first-ever vast \\n            resource for training, evaluation, and benchmarking on Indonesian natural language understanding \\n            (IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence classification to \\n            pair-sentences sequence labeling with different levels of complexity. The datasets for the tasks \\n            lie in different domains and styles to ensure task diversity. We also provide a set of Indonesian \\n            pre-trained models (IndoBERT) trained from a large and clean Indonesian dataset (Indo4B) collected \\n            from publicly available sources such as social media texts, blogs, news, and websites. \\n            We release baseline models for all twelve tasks, as well as the framework for benchmark evaluation, \\n            thus enabling everyone to benchmark their system performances.\",\\n    }\\n', description='    Indo4B is a large-scale Indonesian self-supervised pre-training corpus\\n    consists of around 3.6B words, with around 250M sentences. The corpus\\n    covers both formal and colloquial Indonesian sentences compiled from \\n    12 sources, of which two cover Indonesian colloquial language, eight\\n    cover formal Indonesian language, and the rest have a mixed style of\\n    both colloquial and formal.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo4b_plus/indo4b_plus.py', dataset_name='indo4b_plus', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'sun', 'jav'], config=NusantaraConfig(name='indo4b_plus_source', version='1.0.0', data_dir=None, data_files=None, description='Indo4B-Plus source schema', schema='source', subset_id='indo4b_plus'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @inproceedings{cahyawijaya-etal-2021-indonlg,\\n        title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n        author = \"Cahyawijaya, Samuel  and\\n          Winata, Genta Indra  and\\n          Wilie, Bryan  and\\n          Vincentio, Karissa  and\\n          Li, Xiaohong  and\\n          Kuncoro, Adhiguna  and\\n          Ruder, Sebastian  and\\n          Lim, Zhi Yuan  and\\n          Bahar, Syafri  and\\n          Khodra, Masayu  and\\n          Purwarianti, Ayu  and\\n          Fung, Pascale\",\\n        booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n        month = nov,\\n        year = \"2021\",\\n        address = \"Online and Punta Cana, Dominican Republic\",\\n        publisher = \"Association for Computational Linguistics\",\\n        url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n        doi = \"10.18653/v1/2021.emnlp-main.699\",\\n        pages = \"8875--8898\",\\n        abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress \\n        and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource \\n        languages poses a challenging barrier for building NLG systems that work well for languages with limited \\n        amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG)\\n        progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. \\n        Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important \\n        use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, \\n        and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, \\n        Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. \\n        We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth\\n        the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes \\n        the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference \\n        at very low-resource languages like Javanese and Sundanese.\",\\n    }\\n', description='    Indo4B-Plus is an extension of Indo4B, a large-scale Indonesian self-supervised pre-training corpus. \\n    Indo4B-Plus extend Indo4B by adding two low-resource Indonesian local languages to the corpus, i.e., Sundanese and Javanese.\\n    Indo4B-Plus adds 82,582,025 words (∼2.07%) of Sundanese sentences and 331,041,877 words (∼8.29%) of Javanese\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT En-Id source schema', schema='source', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_law/indo_law.py', dataset_name='indo_law', tasks=[<Tasks.LEGAL_CLASSIFICATION: 'LC'>], languages=['ind'], config=NusantaraConfig(name='indo_law_source', version=1.0.0, data_dir=None, data_files=None, description='Indo-Law source schema', schema='source', subset_id='indo_law'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nuranti2022predicting,\\n  title={Predicting the Category and the Length of Punishment in Indonesian Courts Based on Previous Court Decision Documents},\\n  author={Nuranti, Eka Qadri and Yulianti, Evi and Husin, Husna Sarirah},\\n  journal={Computers},\\n  volume={11},\\n  number={6},\\n  pages={88},\\n  year={2022},\\n  publisher={Multidisciplinary Digital Publishing Institute}\\n}\\n', description='This study presents predictions of first-level judicial decisions by utilizing a collection of Indonesian court decision documents. \\nWe propose using multi-level learning, namely, CNN+attention, using decision document sections as features to predict the category and the length of punishment in Indonesian courts. \\nOur results demonstrate that the decision document sections that strongly affected the accuracy of the prediction model were prosecution history, facts, legal facts, and legal considerations.\\n', homepage='', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_puisi/indo_puisi.py', dataset_name='indo_puisi', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='indo_puisi_source', version='1.0.0', data_dir=None, data_files=None, description='Indo puisi source schema', schema='source', subset_id='indo_puisi'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n', description='Puisi is an Indonesian poetic form. The dataset was collected by scraping various websites. It contains 7223 Indonesian puisi along with the title and author.\\n', homepage='https://github.com/ilhamfp/puisi-pantun-generator', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=[<Tasks.MORPHOLOGICAL_INFLECTION: 'MOR'>], languages=['ind'], config=NusantaraConfig(name='indocollex_source', version=1.0.0, data_dir=None, data_files=None, description='indocollex source schema', schema='source', subset_id='indocollex'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=[<Tasks.MORPHOLOGICAL_INFLECTION: 'MOR'>], languages=['ind'], config=NusantaraConfig(name='indocollex_f2i_source', version=1.0.0, data_dir=None, data_files=None, description='indocollex source schema', schema='source', subset_id='indocollex_f2i'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=[<Tasks.MORPHOLOGICAL_INFLECTION: 'MOR'>], languages=['ind'], config=NusantaraConfig(name='indocollex_i2f_source', version=1.0.0, data_dir=None, data_files=None, description='indocollex source schema', schema='source', subset_id='indocollex_i2f'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks=[<Tasks.COREFERENCE_RESOLUTION: 'COREF'>], languages=['ind'], config=NusantaraConfig(name='indocoref_source', version=1.0.0, data_dir=None, data_files=None, description='Indocoref source schema', schema='source', subset_id='indocoref'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks=[<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ntp_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP source schema', schema='source', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment source schema', schema='source', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks=[<Tasks.SENTENCE_ORDERING: 'SO'>], languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering source schema', schema='source', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_gsd/indolem_ud_id_gsd.py', dataset_name='indolem_ud_id_gsd', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_gsd_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_ud_id_gsd source schema', schema='source', subset_id='indolem_ud_id_gsd'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mcdonald-etal-2013-universal,\\n    title = \"{U}niversal {D}ependency Annotation for Multilingual Parsing\",\\n    author = {McDonald, Ryan  and\\n      Nivre, Joakim  and\\n      Quirmbach-Brundage, Yvonne  and\\n      Goldberg, Yoav  and\\n      Das, Dipanjan  and\\n      Ganchev, Kuzman  and\\n      Hall, Keith  and\\n      Petrov, Slav  and\\n      Zhang, Hao  and\\n      T{\"a}ckstr{\"o}m, Oscar  and\\n      Bedini, Claudia  and\\n      Bertomeu Castell{\\'o}, N{\\'u}ria  and\\n      Lee, Jungmee},\\n    booktitle = \"Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\\n    month = aug,\\n    year = \"2013\",\\n    address = \"Sofia, Bulgaria\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/P13-2017\",\\n    pages = \"92--97\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='The Indonesian-GSD treebank consists of 5598 sentences and 122k words split into train/dev/test of 97k/12k/11k words.\\nThe treebank was originally converted from the content head version of the universal dependency treebank v2.0 (legacy) in 2015.In order to comply with the latest Indonesian annotation guidelines, the treebank has undergone a major revision between UD releases v2.8 and v2.9 (2021).\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud default fold ('0') of source schema\", schema='source', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_0_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '0' of source schema\", schema='source', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_1_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '1' of source schema\", schema='source', subset_id='indolem_ud_id_pud_1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_2_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '2' of source schema\", schema='source', subset_id='indolem_ud_id_pud_2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_3_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '3' of source schema\", schema='source', subset_id='indolem_ud_id_pud_3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_4_source', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '4' of source schema\", schema='source', subset_id='indolem_ud_id_pud_4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonesian_wsd/indonesian_wsd.py', dataset_name='indonesian_wsd', tasks=[<Tasks.WORD_SENSE_DISAMBIGUATION: 'WSD'>], languages=['ind'], config=NusantaraConfig(name='indonesian_wsd_source', version=1.0.0, data_dir=None, data_files=None, description='Indonesian WSD source schema', schema='source', subset_id='indonesian_wsd'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mahendra-etal-2018-cross,\\n    title = \"Cross-Lingual and Supervised Learning Approach for {I}ndonesian Word Sense Disambiguation Task\",\\n    author = \"Mahendra, Rahmad  and\\n      Septiantri, Heninggar  and\\n      Wibowo, Haryo Akbarianto  and\\n      Manurung, Ruli  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 9th Global Wordnet Conference\",\\n    month = jan,\\n    year = \"2018\",\\n    address = \"Nanyang Technological University (NTU), Singapore\",\\n    publisher = \"Global Wordnet Association\",\\n    url = \"https://aclanthology.org/2018.gwc-1.28\",\\n    pages = \"245--250\",\\n    abstract = \"Ambiguity is a problem we frequently face in Natural Language Processing. Word Sense Disambiguation (WSD) is a task to determine the correct sense of an ambiguous word. However, research in WSD for Indonesian is still rare to find. The availability of English-Indonesian parallel corpora and WordNet for both languages can be used as training data for WSD by applying Cross-Lingual WSD method. This training data is used as an input to build a model using supervised machine learning algorithms. Our research also examines the use of Word Embedding features to build the WSD model.\",\\n}\\n', description='Word Sense Disambiguation (WSD) is a task to determine the correct sense of an ambiguous word.\\nThe training data was collected from news websites and manually annotated. The words in training data were processed using the morphological analysis to obtain lemma.\\nThe features being used were some words around the target word (including the words before and after the target word), the nearest verb from the\\ntarget word, the transitive verb around the target word, and the document context. \\n', homepage='https://github.com/rmahendra/Indonesian-WSD', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks=[<Tasks.TEXTUAL_ENTAILMENT: 'TE'>], languages=['ind'], config=NusantaraConfig(name='indonli_source', version=1.1.0, data_dir=None, data_files=None, description='indonli source schema', schema='source', subset_id='indonli'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonlu_nergrit/indonlu_nergrit.py', dataset_name='indonlu_nergrit', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indonlu_nergrit_source', version=1.0.0, data_dir=None, data_files=None, description='IndoNLU NERGrit source schema', schema='source', subset_id='indonlu_nergrit'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n@online{nergrit2019,\\n  title={NERGrit Corpus},\\n  author={NERGrit Developers},\\n  year={2019},\\n  url={https://github.com/grit-id/nergrit-corpus}\\n}\\n', description='This NER dataset is taken from the Grit-ID repository, and the labels are spans in IOB chunking representation.\\nThe dataset consists of three kinds of named entity tags, PERSON (name of person), PLACE (name of location), and\\nORGANIZATION (name of organization).\\n', homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indotacos/indotacos.py', dataset_name='indotacos', tasks=[<Tasks.TAX_COURT_VERDICT: 'TACOS'>], languages=['ind'], config=NusantaraConfig(name='indotacos_source', version=1.0.0, data_dir=None, data_files=None, description='indotacos source schema', schema='source', subset_id='indotacos'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @misc{wibisono2022indotacos,\\n        title = {IndoTacos},\\n        howpublished = {\\\\url{https://www.kaggle.com/datasets/christianwbsn/indonesia-tax-court-verdict}},\\n        note = {Accessed: 2022-09-22}\\n    }\\n', description='Predicting the outcome or the probability of winning a legal case has always been highly attractive in legal sciences and practice.\\nHardly any dataset has been developed to analyze and accelerate the research of court verdict analysis.\\nFind out what factor affects the outcome of tax court verdict using Natural Language Processing.\\n', homepage='https://www.kaggle.com/datasets/christianwbsn/indonesia-tax-court-verdict', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indqner/indqner.py', dataset_name='indqner', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indqner_source', version=1.0.0, data_dir=None, data_files=None, description='NER dataset from Indonesian translation Quran source schema', schema='source', subset_id='indqner'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{,\\nauthor = {Ria Hari Gusmita, Asep Fajar Firmansyah, Khodijah Khuliyah},\\ntitle = {{IndQNER: a NER Benchmark Dataset on Indonesian Translation of Quran}},\\nurl = {https://github.com/RiaGusmita/IndQNER},\\nyear = {2022}\\n}\\n', description='IndQNER is a NER dataset created by manually annotating the Indonesian translation of Quran text.\\nThe dataset contains 18 named entity categories as follow:\\n    \"Allah\": Allah (including synonim of Allah such as Yang maha mengetahui lagi mahabijaksana)\\n    \"Throne\": Throne of Allah (such as \\'Arasy)\\n    \"Artifact\": Artifact (such as Ka\\'bah, Baitullah)\\n    \"AstronomicalBody\": Astronomical body (such as bumi, matahari)\\n    \"Event\": Event (such as hari akhir, kiamat)\\n    \"HolyBook\": Holy book (such as AlQur\\'an)\\n    \"Language\": Language (such as bahasa Arab\\n    \"Angel\": Angel (such as Jibril, Mikail)\\n    \"Person\": Person (such as Bani Israil, Fir\\'aun)\\n    \"Messenger\": Messenger (such as Isa, Muhammad, Musa)\\n    \"Prophet\": Prophet (such as Adam, Sulaiman)\\n    \"AfterlifeLocation\": Afterlife location (such as Jahanam, Jahim, Padang Mahsyar)\\n    \"GeographicalLocation\": Geographical location (such as Sinai, negeru Babilonia)\\n    \"Color\": Color (such as kuning tua)\\n    \"Religion\": Religion (such as Islam, Yahudi, Nasrani)\\n    \"Food\": Food (such as manna, salwa)\\n', homepage='https://github.com/RiaGusmita/IndQNER', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_digit_cdsr/indspeech_digit_cdsr.py', dataset_name='indspeech_digit_cdsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_digit_cdsr_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_digit_cdsr source schema', schema='source', subset_id='indspeech_digit_cdsr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n', description='INDspeech_DIGIT_CDSR is the first Indonesian speech dataset for connected digit speech recognition (CDSR). The data was developed by TELKOMRisTI (R&D Division, PT Telekomunikasi Indonesia) in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan and Bandung Institute of Technology (ITB) under the Asia-Pacific Telecommunity (APT) project in 2004 [Sakti et al., 2004]. Although it was originally developed for a telecommunication system for hearing and speaking impaired people, it can be used for other applications, i.e., automatic call centers that recognize telephone numbers.\\n', homepage='https://github.com/s-sakti/data_indsp_digit_cdsr', license='CC-BY-NC-SA-4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_jv_overlap_source', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr source schema', schema='source', subset_id='indspeech_news_ethnicsr_jv_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_su_overlap_source', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr source schema', schema='source', subset_id='indspeech_news_ethnicsr_su_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_jv_nooverlap_source', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr source schema', schema='source', subset_id='indspeech_news_ethnicsr_jv_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_su_nooverlap_source', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr source schema', schema='source', subset_id='indspeech_news_ethnicsr_su_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_lvcsr/indspeech_news_lvcsr.py', dataset_name='indspeech_news_lvcsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_lvcsr_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_lvcsr source schema', schema='source', subset_id='indspeech_news_lvcsr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tcast-2008,\\n    title = \"Development of {I}ndonesian Large Vocabulary Continuous Speech Recognition System within {A-STAR} Project\",\\n    author = \"Sakti, Sakriani and Kelana, Eka and Riza, Hammam and Sakai, Shinsuke and Markov, Konstantin and Nakamura, Satoshi\",\\n    booktitle = \"Proc. IJCNLP Workshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST)\",\\n    year = \"2008\",\\n    pages = \"19--24\"\\n    address = \"Hyderabad, India\"\\n}\\n\\n@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Translating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='This is the first Indonesian speech dataset for large vocabulary continuous speech recognition (LVCSR) with more than 40 hours of speech and 400 speakers [Sakti et al., 2008]. R&D Division of PT Telekomunikasi Indonesia (TELKOMRisTI) developed the data in 2005-2006, in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan, as the continuation of the Asia-Pacific Telecommunity (APT) project [Sakti et al., 2004]. It has also been successfully used for developing Indonesian LVCSR in the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_lvcsr', license='CC BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_12_MOS_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts source schema for 12 train and MOS test task', schema='source', subset_id='indspeech_news_tts_12_MOS'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_30_MOS_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts source schema for 30 train and MOS test task', schema='source', subset_id='indspeech_news_tts_30_MOS'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_60_MOS_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts source schema for 60 train and MOS test task', schema='source', subset_id='indspeech_news_tts_60_MOS'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_120_MOS_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts source schema for 120 train and MOS test task', schema='source', subset_id='indspeech_news_tts_120_MOS'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_ZR_ZR_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts source schema for ZR train and ZR test task', schema='source', subset_id='indspeech_news_tts_ZR_ZR'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_ban_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for BALI language with overlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_ban_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for BALI language with nooverlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_btk_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for BATAK language with overlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_btk_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for BATAK language with nooverlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_jav_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for JAWA language with overlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_jav_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for JAWA language with nooverlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_sun_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for SUNDA language with overlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_sun_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr source schema for SUNDA language with nooverlapping dataset', schema='source', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_teldialog_lvcsr/indspeech_teldialog_lvcsr.py', dataset_name='indspeech_teldialog_lvcsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_teldialog_lvcsr_source', version='1.0.0', data_dir=None, data_files=None, description='indspeech_teldialog_lvcsr source schema', schema='source', subset_id='indspeech_teldialog_lvcsr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tcast-2008,\\n    title = \"Development of {I}ndonesian Large Vocabulary Continuous Speech Recognition System within {A-STAR} Project\",\\n    author = \"Sakti, Sakriani and Kelana, Eka and Riza, Hammam and Sakai, Shinsuke and Markov, Konstantin and Nakamura, Satoshi\",\\n    booktitle = \"Proc. IJCNLP Workshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST)\",\\n    year = \"2008\",\\n    pages = \"19--24\"\\n    address = \"Hyderabad, India\"\\n}\\n\\n\\n@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='\\nINDspeech_TELDIALOG_LVCSR is one of the first Indonesian speech datasets for large vocabulary continuous speech recognition (LVCSR) based on telephon application. R&D Division of PT Telekomunikasi Indonesia developed the data in 2005-2006, in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan, as the continuation of the Asia-Pacific Telecommunity (APT) project [Sakti et al., 2004]. It has also been successfully used for developing Indonesian LVCSR in the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_teldialog_lvcsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_teldialog_svcsr/indspeech_teldialog_svcsr.py', dataset_name='indspeech_teldialog_svcsr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='indspeech_teldialog_svcsr_source', version=1.0.0, data_dir=None, data_files=None, description='indspeech_teldialog_svcsr source schema', schema='source', subset_id='indspeech_teldialog_svcsr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n', description='This is the first Indonesian speech dataset for small vocabulary continuous speech recognition (SVCSR).\\nThe data was developed by TELKOMRisTI (R&D Division, PT Telekomunikasi Indonesia) in collaboration with Advanced\\nTelecommunication Research Institute International (ATR) Japan and Bandung Institute of Technology (ITB) under the\\nAsia-Pacific Telecommunity (APT) project in 2004 [Sakti et al., 2004]. Although it was originally developed for\\na telecommunication system for hearing and speaking impaired people, it can be used for other applications,\\ni.e., automatic call centers. Furthermore, as all speakers utter the same sentences,\\nit can also be used for voice conversion tasks.\\n\\nThe text is based on a word vocabulary which is derived from some necessary dialog calls,\\nsuch as dialog calls with the 119 emergency department, 108 telephone information department,\\nand ticket reservation department. In total, it consists of 20,000 utterances (about 18 hours of speech) from the\\n70-word dialog vocabulary of 100 sentences (including single word sentences) each uttered by 200 speakers\\n(100 Females, 100 Males). The age is limited to middle age (20-40 years), but they present a wide range of spoken\\ndialects from different ethnic groups. The recording is conducted in parallel for both clean and telephone speech,\\nbut we open only the clean speech due to quality issues on telephone speech.\\nEach audio file is a single-channel 16-bit PCM WAV with a sample rate of 16000 Hz.\\nThese utterances are equally split into training and test sets with 100 speakers (50 Females, 50 Males) in each set.\\n', homepage='https://github.com/s-sakti/data_indsp_teldialog_svcsr/', license='CC-BY-NC-SA-4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/inset_lexicon/inset_lexicon.py', dataset_name='inset_lexicon', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='inset_lexicon_source', version=1.0.0, data_dir=None, data_files=None, description='Inset Lexicon source schema', schema='source', subset_id='inset_lexicon'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Koto, Fajri and Rahmaningtyas, Gemala},\\nyear = {2017},\\nmonth = {12},\\npages = {},\\ntitle = {InSet Lexicon: Evaluation of a Word List for Indonesian Sentiment Analysis in Microblogs},\\ndoi = {10.1109/IALP.2017.8300625}\\n}\\n', description='InSet, an Indonesian sentiment lexicon built to identify written opinion and categorize it into positive or negative opinion,\\nwhich could be utilized to analyze public sentiment towards particular topic, event, or product. Composed using collection\\nof words from Indonesian tweet, InSet was constructed by manually weighting each words and enhanced by adding stemming and synonym set\\n', homepage='https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jadi_ide/jadi_ide.py', dataset_name='jadi_ide', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='jadi_ide_source', version=1.0.0, data_dir=None, data_files=None, description='JaDi-Ide source schema', schema='source', subset_id='jadi_ide'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{hidayatullah2020attention,\\n  title={Attention-based cnn-bilstm for dialect identification on javanese text},\\n  author={Hidayatullah, Ahmad Fathan and Cahyaningtyas, Siwi and Pamungkas, Rheza Daffa},\\n  journal={Kinetik: Game Technology, Information System, Computer Network, Computing, Electronics, and Control},\\n  pages={317--324},\\n  year={2020}\\n}\\n', description='The JaDi-Ide dataset is a Twitter dataset for Javanese dialect identification, containing 16,498 \\ndata samples. The dialect is classified into `Standard Javanese`, `Ngapak Javanese`, and `East \\nJavanese` dialects.\\n', homepage='https://github.com/fathanick/Javanese-Dialect-Identification-from-Twitter-Data', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jv_id_asr/jv_id_asr.py', dataset_name='jv_id_asr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['jav'], config=NusantaraConfig(name='jv_id_asr_source', version=1.0.0, data_dir=None, data_files=None, description='jv_id_asr source schema', schema='source', subset_id='jv_id_asr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{kjartansson-etal-sltu2018,\\n    title = {{Crowd-Sourced Speech Corpora for Javanese, Sundanese,  Sinhala, Nepali, and Bangladeshi Bengali}},\\n    author = {Oddur Kjartansson and Supheakmungkol Sarin and Knot Pipatsrisawat and Martin Jansche and Linne Ha},\\n    booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\\n    year  = {2018},\\n    address = {Gurugram, India},\\n    month = aug,\\n    pages = {52--55},\\n    URL   = {http://dx.doi.org/10.21437/SLTU.2018-11},\\n  }\\n', description='This data set contains transcribed audio data for Javanese. The data set consists of wave files, and a TSV file.\\nThe file utt_spk_text.tsv contains a FileID, UserID and the transcription of audio in the file.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Reykjavik University and Universitas Gadjah Mada in Indonesia.\\n', homepage='http://openslr.org/35/', license='Attribution-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jv_id_tts/jv_id_tts.py', dataset_name='jv_id_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['jav'], config=NusantaraConfig(name='jv_id_tts_source', version=1.0.0, data_dir=None, data_files=None, description='JV_ID_TTS source schema', schema='source', subset_id='jv_id_tts'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='This data set contains high-quality transcribed audio data for Javanese.\\nThe data set consists of wave files, and a TSV file.\\nThe file line_index.tsv contains a filename and the transcription of audio in the file.\\nEach filename is prepended with a speaker identification number.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Gadjah Mada University in Indonesia.\\n', homepage='http://openslr.org/41/', license='See https://www.openslr.org/resources/41/LICENSE file for license information. Attribution-ShareAlike 4.0 (CC BY-SA 4.0).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kamus_alay/kamus_alay.py', dataset_name='kamus_alay', tasks=[<Tasks.MORPHOLOGICAL_INFLECTION: 'MOR'>], languages=['ind'], config=NusantaraConfig(name='kamus_alay_source', version=1.0.0, data_dir=None, data_files=None, description='Kamus Alay source schema', schema='source', subset_id='kamus_alay'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629151,\\nauthor={Aliyah Salsabila, Nikmatun and Ardhito Winatmoko, Yosef and Akbar Septiandri, Ali and Jamal, Ade},\\nbooktitle={2018 International Conference on Asian Language Processing (IALP)},\\ntitle={Colloquial Indonesian Lexicon},\\nyear={2018},\\nvolume={},\\nnumber={},\\npages={226-229},\\ndoi={10.1109/IALP.2018.8629151}}\\n', description='Kamus Alay provide a lexicon for text normalization of Indonesian colloquial words.\\nIt contains 3,592 unique colloquial words-also known as “bahasa alay” -and manually annotated them\\nwith the normalized form. We built this lexicon from Instagram comments provided by Septiandri & Wibisono (2017)\\n', homepage='https://ieeexplore.ieee.org/abstract/document/8629151', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/karonese_sentiment/karonese_sentiment.py', dataset_name='karonese_sentiment', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['btx'], config=NusantaraConfig(name='karonese_sentiment_source', version=1.0.0, data_dir=None, data_files=None, description='Karonese Sentiment source schema', schema='source', subset_id='karonese_sentiment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{karo2022sentiment,\\n  title={Sentiment Analysis in Karonese Tweet using Machine Learning},\\n  author={Karo, Ichwanul Muslim Karo and Fudzee, Mohd Farhan Md and Kasim, Shahreen and Ramli, Azizul Azhar},\\n  journal={Indonesian Journal of Electrical Engineering and Informatics (IJEEI)},\\n  volume={10},\\n  number={1},\\n  pages={219--231},\\n  year={2022}\\n}\\n', description='Karonese sentiment was crawled from Twitter between 1 January 2021 and 31 October 2021.\\nThe first crawling process used several keywords related to the Karonese, such as\\n\"deleng sinabung, Sinabung mountain\", \"mejuah-juah, greeting welcome\", \"Gundaling\",\\nand so on. However, due to the insufficient number of tweets obtained using such\\nkeywords, a second crawling process was done based on several hashtags, such as\\n#kalakkaro, # #antonyginting, and #lyodra.\\n', homepage='http://section.iaesonline.com/index.php/IJEEI/article/view/3565', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/keps/keps.py', dataset_name='keps', tasks=[<Tasks.KEYWORD_EXTRACTION: 'KE'>], languages=['ind'], config=NusantaraConfig(name='keps_source', version=1.0.0, data_dir=None, data_files=None, description='KEPS source schema', schema='source', subset_id='keps'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mahfuzh2019improving,\\n  title={Improving Joint Layer RNN based Keyphrase Extraction by Using Syntactical Features},\\n  author={Miftahul Mahfuzh, Sidik Soleman, and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='The KEPS dataset (Mahfuzh, Soleman and Purwarianti, 2019) consists of text from Twitter\\ndiscussing banking products and services and is written in the Indonesian language. A phrase\\ncontaining important information is considered a keyphrase. Text may contain one or more\\nkeyphrases since important phrases can be located at different positions.\\n- tokens: a list of string features.\\n- seq_label: a list of classification labels, with possible values including O, B, I.\\nThe labels use Inside-Outside-Beginning (IOB) tagging.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for all-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for all-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for all-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for all-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_10-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_10-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_10-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_17-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_17-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_17-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_17-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_21-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_21-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_21-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_21-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_25-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_25-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_25-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_25-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_31-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_31-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_31-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_31-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_39-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_39-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_39-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_39-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_43-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_43-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_43-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_43-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_49-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_49-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2021_49-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_05-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_05-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_05-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_05-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_21-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_21-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_21-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_21-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-raw_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_27-raw', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-dedup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_27-dedup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-neardup_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_27-neardup', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-neardup_clean_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC with source schema for 2022_27-neardup_clean', schema='source', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2016_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2016', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2017_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2017', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2018_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2018', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2019_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2019', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2020_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2020', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2021_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2021', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2022_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for 2022', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_all_source', version=2018.12.1, data_dir=None, data_files=None, description='KoPI-CC_News with source schema for all', schema='source', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for all-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for all-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for all-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ace_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ace_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ace_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ban_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ban_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ban_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for bjn_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for bjn_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for bjn_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ind_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ind_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for ind_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for jav_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for jav_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for jav_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for min_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for min_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for min_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-raw_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for sun_Latn-raw', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-dedup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for sun_Latn-dedup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-neardup_source', version=2022.9.13, data_dir=None, data_files=None, description='KoPI-NLLB with source schema for sun_Latn-neardup', schema='source', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_jav_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2jav source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_day_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2day source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bug_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bug source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_sun_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2sun source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_mad_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2mad source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bin_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bin source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bbc source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_khek_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2khek source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_msa_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2msa source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_min_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2min source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_tiociu_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2tiociu source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_jav_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara jav2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_day_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara day2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bug_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bug2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_sun_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara sun2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_mad_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara mad2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bin_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bin2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bbc_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bbc2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_khek_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara khek2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_msa_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara msa2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_min_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara min2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_tiociu_ind_source', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara tiociu2ind source schema', schema='source', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for all languages', schema='source', subset_id='librivox_indonesia'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ind_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for indonesian languages', schema='source', subset_id='librivox_indonesia_ind'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ban_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for balinese languages', schema='source', subset_id='librivox_indonesia_ban'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_bug_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for bugisnese languages', schema='source', subset_id='librivox_indonesia_bug'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_sun_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for sundanese languages', schema='source', subset_id='librivox_indonesia_sun'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ace_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for acehnese languages', schema='source', subset_id='librivox_indonesia_ace'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_min_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for minangkabau languages', schema='source', subset_id='librivox_indonesia_min'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_jav_source', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia source schema for javanese languages', schema='source', subset_id='librivox_indonesia_jav'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/liputan6/liputan6.py', dataset_name='liputan6', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='liputan6_canonical_source', version='1.0.0', data_dir=None, data_files=None, description='liputan6 source schema', schema='source', subset_id='liputan6_canonical'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto2020liputan6,\\n  title={Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\\n  author={Koto, Fajri and Lau, Jey Han and Baldwin, Timothy},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={598--608},\\n  year={2020}\\n}\\n', description='\\nA large-scale Indonesian summarization dataset consisting of harvested articles from Liputan6.com, an online news portal, resulting in 215,827 document-summary pairs.\\n', homepage='https://github.com/fajri91/sum_liputan6', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/liputan6/liputan6.py', dataset_name='liputan6', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='liputan6_xtreme_source', version='1.0.0', data_dir=None, data_files=None, description='liputan6 source schema', schema='source', subset_id='liputan6_xtreme'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto2020liputan6,\\n  title={Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\\n  author={Koto, Fajri and Lau, Jey Han and Baldwin, Timothy},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={598--608},\\n  year={2020}\\n}\\n', description='\\nA large-scale Indonesian summarization dataset consisting of harvested articles from Liputan6.com, an online news portal, resulting in 215,827 document-summary pairs.\\n', homepage='https://github.com/fajri91/sum_liputan6', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/local_id_abusive/local_id_abusive.py', dataset_name='local_id_abusive', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['jav', 'sun'], config=NusantaraConfig(name='local_id_abusive_jav_source', version=1.0.0, data_dir=None, data_files=None, description='local_id_abusive source schema Javanese', schema='source', subset_id='local_id_abusive_jav'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{putri2021abusive,\\n  title={Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},\\n  author={Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},\\n  booktitle={2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},\\n  pages={461--465},\\n  year={2021},\\n  organization={International Workshop on Computer Science and Engineering (WCSE)},\\n  abstract={Indonesia’s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages.}\\n}\\n', description='This dataset is for abusive and hate speech detection, using Twitter text containing Javanese and Sundanese words.\\n\\n(from the publication source)\\nThe Indonesian local language dataset collection was conducted using Twitter search API to collect the tweets and then\\nimplemented using Tweepy Library. The tweets were collected using queries from the list of abusive words in Indonesian\\ntweets. The abusive words were translated into local Indonesian languages, which are Javanese and Sundanese. The\\ntranslated words are then used as queries to collect tweets containing Indonesian and local languages. The translation\\nprocess involved native speakers for each local language. The crawling process has collected a total of more than 5000\\ntweets. Then, the crawled data were filtered to get tweets that contain local’s vocabulary and/or sentences in Javanese\\nand Sundanese. Next, after the filtering process, the data will be labeled whether the tweets are labeled as hate speech\\nand abusive language or not.\\n', homepage='https://github.com/Shofianina/local-indonesian-abusive-hate-speech-dataset', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/local_id_abusive/local_id_abusive.py', dataset_name='local_id_abusive', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['jav', 'sun'], config=NusantaraConfig(name='local_id_abusive_sun_source', version=1.0.0, data_dir=None, data_files=None, description='local_id_abusive source schema Sundanese', schema='source', subset_id='local_id_abusive_sun'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{putri2021abusive,\\n  title={Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},\\n  author={Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},\\n  booktitle={2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},\\n  pages={461--465},\\n  year={2021},\\n  organization={International Workshop on Computer Science and Engineering (WCSE)},\\n  abstract={Indonesia’s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages.}\\n}\\n', description='This dataset is for abusive and hate speech detection, using Twitter text containing Javanese and Sundanese words.\\n\\n(from the publication source)\\nThe Indonesian local language dataset collection was conducted using Twitter search API to collect the tweets and then\\nimplemented using Tweepy Library. The tweets were collected using queries from the list of abusive words in Indonesian\\ntweets. The abusive words were translated into local Indonesian languages, which are Javanese and Sundanese. The\\ntranslated words are then used as queries to collect tweets containing Indonesian and local languages. The translation\\nprocess involved native speakers for each local language. The crawling process has collected a total of more than 5000\\ntweets. Then, the crawled data were filtered to get tweets that contain local’s vocabulary and/or sentences in Javanese\\nand Sundanese. Next, after the filtering process, the data will be labeled whether the tweets are labeled as hate speech\\nand abusive language or not.\\n', homepage='https://github.com/Shofianina/local-indonesian-abusive-hate-speech-dataset', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_source', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation source schema', schema='source', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/multilexnorm/multilexnorm.py', dataset_name='multilexnorm', tasks=[<Tasks.MULTILEXNORM: 'MLN'>], languages=['ind'], config=NusantaraConfig(name='multilexnorm_source', version='1.0.0', data_dir=None, data_files=None, description='multilexnorm source schema', schema='source', subset_id='multilexnorm'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{multilexnorm,\\n  title= {MultiLexNorm: A Shared Task on Multilingual Lexical Normalization,\\n  author = \"van der Goot, Rob and Ramponi et al.\",\\n  booktitle = \"Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021)\",\\n  year = \"2021\",\\n  publisher = \"Association for Computational Linguistics\",\\n  address = \"Punta Cana, Dominican Republic\"\\n}\\n', description='MULTILEXNPRM is a new benchmark dataset for multilingual lexical normalization\\nincluding 12 language variants,\\nwe here specifically work on the Indonisian-english language.\\n', homepage='https://bitbucket.org/robvanderg/multilexnorm/src/master/', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nergrit_ner_source', version=1.0.0, data_dir=None, data_files=None, description='NERGrit source schema', schema='source', subset_id='nergrit_ner'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nergrit_sentiment_source', version=1.0.0, data_dir=None, data_files=None, description='NERGrit source schema', schema='source', subset_id='nergrit_sentiment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nergrit_statement_source', version=1.0.0, data_dir=None, data_files=None, description='NERGrit source schema', schema='source', subset_id='nergrit_statement'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nerp_source', version=1.0.0, data_dir=None, data_files=None, description='NERP source schema', schema='source', subset_id='nerp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/netifier/netifier.py', dataset_name='netifier', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='netifier_source', version=1.0.0, data_dir=None, data_files=None, description='Netifier source schema', schema='source', subset_id='netifier'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='', description='Netifier dataset is a collection of scraped posts on famous social media sites in Indonesia,\\nsuch as Instagram, Twitter, and Kaskus aimed to do multi-label toxicity classification.\\nThe dataset consists of 7,773 texts. The author manually labelled ~7k samples into 4 categories:\\npornography, hate speech, racism, and radicalism.\\n', homepage='https://github.com/ahmadizzan/netifier', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='News En-Id source schema', schema='source', subset_id='news_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed source schema for Aceh language', schema='source', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed source schema for Banjar language', schema='source', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed source schema for Bugis language', schema='source', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ace source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ban source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bjn source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bug source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for eng source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for ind source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for jav source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for mad source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for min source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for nij source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for sun source language and  bbc target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  ace target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  ban target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  bjn target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  bug target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  eng target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  ind target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  jav target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  mad target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  min target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  nij target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for bbc source language and  sun target language', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with source schema for all 132 language pairs', schema='source', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ace language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ban language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bjn language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bug language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for eng language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ind language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for jav language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for mad language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for min language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for nij language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for sun language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bbc language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for all 12 languages', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ojw/ojw.py', dataset_name='ojw', tasks=[], languages=['kaw'], config=NusantaraConfig(name='ojw_source', version=1.0.0, data_dir=None, data_files=None, description='ojw source schema', schema='source', subset_id='ojw'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{moeljadi-aminullah-2020-building,\\n    title = \"Building the Old {J}avanese {W}ordnet\",\\n    author = \"Moeljadi, David  and\\n      Aminullah, Zakariya Pamuji\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.lrec-1.359\",\\n    pages = \"2940--2946\",\\n    abstract = \"This paper discusses the construction and the ongoing development of the Old Javanese Wordnet.\\n     The words were extracted from the digitized version of the Old Javanese{--}English Dictionary (Zoetmulder, 1982).\\n     The wordnet is built using the {`}expansion{\\'} approach (Vossen, 1998), leveraging on the Princeton Wordnet{\\'}s\\n     core synsets and semantic hierarchy, as well as scientific names. The main goal of our project was to produce a\\n     high quality, human-curated resource. As of December 2019, the Old Javanese Wordnet contains 2,054 concepts or\\n     synsets and 5,911 senses. It is released under a Creative Commons Attribution 4.0 International License\\n     (CC BY 4.0). We are still developing it and adding more synsets and senses. We believe that the lexical data\\n     made available by this wordnet will be useful for a variety of future uses such as the development of Modern\\n     Javanese Wordnet and many language processing tasks and linguistic research on Javanese.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='This dataset contains Old Javanese written language aimed to build a machine readable sources for Old Javanese: providing a wordnet for the language (Moeljadi et. al., 2020).\\n', homepage='https://github.com/davidmoeljadi/OJW', license='Creative Commons Attribution 4.0 International (CC BY 4.0)')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/paracotta_id/paracotta_id.py', dataset_name='paracotta_id', tasks=[<Tasks.PARAPHRASING: 'PARA'>], languages=['ind'], config=NusantaraConfig(name='paracotta_id_source', version=1.0.0, data_dir=None, data_files=None, description='paracotta_id source schema', schema='source', subset_id='paracotta_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{aji2022paracotta,\\n  title={ParaCotta: Synthetic Multilingual Paraphrase Corpora from the Most Diverse Translation Sample Pair},\\n  author={Aji, Alham Fikri and Fatyanosa, Tirana Noor and Prasojo, Radityo Eko and Arthur, Philip and Fitriany, Suci and Qonitah, Salma and Zulfa, Nadhifa and Santoso, Tomi and Data, Mahendra},\\n  journal={arXiv preprint arXiv:2205.04651},\\n  year={2022}\\n}\\n', description='ParaCotta is a synthetic parallel paraphrase corpus across 17 languages: Arabic, Catalan, Czech, German, English, Spanish, Estonian, French, Hindi, Indonesian, Italian, Dutch, Ro- manian, Russian, Swedish, Vietnamese, and Chinese.\\n', homepage='https://github.com/afaji/paracotta-paraphrase', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/parallel_su_id/parallel_su_id.py', dataset_name='parallel_su_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'sun'], config=NusantaraConfig(name='parallel_su_id_source', version=1.0.0, data_dir=None, data_files=None, description='Parallel Su-Id source schema', schema='source', subset_id='parallel_su_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{7437678,\\n  author={Suryani, Arie Ardiyanti and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n  booktitle={2015 International Conference on Information Technology Systems and Innovation (ICITSI)}, \\n  title={Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian}, \\n  year={2015},\\n  volume={},\\n  number={},\\n  pages={1-6},\\n  doi={10.1109/ICITSI.2015.7437678}}\\n', description='This data contains 3616 lines of Sundanese sentences taken from the online Sundanese language magazine Mangle, West Java Dakwah Council, and Balebat, and translated into Indonesian by several students of the Sundanese language study program UPI Bandung.\\n', homepage='https://dataverse.telkomuniversity.ac.id/dataset.xhtml?persistentId=doi:10.34820/FK2/HDYWXW', license='Creative Commons CC0 - No Rights Reserved')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/pos_sun_mono/pos_sun_mono.py', dataset_name='pos_sun_mono', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['sun'], config=NusantaraConfig(name='pos_sun_mono_source', version=1.1.0, data_dir=None, data_files=None, description='pos_sun_mono source schema', schema='source', subset_id='pos_sun_mono'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@data{FK2/VTAHRH_2022,\\n    author = {ARDIYANTI SURYANI, ARIE and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n    publisher = {Telkom University Dataverse},\\n    title = {{PoSTagged Sundanese Monolingual Corpus}},\\n    year = {2022},\\n    version = {DRAFT VERSION},\\n    doi = {10.34820/FK2/VTAHRH},\\n    url = {https://doi.org/10.34820/FK2/VTAHRH}\\n}\\n\\n@INPROCEEDINGS{7437678,\\n  author={Suryani, Arie Ardiyanti and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n  booktitle={2015 International Conference on Information Technology Systems and Innovation (ICITSI)},\\n  title={Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian},\\n  year={2015},\\n  volume={},\\n  number={},\\n  pages={1-6},\\n  doi={10.1109/ICITSI.2015.7437678}\\n}\\n', description='This dataset contains 3616 lines of Sundanese sentences taken from several online magazines (Mangle, Dewan Dakwah Jabar, and Balebat). Annotated with PoS Labels by several undergraduates of the Sundanese Language Education Study Program (PPBS), UPI Bandung.\\n', homepage='https://dataverse.telkomuniversity.ac.id/dataset.xhtml?persistentId=doi:10.34820/FK2/VTAHRH', license='CC0 - \"Public Domain Dedication\"')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/posp/posp.py', dataset_name='posp', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='posp_source', version=1.0.0, data_dir=None, data_files=None, description='POSP source schema', schema='source', subset_id='posp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/sentiment_nathasa_review/sentiment_nathasa_review.py', dataset_name='sentiment_nathasa_review', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='sentiment_nathasa_review_source', version=1.0.0, data_dir=None, data_files=None, description='sentiment_nathasa_review source schema', schema='source', subset_id='sentiment_nathasa_review'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nurlaila2018classification,\\n  title={CLASSIFICATION OF CUSTOMERS EMOTION USING NA{\"I}VE BAYES CLASSIFIER (Case Study: Natasha Skin Care)},\\n  author={Nurlaila, Afifah and Wiranto, Wiranto and Saptono, Ristu},\\n  journal={ITSMART: Jurnal Teknologi dan Informasi},\\n  volume={6},\\n  number={2},\\n  pages={92--97},\\n  year={2018}\\n}\\n', description='Customer Review (Natasha Skincare) is a customers emotion dataset, with amounted to 19,253 samples with the division for each class is 804 joy, 43 surprise, 154 anger, 61 fear, 287 sad, 167 disgust, and 17736 no-emotions.\\n', homepage='https://jurnal.uns.ac.id/itsmart/article/viewFile/17328/15082', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='singgalang_source', version=1.0.0, data_dir=None, data_files=None, description='singgalang source schema', schema='source', subset_id='singgalang'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='smsa_source', version=1.0.0, data_dir=None, data_files=None, description='SMSA source schema', schema='source', subset_id='smsa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/squad_id/squad_id.py', dataset_name='squad_id', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='squad_id_source', version=1.0.0, data_dir=None, data_files=None, description='SQUAD_ID source schema', schema='source', subset_id='squad_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{muis2020sequence,\\n  title={Sequence-to-sequence learning for indonesian automatic question generator},\\n  author={Muis, Ferdiant Joshua and Purwarianti, Ayu},\\n  booktitle={2020 7th International Conference on Advance Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='    This dataset contains Indonesian SQuAD v2.0 dataset (Google-translated).\\n    The dataset can be used for automatic question generation (AQG),\\n    or machine reading comphrehension(MRC) task.\\n', homepage='https://github.com/FerdiantJoshua/question-generator', license='TBD')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks=[<Tasks.PARAPHRASING: 'PARA'>], languages=['ind'], config=NusantaraConfig(name='stif_indonesia_source', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia source schema', schema='source', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_emot/su_emot.py', dataset_name='su_emot', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['sun'], config=NusantaraConfig(name='su_emot_source', version=1.0.0, data_dir=None, data_files=None, description='Sundanese Twitter Dataset for Emotion source schema', schema='source', subset_id='su_emot'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n9297929,  \\nauthor={Putra, Oddy Virgantara and Wasmanson, Fathin Muhammad and Harmini, Triana and Utama, Shoffin Nahwa},  \\nbooktitle={2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)},   \\ntitle={Sundanese Twitter Dataset for Emotion Classification},   \\nyear={2020},  \\nvolume={},  \\nnumber={},  \\npages={391--395},  \\ndoi={10.1109/CENIM51130.2020.9297929}\\n}\\n', description='This is a dataset for emotion classification of Sundanese text. The dataset is gathered from Twitter API between January and March 2019 with 2518 tweets in total. \\nThe tweets filtered by using some hashtags which are represented Sundanese emotion, for instance, #persib, #corona, #saredih, #nyakakak, #garoblog, #sangsara, #gumujeng, #bungah, #sararieun, #ceurik, and #hariwang. \\nThis dataset contains four distinctive emotions: anger, joy, fear, and sadness. Each tweet is annotated using related emotion. For data\\nvalidation, the authors consulted a Sundanese language teacher for expert validation.\\n', homepage='https://github.com/virgantara/sundanese-twitter-dataset', license='UNKNOWN')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_id_asr/su_id_asr.py', dataset_name='su_id_asr', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['sun'], config=NusantaraConfig(name='su_id_asr_source', version=1.0.0, data_dir=None, data_files=None, description='SU_ID_ASR source schema', schema='source', subset_id='su_id_asr'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='Sundanese ASR training data set containing ~220K utterances.\\nThis dataset was collected by Google in Indonesia.\\n\\n\\n', homepage='https://indonlp.github.io/nusa-catalogue/card.html?su_id_asr', license='Attribution-ShareAlike 4.0 International.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_id_tts/su_id_tts.py', dataset_name='su_id_tts', tasks=[<Tasks.TEXT_TO_SPEECH: 'TTS'>], languages=['sun'], config=NusantaraConfig(name='su_id_tts_source', version=1.0.0, data_dir=None, data_files=None, description='SU_ID_TTS source schema', schema='source', subset_id='su_id_tts'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='This data set contains high-quality transcribed audio data for Sundanese. The data set consists of wave files, and a TSV file. The file line_index.tsv contains a filename and the transcription of audio in the file. Each filename is prepended with a speaker identification number.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Universitas Pendidikan Indonesia.\\n', homepage='http://openslr.org/44/', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for eng source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for ind source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for jpn source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for kor source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for myn source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for tha source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_zsm_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for vie source language and  zsm target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_eng_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  eng target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_ind_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  ind target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_jpn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  jpn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_kor_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  kor target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_myn_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  myn target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_tha_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  tha target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_vie_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for zsm source language and  vie target language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_source', version=1.0.0, data_dir=None, data_files=None, description='talpco with source schema for all 7 language pairs from / to ind language', schema='source', subset_id='talpco'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id source schema', schema='source', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks=[<Tasks.KEYWORD_TAGGING: 'KT'>], languages=['ind'], config=NusantaraConfig(name='term_a_source', version=1.0.0, data_dir=None, data_files=None, description='TermA source schema', schema='source', subset_id='term_a'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for default language pair (eng-ind)', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_ara_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-ara language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_spa_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-spa language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_fra_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-fra language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_hin_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-hin language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_por_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-por language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_rus_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-rus language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_zho_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-zho language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_eng_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ind-eng language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ara_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for ara-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_spa_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for spa-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_fra_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for fra-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_hin_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for hin-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_por_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for por-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_rus_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for rus-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_zho_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for zho-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_eng_ind_source', version=1.0.0, data_dir=None, data_files=None, description='tico_19 source schema for eng-ind language pair', schema='source', subset_id='tico_19'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='titml_idn_source', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN source schema', schema='source', subset_id='titml_idn'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/toxicity_200/toxicity_200.py', dataset_name='toxicity_200', tasks=[], languages=['ind', 'ace', 'bjn', 'bug', 'jav'], config=NusantaraConfig(name='toxicity_200_ind_source', version=1.0.0, data_dir=None, data_files=None, description='toxicity 200 with source schema for Indonesia language', schema='source', subset_id='toxicity_200'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='Toxicity-200 is a wordlist to detect toxicity in 200 languages. It contains files that include frequent words and phrases generally considered toxic because they represent: 1) frequently used profanities; 2) frequently used insults and hate speech terms, or language used to bully, denigrate, or demean; 3) pornographic terms; and 4) terms for body parts associated with sexual activity.\\n', homepage='https://github.com/facebookresearch/flores/blob/main/toxicity', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/toxicity_200/toxicity_200.py', dataset_name='toxicity_200', tasks=[], languages=['ind', 'ace', 'bjn', 'bug', 'jav'], config=NusantaraConfig(name='toxicity_200_ace_source', version=1.0.0, data_dir=None, data_files=None, description='toxicity 200 with source schema for Aceh language', schema='source', subset_id='toxicity_200'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='Toxicity-200 is a wordlist to detect toxicity in 200 languages. It contains files that include frequent words and phrases generally considered toxic because they represent: 1) frequently used profanities; 2) frequently used insults and hate speech terms, or language used to bully, denigrate, or demean; 3) pornographic terms; and 4) terms for body parts associated with sexual activity.\\n', homepage='https://github.com/facebookresearch/flores/blob/main/toxicity', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/toxicity_200/toxicity_200.py', dataset_name='toxicity_200', tasks=[], languages=['ind', 'ace', 'bjn', 'bug', 'jav'], config=NusantaraConfig(name='toxicity_200_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='toxicity 200 with source schema for Banjar language', schema='source', subset_id='toxicity_200'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='Toxicity-200 is a wordlist to detect toxicity in 200 languages. It contains files that include frequent words and phrases generally considered toxic because they represent: 1) frequently used profanities; 2) frequently used insults and hate speech terms, or language used to bully, denigrate, or demean; 3) pornographic terms; and 4) terms for body parts associated with sexual activity.\\n', homepage='https://github.com/facebookresearch/flores/blob/main/toxicity', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/toxicity_200/toxicity_200.py', dataset_name='toxicity_200', tasks=[], languages=['ind', 'ace', 'bjn', 'bug', 'jav'], config=NusantaraConfig(name='toxicity_200_bug_source', version=1.0.0, data_dir=None, data_files=None, description='toxicity 200 with source schema for Bugis language', schema='source', subset_id='toxicity_200'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='Toxicity-200 is a wordlist to detect toxicity in 200 languages. It contains files that include frequent words and phrases generally considered toxic because they represent: 1) frequently used profanities; 2) frequently used insults and hate speech terms, or language used to bully, denigrate, or demean; 3) pornographic terms; and 4) terms for body parts associated with sexual activity.\\n', homepage='https://github.com/facebookresearch/flores/blob/main/toxicity', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/toxicity_200/toxicity_200.py', dataset_name='toxicity_200', tasks=[], languages=['ind', 'ace', 'bjn', 'bug', 'jav'], config=NusantaraConfig(name='toxicity_200_jav_source', version=1.0.0, data_dir=None, data_files=None, description='toxicity 200 with source schema for Java language', schema='source', subset_id='toxicity_200'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='Toxicity-200 is a wordlist to detect toxicity in 200 languages. It contains files that include frequent words and phrases generally considered toxic because they represent: 1) frequently used profanities; 2) frequently used insults and hate speech terms, or language used to bully, denigrate, or demean; 3) pornographic terms; and 4) terms for body parts associated with sexual activity.\\n', homepage='https://github.com/facebookresearch/flores/blob/main/toxicity', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tydiqa_id/tydiqa_id.py', dataset_name='tydiqa_id', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='tydiqa_id_source', version=1.0.0, data_dir=None, data_files=None, description='TyDiQA Id source schema', schema='source', subset_id='tydiqa_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{clark-etal-2020-tydi,\\n    title = \"{T}y{D}i {QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages\",\\n    author = \"Clark, Jonathan H.  and\\n      Choi, Eunsol  and\\n      Collins, Michael  and\\n      Garrette, Dan  and\\n      Kwiatkowski, Tom  and\\n      Nikolaev, Vitaly  and\\n      Palomaki, Jennimaria\",\\n    journal = \"Transactions of the Association for Computational Linguistics\",\\n    volume = \"8\",\\n    year = \"2020\",\\n    address = \"Cambridge, MA\",\\n    publisher = \"MIT Press\",\\n    url = \"https://aclanthology.org/2020.tacl-1.30\",\\n    doi = \"10.1162/tacl_a_00317\",\\n    pages = \"454--470\",\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\"\\n}\\n', description='TyDiQA dataset is collected from Wikipedia articles with human-annotated question and answer pairs covering 11 languages. \\nThe question-answer pairs are collected for each language without using translation services.\\nIndoNLG uses the Indonesian data from the secondary Gold passage task of the original TyDiQA dataset and\\nrandomly split off 15% of the training data and use it as the test set.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ud_id_csui/ud_id_csui.py', dataset_name='ud_id_csui', tasks=[<Tasks.DEPENDENCY_PARSING: 'DEP'>, <Tasks.MACHINE_TRANSLATION: 'MT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='ud_id_csui_source', version=1.0.0, data_dir=None, data_files=None, description='ud_id_csui source schema', schema='source', subset_id='ud_id_csui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article {10.3844/jcssp.2020.1585.1597,\\nauthor = {Alfina, Ika and Budi, Indra and Suhartanto, Heru},\\ntitle = {Tree Rotations for Dependency Trees: Converting the Head-Directionality of Noun Phrases},\\narticle_type = {journal},\\nvolume = {16},\\nnumber = {11},\\nyear = {2020},\\nmonth = {Nov},\\npages = {1585-1597},\\ndoi = {10.3844/jcssp.2020.1585.1597},\\nurl = {https://thescipub.com/abstract/jcssp.2020.1585.1597},\\njournal = {Journal of Computer Science},\\npublisher = {Science Publications}\\n}\\n', description='UD Indonesian-CSUI is a conversion from an Indonesian constituency treebank in the Penn Treebank format named Kethu that was also a conversion from a constituency treebank built by Dinakaramani et al. (2015).\\nThis treebank is named after the place where treebanks were built: Faculty of Computer Science (CS), Universitas Indonesia (UI).\\n\\nAbout this treebank:\\n- Genre is news in formal Indonesian (the majority is economic news)\\n- 1030 sentences (28K words) divided into testing and training dataset of around 10K words and around 18K words respectively.\\n- Average of 27.4 words per-sentence.\\n', homepage='https://github.com/UniversalDependencies/UD_Indonesian-CSUI', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/unimorph_id/unimorph_id.py', dataset_name='unimorph_id', tasks=[<Tasks.MORPHOLOGICAL_INFLECTION: 'MOR'>], languages=['ind'], config=NusantaraConfig(name='unimorph_id_source', version=1.0.0, data_dir=None, data_files=None, description='unimorph_id source schema', schema='source', subset_id='unimorph_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{pimentel-ryskina-etal-2021-sigmorphon,\\n    title = \"SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages\",\\n    author = \"Pimentel, Tiago  and\\n      Ryskina, Maria  and\\n      Mielke, Sabrina J.  and\\n      Wu, Shijie  and\\n      Chodroff, Eleanor  and\\n      Leonard, Brian  and\\n      Nicolai, Garrett  and\\n      Ghanggo Ate, Yustinus  and\\n      Khalifa, Salam  and\\n      Habash, Nizar  and\\n      El-Khaissi, Charbel  and\\n      Goldman, Omer  and\\n      Gasser, Michael  and\\n      Lane, William  and\\n      Coler, Matt  and\\n      Oncevay, Arturo  and\\n      Montoya Samame, Jaime Rafael  and\\n      Silva Villegas, Gema Celeste  and\\n      Ek, Adam  and\\n      Bernardy, Jean-Philippe  and\\n      Shcherbakov, Andrey  and\\n      Bayyr-ool, Aziyana  and\\n      Sheifer, Karina  and\\n      Ganieva, Sofya  and\\n      Plugaryov, Matvey  and\\n      Klyachko, Elena  and\\n      Salehi, Ali  and\\n      Krizhanovsky, Andrew  and\\n      Krizhanovsky, Natalia  and\\n      Vania, Clara  and\\n      Ivanova, Sardana  and\\n      Salchak, Aelita  and\\n      Straughn, Christopher  and\\n      Liu, Zoey  and\\n      Washington, Jonathan North  and\\n      Ataman, Duygu  and\\n      Kiera{\\'s}, Witold  and\\n      Woli{\\'n}ski, Marcin  and\\n      Suhardijanto, Totok  and\\n      Stoehr, Niklas  and\\n      Nuriah, Zahroh  and\\n      Ratan, Shyam  and\\n      Tyers, Francis M.  and\\n      Ponti, Edoardo M.  and\\n      Aiton, Grant  and\\n      Hatcher, Richard J.  and\\n      Prud\\'hommeaux, Emily  and\\n      Kumar, Ritesh  and\\n      Hulden, Mans  and\\n      Barta, Botond  and\\n      Lakatos, Dorina  and\\n      Szolnok, G{\\'a}bor  and\\n      {\\'A}cs, Judit  and\\n      Raj, Mohit  and\\n      Yarowsky, David  and\\n      Cotterell, Ryan  and\\n      Ambridge, Ben  and\\n      Vylomova, Ekaterina\",\\n    booktitle = \"Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.sigmorphon-1.25\",\\n    doi = \"10.18653/v1/2021.sigmorphon-1.25\",\\n    pages = \"229--259\"\\n}', description='The UniMorph project, Indonesian chapter.\\nDue to sparsity of UniMorph original parsing, raw source is used instead.\\nOriginal parsing can be found on https://huggingface.co/datasets/universal_morphologies/blob/2.3.2/universal_morphologies.py\\n', homepage='https://github.com/unimorph/ind', license='Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for eng language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ind language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for jav language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for min language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for sun language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ace language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for mly language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for map_bms language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikilingua/wikilingua.py', dataset_name='wikilingua', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='wikilingua_source', version=1.0.0, data_dir=None, data_files=None, description='wikilingua source schema', schema='source', subset_id='wikilingua'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{\\n    ladhak-wiki-2020,\\n    title={WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\\n    author={Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\\n    booktitle={Findings of EMNLP, 2020},\\n    year={2020}\\n}\\n', description='We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of crosslingual abstractive \\nsummarization systems. We extract article and summary pairs in 18 languages from WikiHow12, a high quality, \\ncollaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard \\narticle summary alignments across languages by aligning the images that are used to describe each how-to step in an \\narticle.\\n', homepage='https://github.com/esdurmus/Wikilingua', license='CC-BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wrete/wrete.py', dataset_name='wrete', tasks=[<Tasks.TEXTUAL_ENTAILMENT: 'TE'>], languages=['ind'], config=NusantaraConfig(name='wrete_source', version=1.0.0, data_dir=None, data_files=None, description='WReTe source schema', schema='source', subset_id='wrete'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='WReTe, The Wiki Revision Edits Textual Entailment dataset (Setya and Mahendra, 2018) consists of 450 sentence pairs constructed from Wikipedia revision history. The dataset contains pairs of sentences and binary semantic relations between the pairs. The data are labeled as entailed when the meaning of the second sentence can be derived from the first one, and not entailed otherwise\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/x_fact/x_fact.py', dataset_name='x_fact', tasks=[<Tasks.FACT_CHECKING: 'FCT'>], languages=['ara', 'aze', 'ben', 'deu', 'spa', 'fas', 'fra', 'guj', 'hin', 'ind', 'ita', 'kat', 'mar', 'nor', 'nld', 'pan', 'pol', 'por', 'ron', 'rus', 'sin', 'srp', 'sqi', 'tam', 'tur'], config=NusantaraConfig(name='x_fact_source', version=1.0.0, data_dir=None, data_files=None, description='x_fact source schema', schema='source', subset_id='x_fact'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{gupta2021xfact,\\n      title={{X-FACT: A New Benchmark Dataset for Multilingual Fact Checking}},\\n      author={Gupta, Ashim and Srikumar, Vivek},\\n      booktitle = \"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\",\\n      month = jul,\\n      year = \"2021\",\\n      address = \"Online\",\\n      publisher = \"Association for Computational Linguistics\",\\n}\\n', description='X-FACT: the largest publicly available multilingual dataset for factual verification of naturally existing realworld claims.\\n', homepage='https://github.com/utahnlp/x-fact', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xcopa/xcopa.py', dataset_name='xcopa', tasks=[<Tasks.QUESTION_ANSWERING: 'QA'>], languages=['ind'], config=NusantaraConfig(name='xcopa_source', version=1.0.0, data_dir=None, data_files=None, description='XCOPA source schema', schema='source', subset_id='xcopa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@inproceedings{ponti2020xcopa,\\n  title={{XCOPA: A} Multilingual Dataset for Causal Commonsense Reasoning},\\n  author={Edoardo M. Ponti, Goran Glava\\x0b{s}, Olga Majewska, Qianchu Liu, Ivan Vuli'{c} and Anna Korhonen},\\n  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\\n  year={2020},\\n  url={https://ducdauge.github.io/files/xcopa.pdf}\\n}\\n@inproceedings{roemmele2011choice,\\n  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},\\n  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},\\n  booktitle={2011 AAAI Spring Symposium Series},\\n  year={2011},\\n  url={https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF},\\n}\\n\", description='  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\\nthe globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages. All the details about the\\ncreation of XCOPA and the implementation of the baselines are available in the paper.\\n', homepage='https://github.com/cambridgeltl/xcopa', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_source', version=2.0.0, data_dir=None, data_files=None, description='xl_sum source schema', schema='source', subset_id='xl_sum'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xpersona_id/xpersona_id.py', dataset_name='xpersona_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='xpersona_id_source', version=1.0.0, data_dir=None, data_files=None, description='XPersona ID source schema', schema='source', subset_id='xpersona_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{lin2020xpersona,\\n  title={XPersona: Evaluating multilingual personalized chatbot},\\n  author={Lin, Zhaojiang and Liu, Zihan and Winata, Genta Indra and Cahyawijaya, Samuel and Madotto, Andrea and Bang, Yejin and Ishii, Etsuko and Fung, Pascale},\\n  journal={arXiv preprint arXiv:2003.07568},\\n  year={2020}\\n}\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\"\\n}\\n', description='XPersona is a multi-lingual extension of Persona-Chat. \\nXPersona dataset includes persona conversations in six different languages other than English for building and evaluating multilingual personalized agents.\\n', homepage='', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xsid/xsid.py', dataset_name='xsid', tasks=[<Tasks.INTENT_CLASSIFICATION: 'INT'>, <Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='xsid_source', version=0.3.0, data_dir=None, data_files=None, description='xSID source schema', schema='source', subset_id='xsid'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='0.3.0', citation='@inproceedings{van-der-goot-etal-2020-cross,\\n      title={From Masked-Language Modeling to Translation: Non-{E}nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding},\\n      author={van der Goot, Rob and Sharaf, Ibrahim and Imankulova, Aizhan and {\"U}st{\"u}n, Ahmet and Stepanovic, Marija and Ramponi, Alan and Khairunnisa, Siti Oryza and Komachi, Mamoru and Plank, Barbara},\\n    booktitle = \"Proceedings of the 2021 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\\n    year = \"2021\",\\n    address = \"Mexico City, Mexico\",\\n    publisher = \"Association for Computational Linguistics\"\\n}\\n', description='XSID is a new benchmark for cross-lingual (X) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect.\\n', homepage='https://bitbucket.org/robvanderg/xsid/src/master/', license='CC-BY-SA 4.0')\n",
      "Nusantara datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset for Javanese and Indonesian translation generated from the verse-aligned Bible parallel corpus with the same split setting. In terms of size, both the Su ↔ Id and Jv ↔ Id datasets are much smaller compared to the En ↔ Id dataset, because there are Bible chapters for which translations are available for Indonesian, albeit not for the local languages.', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/casa/casa.py', dataset_name='casa', tasks=set(), languages=['ind'], config=NusantaraConfig(name='casa_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='CASA Nusantara schema', schema='nusantara_text_multi', subset_id='casa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@INPROCEEDINGS{8629181,\\n    author={Ilmania, Arfinda and Abdurrahman and Cahyawijaya, Samuel and Purwarianti, Ayu},\\n    booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n    title={Aspect Detection and Sentiment Classification Using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis},\\n    year={2018},\\n    volume={},\\n    number={},\\n    pages={62-67},\\n    doi={10.1109/IALP.2018.8629181\\n}\\n', description='\\nCASA: An aspect-based sentiment analysis dataset consisting of around a thousand car reviews collected from multiple Indonesian online automobile platforms (Ilmania et al., 2018).\\nThe dataset covers six aspects of car quality.\\nWe define the task to be a multi-label classification task,\\nwhere each label represents a sentiment for a single aspect with three possible values: positive, negative, and neutral.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for ind language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for jav language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for sun language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/code_mixed_jv_id/code_mixed_jv_id.py', dataset_name='code_mixed_jv_id', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['jav', 'ind'], config=NusantaraConfig(name='code_mixed_jv_id_jv_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='code_mixed_jv_id nusantara_text schema for Javanese', schema='nusantara_text', subset_id='code_mixed_jv'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{Tho_2021,\\n  doi = {10.1088/1742-6596/1869/1/012084},\\n  url = {https://doi.org/10.1088/1742-6596/1869/1/012084},\\n  year = 2021,\\n  month = {apr},\\n  publisher = {{IOP} Publishing},\\n  volume = {1869},\\n  number = {1},\\n  pages = {012084},\\n  author = {C Tho and Y Heryadi and L Lukas and A Wibowo},\\n  title = {Code-mixed sentiment analysis of Indonesian language and Javanese language using Lexicon based approach},\\n  journal = {Journal of Physics: Conference Series},\\n  abstract = {Nowadays mixing one language with another language either in\\n  spoken or written communication has become a common practice for bilingual\\n  speakers in daily conversation as well as in social media. Lexicon based\\n  approach is one of the approaches in extracting the sentiment analysis. This\\n  study is aimed to compare two lexicon models which are SentiNetWord and VADER\\n  in extracting the polarity of the code-mixed sentences in Indonesian language\\n  and Javanese language. 3,963 tweets were gathered from two accounts that\\n  provide code-mixed tweets. Pre-processing such as removing duplicates,\\n  translating to English, filter special characters, transform lower case and\\n  filter stop words were conducted on the tweets. Positive and negative word\\n  score from lexicon model was then calculated using simple mathematic formula\\n  in order to classify the polarity. By comparing with the manual labelling,\\n  the result showed that SentiNetWord perform better than VADER in negative\\n  sentiments. However, both of the lexicon model did not perform well in\\n  neutral and positive sentiments. On overall performance, VADER showed better\\n  performance than SentiNetWord. This study showed that the reason for the\\n  misclassified was that most of Indonesian language and Javanese language\\n  consist of words that were considered as positive in both Lexicon model.}\\n}\\n', description='Sentiment analysis and machine translation data for Javanese and Indonesian.\\n', homepage='https://iopscience.iop.org/article/10.1088/1742-6596/1869/1/012084', license='cc_by_3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/code_mixed_jv_id/code_mixed_jv_id.py', dataset_name='code_mixed_jv_id', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['jav', 'ind'], config=NusantaraConfig(name='code_mixed_jv_id_id_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='code_mixed_jv_id nusantara_text schema for Indonesian', schema='nusantara_text', subset_id='code_mixed_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{Tho_2021,\\n  doi = {10.1088/1742-6596/1869/1/012084},\\n  url = {https://doi.org/10.1088/1742-6596/1869/1/012084},\\n  year = 2021,\\n  month = {apr},\\n  publisher = {{IOP} Publishing},\\n  volume = {1869},\\n  number = {1},\\n  pages = {012084},\\n  author = {C Tho and Y Heryadi and L Lukas and A Wibowo},\\n  title = {Code-mixed sentiment analysis of Indonesian language and Javanese language using Lexicon based approach},\\n  journal = {Journal of Physics: Conference Series},\\n  abstract = {Nowadays mixing one language with another language either in\\n  spoken or written communication has become a common practice for bilingual\\n  speakers in daily conversation as well as in social media. Lexicon based\\n  approach is one of the approaches in extracting the sentiment analysis. This\\n  study is aimed to compare two lexicon models which are SentiNetWord and VADER\\n  in extracting the polarity of the code-mixed sentences in Indonesian language\\n  and Javanese language. 3,963 tweets were gathered from two accounts that\\n  provide code-mixed tweets. Pre-processing such as removing duplicates,\\n  translating to English, filter special characters, transform lower case and\\n  filter stop words were conducted on the tweets. Positive and negative word\\n  score from lexicon model was then calculated using simple mathematic formula\\n  in order to classify the polarity. By comparing with the manual labelling,\\n  the result showed that SentiNetWord perform better than VADER in negative\\n  sentiments. However, both of the lexicon model did not perform well in\\n  neutral and positive sentiments. On overall performance, VADER showed better\\n  performance than SentiNetWord. This study showed that the reason for the\\n  misclassified was that most of Indonesian language and Javanese language\\n  consist of words that were considered as positive in both Lexicon model.}\\n}\\n', description='Sentiment analysis and machine translation data for Javanese and Indonesian.\\n', homepage='https://iopscience.iop.org/article/10.1088/1742-6596/1869/1/012084', license='cc_by_3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/code_mixed_jv_id/code_mixed_jv_id.py', dataset_name='code_mixed_jv_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['jav', 'ind'], config=NusantaraConfig(name='code_mixed_jv_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='code_mixed_jv_id nusantara_t2t schema for Javanese and Indonesian', schema='nusantara_t2t', subset_id='code_mixed_jv_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{Tho_2021,\\n  doi = {10.1088/1742-6596/1869/1/012084},\\n  url = {https://doi.org/10.1088/1742-6596/1869/1/012084},\\n  year = 2021,\\n  month = {apr},\\n  publisher = {{IOP} Publishing},\\n  volume = {1869},\\n  number = {1},\\n  pages = {012084},\\n  author = {C Tho and Y Heryadi and L Lukas and A Wibowo},\\n  title = {Code-mixed sentiment analysis of Indonesian language and Javanese language using Lexicon based approach},\\n  journal = {Journal of Physics: Conference Series},\\n  abstract = {Nowadays mixing one language with another language either in\\n  spoken or written communication has become a common practice for bilingual\\n  speakers in daily conversation as well as in social media. Lexicon based\\n  approach is one of the approaches in extracting the sentiment analysis. This\\n  study is aimed to compare two lexicon models which are SentiNetWord and VADER\\n  in extracting the polarity of the code-mixed sentences in Indonesian language\\n  and Javanese language. 3,963 tweets were gathered from two accounts that\\n  provide code-mixed tweets. Pre-processing such as removing duplicates,\\n  translating to English, filter special characters, transform lower case and\\n  filter stop words were conducted on the tweets. Positive and negative word\\n  score from lexicon model was then calculated using simple mathematic formula\\n  in order to classify the polarity. By comparing with the manual labelling,\\n  the result showed that SentiNetWord perform better than VADER in negative\\n  sentiments. However, both of the lexicon model did not perform well in\\n  neutral and positive sentiments. On overall performance, VADER showed better\\n  performance than SentiNetWord. This study showed that the reason for the\\n  misclassified was that most of Indonesian language and Javanese language\\n  consist of words that were considered as positive in both Lexicon model.}\\n}\\n', description='Sentiment analysis and machine translation data for Javanese and Indonesian.\\n', homepage='https://iopscience.iop.org/article/10.1088/1742-6596/1869/1/012084', license='cc_by_3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks={<Tasks.SPEECH_TO_TEXT_TRANSLATION: 'STTT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_ind_eng_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for nusantara_sptext from ind to eng', schema='nusantara_sptext', subset_id='co_vo_st2_ind_eng'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks={<Tasks.SPEECH_TO_TEXT_TRANSLATION: 'STTT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_eng_ind_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for nusantara_sptext from eng to ind', schema='nusantara_sptext', subset_id='co_vo_st2_eng_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_ind_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for nusantara_t2t from ind to eng', schema='nusantara_t2t', subset_id='co_vo_st2_ind_eng'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/covost2/covost2.py', dataset_name='covost2', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='covost2_eng_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='covost2 source schema for nusantara_t2t from eng to ind', schema='nusantara_t2t', subset_id='co_vo_st2_eng_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@article{wang2020covost,\\n  title={Covost 2 and massively multilingual speech-to-text translation},\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  journal={arXiv preprint arXiv:2007.10310},\\n  year={2020}\\n}\\n\\n@inproceedings{wang21s_interspeech,\\n  author={Wang, Changhan and Wu, Anne and Pino, Juan},\\n  title={{CoVoST 2 and Massively Multilingual Speech Translation}},\\n  year=2021,\\n  booktitle={Proc. Interspeech 2021},\\n  pages={2247--2251},\\n  url={https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech}\\n  doi={10.21437/Interspeech.2021-2027}\\n}\\n', description=\"CoVoST2 is a large-scale multilingual speech translation corpus covering translations from 21 languages to English\\nand from English into 15 languages. The dataset is created using Mozilla's open-source Common Voice database of\\ncrowdsourced voice recordings. There are 2,900 hours of speech represented in the corpus.\\n\", homepage='https://huggingface.co/datasets/covost2', license='CC BY-NC 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cvss/cvss.py', dataset_name='cvss', tasks={<Tasks.SPEECH_TO_SPEECH_TRANSLATION: 'S2ST'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='cvss_c_nusantara_s2s', version=1.0.0, data_dir=None, data_files=None, description=\"CVSS Nusantara schema, all translation speeches are in a single canonical speaker's voice.\", schema='nusantara_s2s', subset_id='cvss_c'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='S2S', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{jia2022cvss,\\n    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},\\n    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},\\n    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},\\n    pages={6691--6703},\\n    year={2022}\\n}\\n', description='CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\\ncovering sentence-level parallel speech-to-speech translation pairs from 21\\nlanguages into English.\\n', homepage='https://github.com/google-research-datasets/cvss', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/cvss/cvss.py', dataset_name='cvss', tasks={<Tasks.SPEECH_TO_SPEECH_TRANSLATION: 'S2ST'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='cvss_t_nusantara_s2s', version=1.0.0, data_dir=None, data_files=None, description='CVSS Nusantara schema, translation speeches are in voices transferred from the corresponding source speeches', schema='nusantara_s2s', subset_id='cvss_t'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='S2S', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{jia2022cvss,\\n    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},\\n    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},\\n    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},\\n    pages={6691--6703},\\n    year={2022}\\n}\\n', description='CVSS is a massively multilingual-to-English speech-to-speech translation corpus,\\ncovering sentence-level parallel speech-to-speech translation pairs from 21\\nlanguages into English.\\n', homepage='https://github.com/google-research-datasets/cvss', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emot/emot.py', dataset_name='emot', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emot_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmoT Nusantara schema', schema='nusantara_text', subset_id='emot'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emotcmt_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT Nusantara schema', schema='nusantara_text', subset_id='emotcmt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/emotion_id_opinion/emotion_id_opinion.py', dataset_name='emotion_id_opinion', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emotion_id_opinion_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmoIdOpinion Nusantara schema', schema='nusantara_text', subset_id='emotion_id_opinion'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@article{RICCOSAN2022108465,\\ntitle = {Emotion dataset from Indonesian public opinion},\\njournal = {Data in Brief},\\nvolume = {43},\\npages = {108465},\\nyear = {2022},\\nissn = {2352-3409},\\ndoi = {https://doi.org/10.1016/j.dib.2022.108465},\\nurl = {https://www.sciencedirect.com/science/article/pii/S2352340922006588},\\nauthor = { Riccosan and Karen Etania Saputra and Galih Dea Pratama and Andry Chowanda},\\nkeywords = {Emotion classification, Dataset, Tweet, Indonesia},\\nabstract = {An opinion is a type of judgment or a person's point of view about something. Twitter is a popular social media platform that includes a lot of public opinions and would be a suitable location to mine data in text form. With its vast population and active Twitter user base, Indonesia has the potential to be a source of opinion data mining. An opinion may be processed and result in the form of a person's emotional response towards something, such as whether they like, hate, love, or are happy about it. Upon that basis, a dataset of Indonesian-language tweets conveying public opinion on various topics was formed. The fact that there are only limited publicly available emotions text datasets in the Indonesian language supports our basis in this research to form our emotion dataset. The gathered data was cleaned and normalized in the pre-processing stage to the necessary form for study on the task of classifying emotions in Indonesian. The data collected is annotated with six emotional labels: anger, fear, joy, love, sad, and neutral.}\\n}\\n\", description=\"Emotion ID Opinion is a dataset of Indonesian-language tweets conveying public opinion on a variety of topics.\\nIt comtains 7080 indunesian tweets and a person's emotion response towards each tweet.\\nThe data is annotated with six emotional labels, namely anger, fear, joy, love, sad, and neutral.\\n\", homepage='https://github.com/Ricco48/Emotion-Dataset-from-Indonesian-Public-Opinion', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/facqa/facqa.py', dataset_name='facqa', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='facqa_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='FacQA Nusantara schema', schema='nusantara_qa', subset_id='facqa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@inproceedings{purwarianti2007machine,\\n  title={A Machine Learning Approach for Indonesian Question Answering System},\\n  author={Ayu Purwarianti, Masatoshi Tsuchiya, and Seiichi Nakagawa},\\n  booktitle={Proceedings of Artificial Intelligence and Applications },\\n  pages={573--578},\\n  year={2007}\\n}\\n', description='\\nFacQA: The goal of the FacQA dataset is to find the answer to a question from a provided short passage from a news article.\\nEach row in the FacQA dataset consists of a question, a short passage, and a label phrase, which can be found inside the\\ncorresponding short passage. There are six categories of questions: date, location, name,\\norganization, person, and quantitative.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/hoasa/hoasa.py', dataset_name='hoasa', tasks=set(), languages=['ind'], config=NusantaraConfig(name='hoasa_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='HoASA Nusantara schema', schema='nusantara_text_multi', subset_id='hoasa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n@inproceedings{azhar2019multi,\\n  title={Multi-label Aspect Categorization with Convolutional Neural Networks and Extreme Gradient Boosting},\\n  author={A. N. Azhar, M. L. Khodra, and A. P. Sutiono}\\n  booktitle={Proceedings of the 2019 International Conference on Electrical Engineering and Informatics (ICEEI)},\\n  pages={35--40},\\n  year={2019}\\n}\\n', description='\\nHoASA: An aspect-based sentiment analysis dataset consisting of hotel reviews collected from the hotel aggregator platform, AiryRooms.\\nThe dataset covers ten different aspects of hotel quality. Similar to the CASA dataset, each review is labeled with a single sentiment label for each aspect.\\nThere are four possible sentiment classes for each sentiment label:\\npositive, negative, neutral, and positive-negative.\\nThe positivenegative label is given to a review that contains multiple sentiments of the same aspect but for different objects (e.g., cleanliness of bed and toilet).\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_abusive_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive Nusantara schema', schema='nusantara_text', subset_id='id_abusive'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_abusive_news_comment/id_abusive_news_comment.py', dataset_name='id_abusive_news_comment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_abusive_news_comment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Abusive Online News Comment Nusantara schema', schema='nusantara_text', subset_id='id_abusive_news_comment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{9034620,  author={Kiasati Desrul, Dhamir Raniah and Romadhony, Ade},  booktitle={2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)},   title={Abusive Language Detection on Indonesian Online News Comments},   year={2019},  volume={},  number={},  pages={320-325},  doi={10.1109/ISRITI48646.2019.9034620}}\\n', description=\"Abusive language is an expression used by a person with insulting delivery of any person's aspect.\\nIn the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse.\\nAn abusive language detection system is important to prevent the negative effect of such comments.\\nThis dataset contains 3184 samples of Indonesian online news comments with 3 labels.\\n\", homepage='https://github.com/dhamirdesrul/Indonesian-Online-News-Comments', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_clickbait_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID Nusantara schema', schema='nusantara_text', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_frog_story/id_frog_story.py', dataset_name='id_frog_story', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='id_frog_story_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='IdFrogStory Nusantara schema', schema='nusantara_ssp', subset_id='id_frog_story'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{FrogStorytelling,\\n  author=\"Moeljadi, David\",\\n  title=\"Usage of Indonesian Possessive Verbal Predicates : A Statistical Analysis Based on Storytelling Survey\",\\n  journal=\"Tokyo University Linguistic Papers\",\\n  ISSN=\"1345-8663\",\\n  publisher=\"東京大学大学院人文社会系研究科・文学部言語学研究室\",\\n  year=\"2014\",\\n  month=\"sep\",\\n  volume=\"35\",\\n  number=\"\",\\n  pages=\"155-176\",\\n  URL=\"https://ci.nii.ac.jp/naid/120005525793/en/\",\\n  DOI=\"info:doi/10.15083/00027472\",\\n}\\n', description='Indonesian Frog Storytelling Corpus\\nIndonesian written and spoken corpus, based on the twenty-eight pictures. (http://compling.hss.ntu.edu.sg/who/david/corpus/pictures.pdf)\\n', homepage='https://github.com/matbahasa/corpus-frog-storytelling', license='Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_google_play_review/id_google_play_review.py', dataset_name='id_google_play_review', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_google_play_review_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='id_google_play_review Nusantara schema, 1-5 stars rating only (for pos/neg labels, please use the subset_id \"id_google_play_review_posneg\")', schema='nusantara_text', subset_id='id_google_play_review'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={Jakartaresearch/google-play-review · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/jakartaresearch/google-play-review},\\n   author={Research, Jakarta AI}\\n} \\n', description='Indonesian Google Play Review, dataset scrapped from e-commerce app on Google Play for sentiment analysis.\\nTotal number of data: 10041 (train: 7028, validation: 3012). Provided by Jakarta AI Research.\\n', homepage='https://github.com/jakartaresearch/hf-datasets/tree/main/google-play-review/google-play-review', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_google_play_review/id_google_play_review.py', dataset_name='id_google_play_review', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_google_play_review_posneg_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='id_google_play_review Nusantara schema, pos/neg label only', schema='nusantara_text', subset_id='id_google_play_review_posneg'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={Jakartaresearch/google-play-review · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/jakartaresearch/google-play-review},\\n   author={Research, Jakarta AI}\\n} \\n', description='Indonesian Google Play Review, dataset scrapped from e-commerce app on Google Play for sentiment analysis.\\nTotal number of data: 10041 (train: 7028, validation: 3012). Provided by Jakarta AI Research.\\n', homepage='https://github.com/jakartaresearch/hf-datasets/tree/main/google-play-review/google-play-review', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_hatespeech_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech Nusantara schema', schema='nusantara_text', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hoax_news/id_hoax_news.py', dataset_name='id_hoax_news', tasks={<Tasks.HOAX_NEWS_CLASSIFICATION: 'HNC'>}, languages=['ind'], config=NusantaraConfig(name='id_hoax_news_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Hoax News Nusantara schema', schema='nusantara_text', subset_id='id_hoax_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8265649,  author={Pratiwi, Inggrid Yanuar Risca and Asmara, Rosa Andrie and Rahutomo, Faisal},  booktitle={2017 11th International Conference on Information & Communication Technology and System (ICTS)},   title={Study of hoax news detection using naïve bayes classifier in Indonesian language},   year={2017},  volume={},  number={},  pages={73-78},  doi={10.1109/ICTS.2017.8265649}}\\n', description='This research proposes to build an automatic hoax news detection and collects 250 pages of hoax and valid news articles in Indonesian language.\\nEach data sample is annotated by three reviewers and the final taggings are obtained by voting of those three reviewers.\\n', homepage='https://data.mendeley.com/datasets/p3hfgr5j3m/1', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_hsd_nofaaulia/id_hsd_nofaaulia.py', dataset_name='id_hsd_nofaaulia', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_hsd_nofaaulia_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='id_hsd_nofaaulia Nusantara schema', schema='nusantara_text', subset_id='id_hsd_nofaaulia'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@inproceedings{10.1145/3330482.3330491,\\nauthor = {Aulia, Nofa and Budi, Indra},\\ntitle = {Hate Speech Detection on Indonesian Long Text Documents Using Machine Learning Approach},\\nyear = {2019},\\nisbn = {9781450361064},\\npublisher = {Association for Computing Machinery},\\naddress = {New York, NY, USA},\\nurl = {https://doi.org/10.1145/3330482.3330491},\\ndoi = {10.1145/3330482.3330491},\\nabstract = {Due to the growth of hate speech on social media in recent years, it is important to understand this issue. An automatic hate speech detection system is needed to help to counter this problem. There have been many studies on detecting hate speech in short documents like Twitter data. But to our knowledge, research on long documents is rare, we suppose that the difficulty is increasing due to the possibility of the message of the text may be hidden. In this research, we explore in detecting hate speech on Indonesian long documents using machine learning approach. We build a new Indonesian hate speech dataset from Facebook. The experiment showed that the best performance obtained by Support Vector Machine (SVM) as its classifier algorithm using TF-IDF, char quad-gram, word unigram, and lexicon features that yield f1-score of 85%.},\\nbooktitle = {Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence},\\npages = {164–169},\\nnumpages = {6},\\nkeywords = {machine learning, SVM, long documents, hate speech detection},\\nlocation = {Bali, Indonesia},\\nseries = {ICCAI '19}\\n}\\n\", description='There have been many studies on detecting hate speech in short documents like Twitter data. But to our knowledge, research on long documents is rare, we suppose that the difficulty is increasing due to the possibility of the message of the text may be hidden. In this research, we explore in detecting hate speech on Indonesian long documents using machine learning approach. We build a new Indonesian hate speech dataset from Facebook.\\n', homepage='https://dl.acm.org/doi/10.1145/3330482.3330491', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=set(), languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS Nusantara schema', schema='nusantara_text_multi', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT Nusantara schema', schema='nusantara_t2t', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_qqp/id_qqp.py', dataset_name='id_qqp', tasks={<Tasks.PARAPHRASING: 'PARA'>}, languages=['ind'], config=NusantaraConfig(name='id_qqp_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='ID QQP Nusantara schema', schema='nusantara_t2t', subset_id='id_qqp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{quoraFirstQuora,\\n\\tauthor = {},\\n\\ttitle = {{F}irst {Q}uora {D}ataset {R}elease: {Q}uestion {P}airs --- quoradata.quora.com},\\n\\thowpublished = {https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs},\\n\\tyear = 2017,\\n\\tnote = {Online},\\n}\\n', description='Quora Question Pairs (QQP) dataset consists of over 400,000 question pairs, \\nand each question pair is annotated with a binary value indicating whether \\nthe two questions are paraphrase of each other. This dataset is translated \\nversion of QQP to Indonesian Language.\\n', homepage='https://github.com/louisowen6/quora_paraphrasing_id', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_short_answer_grading/id_short_answer_grading.py', dataset_name='id_short_answer_grading', tasks=set(), languages=['ind'], config=NusantaraConfig(name='id_short_answer_grading_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='id_short_answer_grading Nusantara schema', schema='nusantara_pairs', subset_id='id_short_answer_grading'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{\\n    JLK,\\n    author = {Muh Haidir and Ayu Purwarianti},\\n    title = { Short Answer Grading Using Contextual Word Embedding and Linear Regression},\\n    journal = {Jurnal Linguistik Komputasional},\\n    volume = {3},\\n    number = {2},\\n    year = {2020},\\n    keywords = {},\\n    abstract = {Abstract—One of the obstacles in an efficient MOOC is the evaluation of student answers, including the short answer grading which requires large effort from instructors to conduct it manually.\\n                Thus, NLP research in short answer grading has been conducted in order to support the automation, using several techniques such as rule\\n                and machine learning based. Here, we’ve conducted experiments on deep learning based short answer grading to compare the answer\\n                representation and answer assessment method. In the answer representation, we compared word embedding and sentence embedding models\\n                such as BERT, and its modification. In the answer assessment method, we use linear regression. There are 2 datasets that we used, available\\n                English short answer grading dataset with 80 questions and 2442 to get the best configuration for model and Indonesian short answer grading\\n                dataset with 36 questions and 9165 short answers as testing data. Here, we’ve collected Indonesian short answers for Biology and Geography\\n                subjects from 534 respondents where the answer grading was done by 7 experts. The best root mean squared error for both dataset was achieved\\n                by using BERT pretrained, 0.880 for English dataset dan 1.893 for Indonesian dataset.},\\n    issn = {2621-9336},\\tpages = {54--61},\\tdoi = {10.26418/jlk.v3i2.38},\\n    url = {https://inacl.id/journal/index.php/jlk/article/view/38}\\n}', description='Indonesian short answers for Biology and Geography subjects from 534 respondents where the answer grading was done by 7 experts.', homepage='https://github.com/AgeMagi/tugas-akhir', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_stance/id_stance.py', dataset_name='id_stance', tasks={<Tasks.TEXTUAL_ENTAILMENT: 'TE'>}, languages=['ind'], config=NusantaraConfig(name='id_stance_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='IdStance Nusantara schema', schema='nusantara_pairs', subset_id='id_stance'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629144,  \\n  author={R. {Jannati} and R. {Mahendra} and C. W. {Wardhana} and M. {Adriani}},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  title={Stance Classification Towards Political Figures on Blog Writing},\\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={96-101},\\n}\\n', description=\"Stance Classification Towards Political Figures on Blog Writing.\\nThis dataset contains dataset from the second research, which is combined from the first research and new dataset.\\nThe dataset consist of 337 data, about five target and every target have 1 different event.\\nTwo label are used: 'For' and 'Againts'.\\n1. For - the text that is created by author is support the target in an event\\n2. Against - the text that is created by author is oppose the target in an event\\n\", homepage='https://github.com/reneje/id_stance_dataset_article-Stance-Classification-Towards-Political-Figures-on-Blog-Writing', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_sts/id_sts.py', dataset_name='id_sts', tasks=set(), languages=['ind'], config=NusantaraConfig(name='id_sts_nusantara_pairs_score', version=1.0.0, data_dir=None, data_files=None, description='ID_STS Nusantara schema', schema='nusantara_pairs_score', subset_id='id_sts'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n', description='SemEval is a series of international natural language processing (NLP) research workshops whose mission is\\nto advance the current state of the art in semantic analysis and to help create high-quality annotated datasets in a\\nrange of increasingly challenging problems in natural language semantics. This is a translated version of SemEval Dataset\\nfrom 2012-2016 for Semantic Textual Similarity Task to Indonesian language.\\n', homepage='https://github.com/ahmadizzan/sts-indo', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_jav_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel  Nusantara schema for jav to ind and ind to jav', schema='nusantara_t2t', subset_id='id_wiki_parallel_jav_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_min_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel  Nusantara schema for min to ind and ind to min', schema='nusantara_t2t', subset_id='id_wiki_parallel_min_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/id_wiki_parallel/id_wiki_parallel.py', dataset_name='id_wiki_parallel', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'min', 'sun'], config=NusantaraConfig(name='id_wiki_parallel_sun_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='ID Wiki Parallel  Nusantara schema for sun to ind and ind to sun', schema='nusantara_t2t', subset_id='id_wiki_parallel_sun_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n7065828,\\nauthor={Trisedya, Bayu Distiawan and Inastra, Dyah},\\nbooktitle={2014 International Conference on Advanced Computer Science and Information System},\\ntitle={Creating Indonesian-Javanese parallel corpora using wikipedia articles},\\nyear={2014},\\nvolume={},\\nnumber={},\\npages={239-245},\\ndoi={10.1109/ICACSIS.2014.7065828}}\\n', description='This dataset is designed for machine translation task, specifically jav->ind, min->ind, sun->ind, and vice versa. The data are taken\\nfrom sentences in Wikipedia.\\n\\n(from the publication abstract)\\nParallel corpora are necessary for multilingual researches especially in information retrieval (IR) and natural language processing (NLP). However, such corpora are hard to find, specifically for low-resources languages like ethnic\\nlanguages. Parallel corpora of ethnic languages were usually collected manually. On the other hand, Wikipedia as a free online encyclopedia is supporting more and more languages each year, including ethnic languages in Indonesia. It has\\nbecome one of the largest multilingual sites in World Wide Web that provides free distributed articles. In this paper, we explore a few sentence alignment methods which have been used before for another domain. We want to check whether\\nWikipedia can be used as one of the resources for collecting parallel corpora of Indonesian and Javanese, an ethnic language in Indonesia. We used two approaches of sentence alignment by treating Wikipedia as both parallel corpora and\\ncomparable corpora. In parallel corpora case, we used sentence length based and word correspondence methods. Meanwhile,\\nwe used the characteristics of hypertext links from Wikipedia in comparable corpora case. After the experiments, we can\\nsee that Wikipedia is useful enough for our purpose because both approaches gave positive results.\\n', homepage='https://github.com/dindainastra/indowikiparalelcorpora', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Identic Nusantara schema', schema='nusantara_t2t', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Identic Nusantara schema', schema='nusantara_seq_label', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_raw_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC raw source schema', schema='nusantara_t2t', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_tokenized_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC tokenized source schema', schema='nusantara_t2t', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_noclitic_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC noclitic source schema', schema='nusantara_t2t', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_en_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC en source schema', schema='nusantara_seq_label', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/identic/identic.py', dataset_name='identic', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='identic_id_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='IDENTIC id source schema', schema='nusantara_seq_label', subset_id='identic'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{larasati-2012-identic,\\n    title = \"{IDENTIC} Corpus: Morphologically Enriched {I}ndonesian-{E}nglish Parallel Corpus\",\\n    author = \"Larasati, Septina Dian\",\\n    booktitle = \"Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}\\'12)\",\\n    month = may,\\n    year = \"2012\",\\n    address = \"Istanbul, Turkey\",\\n    publisher = \"European Language Resources Association (ELRA)\",\\n    url = \"http://www.lrec-conf.org/proceedings/lrec2012/pdf/644_Paper.pdf\",\\n    pages = \"902--906\",\\n    abstract = \"This paper describes the creation process of an Indonesian-English parallel corpus (IDENTIC).\\n    The corpus contains 45,000 sentences collected from different sources in different genres.\\n    Several manual text preprocessing tasks, such as alignment and spelling correction, are applied to the corpus\\n    to assure its quality. We also apply language specific text processing such as tokenization on both sides and\\n    clitic normalization on the Indonesian side. The corpus is available in two different formats: \\x91plain\\',\\n    stored in text format and \\x91morphologically enriched\\', stored in CoNLL format. Some parts of the corpus are\\n    publicly available at the IDENTIC homepage.\",\\n}\\n', description='IDENTIC is an Indonesian-English parallel corpus for research purposes.\\nThe corpus is a bilingual corpus paired with English. The aim of this work is to build and provide\\nresearchers a proper Indonesian-English textual data set and also to promote research in this language pair.\\nThe corpus contains texts coming from different sources with different genres.\\nAdditionally, the corpus contains tagged texts that follows MorphInd tagset (Larasati et. al., 2011).\\n', homepage='https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-BF85-F', license='CC BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='idk_mrc_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC with nusantara_qa schema', schema='nusantara_qa', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_trans_squad_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (trans_squad) with nusantara_qa schema', schema='nusantara_qa', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_tydiqa_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (tydiqa) with nusantara_qa schema', schema='nusantara_qa', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_model_gen_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (model_gen) with nusantara_qa schema', schema='nusantara_qa', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idk_mrc/idk_mrc.py', dataset_name='idk_mrc', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='idk_mrc_baseline_human_filt_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='IDK-MRC baseline (human_filt) with nusantara_qa schema', schema='nusantara_qa', subset_id='idk_mrc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{putri2022idk,\\n    doi = {10.48550/ARXIV.2210.13778},\\n    url = {https://arxiv.org/abs/2210.13778},\\n    author = {Putri, Rifki Afina and Oh, Alice},\\n    title = {IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension},\\n    publisher = {arXiv},\\n    year = {2022}\\n}\\n\\n', description='I(n)dontKnow-MRC (IDK-MRC) is an Indonesian Machine Reading Comprehension dataset that covers\\nanswerable and unanswerable questions. Based on the combination of the existing answerable questions in TyDiQA,\\nthe new unanswerable question in IDK-MRC is generated using a question generation model and human-written question.\\nEach paragraph in the dataset has a set of answerable and unanswerable questions with the corresponding answer.\\n\\nBesides IDK-MRC (idk_mrc) dataset, several baseline datasets also provided:\\n1. Trans SQuAD (trans_squad): machine translated SQuAD 2.0 (Muis and Purwarianti, 2020)\\n2. TyDiQA (tydiqa): Indonesian answerable questions set from the TyDiQA-GoldP (Clark et al., 2020)\\n3. Model Gen (model_gen): TyDiQA + the unanswerable questions output from the question generation model\\n4. Human Filt (human_filt): Model Gen dataset that has been filtered by human annotator\\n', homepage='https://github.com/rifkiaputri/IDK-MRC', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI Nusantara schema', schema='nusantara_seq_label', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/imdb_jv/imdb_jv.py', dataset_name='imdb_jv', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='imdb_jv_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='imdb_jv Nusantara schema', schema='nusantara_text', subset_id='imdb_jv'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wongso2021causal,\\n  title={Causal and masked language modeling of Javanese language using transformer-based architectures},\\n  author={Wongso, Wilson and Setiawan, David Samuel and Suhartono, Derwin},\\n  booktitle={2021 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={1--7},\\n  year={2021},\\n  organization={IEEE}\\n}\\n', description='Javanese Imdb Movie Reviews Dataset is a Javanese version of the IMDb Movie Reviews dataset by translating the original English dataset to Javanese.\\n', homepage='https://huggingface.co/datasets/w11wo/imdb-javanese', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo4b/indo4b.py', dataset_name='indo4b', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='indo4b_nusantara_ssp', version='1.0.0', data_dir=None, data_files=None, description='Indo4B Nusantara schema', schema='nusantara_ssp', subset_id='indo4b'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @inproceedings{wilie-etal-2020-indonlu,\\n        title = \"{I}ndo{NLU}: Benchmark and Resources for Evaluating {I}ndonesian \\n            Natural Language Understanding\",\\n        author = \"Wilie, Bryan  and\\n          Vincentio, Karissa  and\\n          Winata, Genta Indra  and\\n          Cahyawijaya, Samuel  and\\n          Li, Xiaohong  and\\n          Lim, Zhi Yuan  and\\n          Soleman, Sidik  and\\n          Mahendra, Rahmad  and\\n          Fung, Pascale  and\\n          Bahar, Syafri  and\\n          Purwarianti, Ayu\",\\n        booktitle = \"Proceedings of the 1st Conference of the Asia-Pacific Chapter of the \\n                Association for Computational Linguistics and the 10th International Joint \\n                Conference on Natural Language Processing\",\\n        month = dec,\\n        year = \"2020\",\\n        address = \"Suzhou, China\",\\n        publisher = \"Association for Computational Linguistics\",\\n        url = \"https://aclanthology.org/2020.aacl-main.85\",\\n        pages = \"843--857\",\\n        abstract = \"Although Indonesian is known to be the fourth most frequently used language \\n            over the internet, the research progress on this language in natural language processing (NLP) \\n            is slow-moving due to a lack of available resources. In response, we introduce the first-ever vast \\n            resource for training, evaluation, and benchmarking on Indonesian natural language understanding \\n            (IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence classification to \\n            pair-sentences sequence labeling with different levels of complexity. The datasets for the tasks \\n            lie in different domains and styles to ensure task diversity. We also provide a set of Indonesian \\n            pre-trained models (IndoBERT) trained from a large and clean Indonesian dataset (Indo4B) collected \\n            from publicly available sources such as social media texts, blogs, news, and websites. \\n            We release baseline models for all twelve tasks, as well as the framework for benchmark evaluation, \\n            thus enabling everyone to benchmark their system performances.\",\\n    }\\n', description='    Indo4B is a large-scale Indonesian self-supervised pre-training corpus\\n    consists of around 3.6B words, with around 250M sentences. The corpus\\n    covers both formal and colloquial Indonesian sentences compiled from \\n    12 sources, of which two cover Indonesian colloquial language, eight\\n    cover formal Indonesian language, and the rest have a mixed style of\\n    both colloquial and formal.\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo4b_plus/indo4b_plus.py', dataset_name='indo4b_plus', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'sun', 'jav'], config=NusantaraConfig(name='indo4b_plus_nusantara_ssp', version='1.0.0', data_dir=None, data_files=None, description='Indo4B-Plus Nusantara schema', schema='nusantara_ssp', subset_id='indo4b_plus'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @inproceedings{cahyawijaya-etal-2021-indonlg,\\n        title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n        author = \"Cahyawijaya, Samuel  and\\n          Winata, Genta Indra  and\\n          Wilie, Bryan  and\\n          Vincentio, Karissa  and\\n          Li, Xiaohong  and\\n          Kuncoro, Adhiguna  and\\n          Ruder, Sebastian  and\\n          Lim, Zhi Yuan  and\\n          Bahar, Syafri  and\\n          Khodra, Masayu  and\\n          Purwarianti, Ayu  and\\n          Fung, Pascale\",\\n        booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n        month = nov,\\n        year = \"2021\",\\n        address = \"Online and Punta Cana, Dominican Republic\",\\n        publisher = \"Association for Computational Linguistics\",\\n        url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n        doi = \"10.18653/v1/2021.emnlp-main.699\",\\n        pages = \"8875--8898\",\\n        abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress \\n        and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource \\n        languages poses a challenging barrier for building NLG systems that work well for languages with limited \\n        amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG)\\n        progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. \\n        Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important \\n        use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, \\n        and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, \\n        Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. \\n        We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth\\n        the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes \\n        the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference \\n        at very low-resource languages like Javanese and Sundanese.\",\\n    }\\n', description='    Indo4B-Plus is an extension of Indo4B, a large-scale Indonesian self-supervised pre-training corpus. \\n    Indo4B-Plus extend Indo4B by adding two low-resource Indonesian local languages to the corpus, i.e., Sundanese and Javanese.\\n    Indo4B-Plus adds 82,582,025 words (∼2.07%) of Sundanese sentences and 331,041,877 words (∼8.29%) of Javanese\\n', homepage='https://github.com/IndoNLP/indonlu', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT Nusantara schema', schema='nusantara_t2t', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_law/indo_law.py', dataset_name='indo_law', tasks={<Tasks.LEGAL_CLASSIFICATION: 'LC'>}, languages=['ind'], config=NusantaraConfig(name='indo_law_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Indo-Law Nusantara schema', schema='nusantara_text', subset_id='indo_law'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nuranti2022predicting,\\n  title={Predicting the Category and the Length of Punishment in Indonesian Courts Based on Previous Court Decision Documents},\\n  author={Nuranti, Eka Qadri and Yulianti, Evi and Husin, Husna Sarirah},\\n  journal={Computers},\\n  volume={11},\\n  number={6},\\n  pages={88},\\n  year={2022},\\n  publisher={Multidisciplinary Digital Publishing Institute}\\n}\\n', description='This study presents predictions of first-level judicial decisions by utilizing a collection of Indonesian court decision documents. \\nWe propose using multi-level learning, namely, CNN+attention, using decision document sections as features to predict the category and the length of punishment in Indonesian courts. \\nOur results demonstrate that the decision document sections that strongly affected the accuracy of the prediction model were prosecution history, facts, legal facts, and legal considerations.\\n', homepage='', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_puisi/indo_puisi.py', dataset_name='indo_puisi', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='indo_puisi_nusantara_ssp', version='1.0.0', data_dir=None, data_files=None, description='Indo puisi Nusantara schema', schema='nusantara_ssp', subset_id='indo_puisi'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='\\n', description='Puisi is an Indonesian poetic form. The dataset was collected by scraping various websites. It contains 7223 Indonesian puisi along with the title and author.\\n', homepage='https://github.com/ilhamfp/puisi-pantun-generator', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=set(), languages=['ind'], config=NusantaraConfig(name='indocollex_nusantara_pairs_multi', version=1.0.0, data_dir=None, data_files=None, description='indocollex Nusantara schema', schema='nusantara_pairs_multi', subset_id='indocollex'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=set(), languages=['ind'], config=NusantaraConfig(name='indocollex_f2i_nusantara_pairs_multi', version=1.0.0, data_dir=None, data_files=None, description='indocollex Nusantara schema', schema='nusantara_pairs_multi', subset_id='indocollex_f2i'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocollex/indocollex.py', dataset_name='indocollex', tasks=set(), languages=['ind'], config=NusantaraConfig(name='indocollex_i2f_nusantara_pairs_multi', version=1.0.0, data_dir=None, data_files=None, description='indocollex Nusantara schema', schema='nusantara_pairs_multi', subset_id='indocollex_i2f'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo-etal-2021-indocollex,\\n    title = \"{I}ndo{C}ollex: A Testbed for Morphological Transformation of {I}ndonesian Word Colloquialism\",\\n    author = {Wibowo, Haryo Akbarianto  and Nityasya, Made Nindyatama  and Aky{\"u}rek, Afra Feyza  and Fitriany, Suci  and Aji, Alham Fikri  and Prasojo, Radityo Eko  and Wijaya, Derry Tanti},\\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.findings-acl.280\",\\n    doi = \"10.18653/v1/2021.findings-acl.280\",\\n    pages = \"3170--3183\",\\n}', description='IndoCollex: A Testbed for Morphological Transformation of Indonesian Colloquial Words\\n', homepage='https://github.com/haryoa/indo-collex', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks={<Tasks.COREFERENCE_RESOLUTION: 'COREF'>}, languages=['ind'], config=NusantaraConfig(name='indocoref_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='Indocoref Nusantara schema', schema='nusantara_kb', subset_id='indocoref'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks={<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ntp_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP Nusantara schema', schema='nusantara_pairs', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment Nusantara schema', schema='nusantara_text', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks={<Tasks.SENTENCE_ORDERING: 'SO'>}, languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_gsd/indolem_ud_id_gsd.py', dataset_name='indolem_ud_id_gsd', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_gsd_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='indolem_ud_id_gsd Nusantara KB schema', schema='nusantara_kb', subset_id='indolem_ud_id_gsd'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mcdonald-etal-2013-universal,\\n    title = \"{U}niversal {D}ependency Annotation for Multilingual Parsing\",\\n    author = {McDonald, Ryan  and\\n      Nivre, Joakim  and\\n      Quirmbach-Brundage, Yvonne  and\\n      Goldberg, Yoav  and\\n      Das, Dipanjan  and\\n      Ganchev, Kuzman  and\\n      Hall, Keith  and\\n      Petrov, Slav  and\\n      Zhang, Hao  and\\n      T{\"a}ckstr{\"o}m, Oscar  and\\n      Bedini, Claudia  and\\n      Bertomeu Castell{\\'o}, N{\\'u}ria  and\\n      Lee, Jungmee},\\n    booktitle = \"Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\\n    month = aug,\\n    year = \"2013\",\\n    address = \"Sofia, Bulgaria\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/P13-2017\",\\n    pages = \"92--97\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='The Indonesian-GSD treebank consists of 5598 sentences and 122k words split into train/dev/test of 97k/12k/11k words.\\nThe treebank was originally converted from the content head version of the universal dependency treebank v2.0 (legacy) in 2015.In order to comply with the latest Indonesian annotation guidelines, the treebank has undergone a major revision between UD releases v2.8 and v2.9 (2021).\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud default fold ('0') of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_0_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '0' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_1_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '1' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_2_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '2' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_3_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '3' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_4_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '4' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonesian_wsd/indonesian_wsd.py', dataset_name='indonesian_wsd', tasks={<Tasks.WORD_SENSE_DISAMBIGUATION: 'WSD'>}, languages=['ind'], config=NusantaraConfig(name='indonesian_wsd_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Indonesian WSD Nusantara schema', schema='nusantara_t2t', subset_id='indonesian_wsd'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mahendra-etal-2018-cross,\\n    title = \"Cross-Lingual and Supervised Learning Approach for {I}ndonesian Word Sense Disambiguation Task\",\\n    author = \"Mahendra, Rahmad  and\\n      Septiantri, Heninggar  and\\n      Wibowo, Haryo Akbarianto  and\\n      Manurung, Ruli  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 9th Global Wordnet Conference\",\\n    month = jan,\\n    year = \"2018\",\\n    address = \"Nanyang Technological University (NTU), Singapore\",\\n    publisher = \"Global Wordnet Association\",\\n    url = \"https://aclanthology.org/2018.gwc-1.28\",\\n    pages = \"245--250\",\\n    abstract = \"Ambiguity is a problem we frequently face in Natural Language Processing. Word Sense Disambiguation (WSD) is a task to determine the correct sense of an ambiguous word. However, research in WSD for Indonesian is still rare to find. The availability of English-Indonesian parallel corpora and WordNet for both languages can be used as training data for WSD by applying Cross-Lingual WSD method. This training data is used as an input to build a model using supervised machine learning algorithms. Our research also examines the use of Word Embedding features to build the WSD model.\",\\n}\\n', description='Word Sense Disambiguation (WSD) is a task to determine the correct sense of an ambiguous word.\\nThe training data was collected from news websites and manually annotated. The words in training data were processed using the morphological analysis to obtain lemma.\\nThe features being used were some words around the target word (including the words before and after the target word), the nearest verb from the\\ntarget word, the transitive verb around the target word, and the document context. \\n', homepage='https://github.com/rmahendra/Indonesian-WSD', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks={<Tasks.TEXTUAL_ENTAILMENT: 'TE'>}, languages=['ind'], config=NusantaraConfig(name='indonli_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='indonli Nusantara schema', schema='nusantara_pairs', subset_id='indonli'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonlu_nergrit/indonlu_nergrit.py', dataset_name='indonlu_nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indonlu_nergrit_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='IndoNLU NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='indonlu_nergrit'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n@online{nergrit2019,\\n  title={NERGrit Corpus},\\n  author={NERGrit Developers},\\n  year={2019},\\n  url={https://github.com/grit-id/nergrit-corpus}\\n}\\n', description='This NER dataset is taken from the Grit-ID repository, and the labels are spans in IOB chunking representation.\\nThe dataset consists of three kinds of named entity tags, PERSON (name of person), PLACE (name of location), and\\nORGANIZATION (name of organization).\\n', homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold0_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold1_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold2_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold3_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold4_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indotacos/indotacos.py', dataset_name='indotacos', tasks={<Tasks.TAX_COURT_VERDICT: 'TACOS'>}, languages=['ind'], config=NusantaraConfig(name='indotacos_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='IndoTacos Nusantara schema', schema='nusantara_text', subset_id='indotacos'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='    @misc{wibisono2022indotacos,\\n        title = {IndoTacos},\\n        howpublished = {\\\\url{https://www.kaggle.com/datasets/christianwbsn/indonesia-tax-court-verdict}},\\n        note = {Accessed: 2022-09-22}\\n    }\\n', description='Predicting the outcome or the probability of winning a legal case has always been highly attractive in legal sciences and practice.\\nHardly any dataset has been developed to analyze and accelerate the research of court verdict analysis.\\nFind out what factor affects the outcome of tax court verdict using Natural Language Processing.\\n', homepage='https://www.kaggle.com/datasets/christianwbsn/indonesia-tax-court-verdict', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indqner/indqner.py', dataset_name='indqner', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indqner_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NER dataset from Indonesian translation Quran Nusantara schema', schema='nusantara_seq_label', subset_id='indqner'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{,\\nauthor = {Ria Hari Gusmita, Asep Fajar Firmansyah, Khodijah Khuliyah},\\ntitle = {{IndQNER: a NER Benchmark Dataset on Indonesian Translation of Quran}},\\nurl = {https://github.com/RiaGusmita/IndQNER},\\nyear = {2022}\\n}\\n', description='IndQNER is a NER dataset created by manually annotating the Indonesian translation of Quran text.\\nThe dataset contains 18 named entity categories as follow:\\n    \"Allah\": Allah (including synonim of Allah such as Yang maha mengetahui lagi mahabijaksana)\\n    \"Throne\": Throne of Allah (such as \\'Arasy)\\n    \"Artifact\": Artifact (such as Ka\\'bah, Baitullah)\\n    \"AstronomicalBody\": Astronomical body (such as bumi, matahari)\\n    \"Event\": Event (such as hari akhir, kiamat)\\n    \"HolyBook\": Holy book (such as AlQur\\'an)\\n    \"Language\": Language (such as bahasa Arab\\n    \"Angel\": Angel (such as Jibril, Mikail)\\n    \"Person\": Person (such as Bani Israil, Fir\\'aun)\\n    \"Messenger\": Messenger (such as Isa, Muhammad, Musa)\\n    \"Prophet\": Prophet (such as Adam, Sulaiman)\\n    \"AfterlifeLocation\": Afterlife location (such as Jahanam, Jahim, Padang Mahsyar)\\n    \"GeographicalLocation\": Geographical location (such as Sinai, negeru Babilonia)\\n    \"Color\": Color (such as kuning tua)\\n    \"Religion\": Religion (such as Islam, Yahudi, Nasrani)\\n    \"Food\": Food (such as manna, salwa)\\n', homepage='https://github.com/RiaGusmita/IndQNER', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_digit_cdsr/indspeech_digit_cdsr.py', dataset_name='indspeech_digit_cdsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_digit_cdsr_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_digit_cdsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_digit_cdsr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n', description='INDspeech_DIGIT_CDSR is the first Indonesian speech dataset for connected digit speech recognition (CDSR). The data was developed by TELKOMRisTI (R&D Division, PT Telekomunikasi Indonesia) in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan and Bandung Institute of Technology (ITB) under the Asia-Pacific Telecommunity (APT) project in 2004 [Sakti et al., 2004]. Although it was originally developed for a telecommunication system for hearing and speaking impaired people, it can be used for other applications, i.e., automatic call centers that recognize telephone numbers.\\n', homepage='https://github.com/s-sakti/data_indsp_digit_cdsr', license='CC-BY-NC-SA-4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_jv_overlap_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_news_ethnicsr_jv_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_su_overlap_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_news_ethnicsr_su_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_jv_nooverlap_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_news_ethnicsr_jv_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_ethnicsr/indspeech_news_ethnicsr.py', dataset_name='indspeech_news_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_ethnicsr_su_nooverlap_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='indspeech_news_ethnicsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_news_ethnicsr_su_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sani-cocosda-2012,\\n    title = \"Towards Language Preservation: Preliminary Collection and Vowel Analysis of {I}ndonesian Ethnic Speech Data\",\\n    author = \"Sani, Auliya and Sakti, Sakriani and Neubig, Graham and Toda, Tomoki and Mulyanto, Adi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2012\",\\n    pages = \"118--122\"\\n    address = \"Macau, China\"\\n}\\n', description='\\nINDspeech_NEWS_EthnicSR is a collection of Indonesian ethnic speech corpora for Javanese and Sundanese for Indonesian ethnic speech recognition. It was developed in 2012 by the Nara Institute of Science and Technology (NAIST, Japan) in collaboration with the Bandung Institute of Technology (ITB, Indonesia) [Sani et al., 2012].\\n', homepage='https://github.com/s-sakti/data_indsp_news_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_lvcsr/indspeech_news_lvcsr.py', dataset_name='indspeech_news_lvcsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_lvcsr_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_lvcsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_news_lvcsr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tcast-2008,\\n    title = \"Development of {I}ndonesian Large Vocabulary Continuous Speech Recognition System within {A-STAR} Project\",\\n    author = \"Sakti, Sakriani and Kelana, Eka and Riza, Hammam and Sakai, Shinsuke and Markov, Konstantin and Nakamura, Satoshi\",\\n    booktitle = \"Proc. IJCNLP Workshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST)\",\\n    year = \"2008\",\\n    pages = \"19--24\"\\n    address = \"Hyderabad, India\"\\n}\\n\\n@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Translating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='This is the first Indonesian speech dataset for large vocabulary continuous speech recognition (LVCSR) with more than 40 hours of speech and 400 speakers [Sakti et al., 2008]. R&D Division of PT Telekomunikasi Indonesia (TELKOMRisTI) developed the data in 2005-2006, in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan, as the continuation of the Asia-Pacific Telecommunity (APT) project [Sakti et al., 2004]. It has also been successfully used for developing Indonesian LVCSR in the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_lvcsr', license='CC BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_12_MOS_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts nusantara_sptext schema for 12 train and MOS test task', schema='nusantara_sptext', subset_id='indspeech_news_tts_12_MOS'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_30_MOS_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts nusantara_sptext schema for 30 train and MOS test task', schema='nusantara_sptext', subset_id='indspeech_news_tts_30_MOS'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_60_MOS_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts nusantara_sptext schema for 60 train and MOS test task', schema='nusantara_sptext', subset_id='indspeech_news_tts_60_MOS'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_120_MOS_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts nusantara_sptext schema for 120 train and MOS test task', schema='nusantara_sptext', subset_id='indspeech_news_tts_120_MOS'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_news_tts/indspeech_news_tts.py', dataset_name='indspeech_news_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_news_tts_ZR_ZR_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_news_tts nusantara_sptext schema for ZR train and ZR test task', schema='nusantara_sptext', subset_id='indspeech_news_tts_ZR_ZR'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tts-cocosda-2008,\\n    title = \"Development of HMM-based Indonesian Speech Synthesis\",\\n    author = \"Sakti, Sakriani and Maia, Ranniery and Sakai, Shinsuke and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2008\",\\n    pages = \"215--220\"\\n    address = \"Kyoto, Japan\"\\n}\\n\\n@inproceedings{sakti-tts-malindo-2010,\\n    title = \"Quality and Intelligibility Assessment of Indonesian HMM-Based Speech Synthesis System\",\\n    author = \"Sakti, Sakriani and Sakai, Shinsuke and Isotani, Ryosuke and Kawai, Hisashi and Nakamura, Satoshi\",\\n    booktitle = \"Proc. MALINDO\",\\n    year = \"2010\",\\n    pages = \"51--57\"\\n    address = \"Jakarta, Indonesia\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='INDspeech_NEWS_TTS is a speech dataset for developing an Indonesian text-to-speech synthesis system. The data was developed by Advanced Telecommunication Research Institute International (ATR) Japan under the the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_news_tts', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_ban_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for BALI language with overlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_ban_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for BALI language with nooverlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_btk_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for BATAK language with overlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_btk_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for BATAK language with nooverlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_jav_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for JAWA language with overlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_jav_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for JAWA language with nooverlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_overlap_sun_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for SUNDA language with overlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_overlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_newstra_ethnicsr/indspeech_newstra_ethnicsr.py', dataset_name='indspeech_newstra_ethnicsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun', 'jav', 'btk', 'ban'], config=NusantaraConfig(name='indspeech_newstra_ethnicsr_nooverlap_sun_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_newstra_ethnicsr nusantara_sptext schema for SUNDA language with nooverlapping dataset', schema='nusantara_sptext', subset_id='indspeech_newstra_ethnicsr_nooverlap'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-cocosda-2013,\\n    title = \"Towards Language Preservation: Design and Collection of Graphemically Balanced and Parallel Speech Corpora of {I}ndonesian Ethnic Languages\",\\n    author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n    booktitle = \"Proc. Oriental COCOSDA\",\\n    year = \"2013\",\\n    address = \"Gurgaon, India\"\\n}\\n\\n@inproceedings{sakti-sltu-2014,\\n  title = \"Recent progress in developing grapheme-based speech recognition for {I}ndonesian ethnic languages: {J}avanese, {S}undanese, {B}alinese and {B}ataks\",\\n  author = \"Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014)\",\\n  year = \"2014\",\\n  pages = \"46--52\",\\n  address = \"St. Petersburg, Russia\"\\n}\\n\\n@inproceedings{novitasari-sltu-2020,\\n  title = \"Cross-Lingual Machine Speech Chain for {J}avanese, {S}undanese, {B}alinese, and {B}ataks Speech Recognition and Synthesis\",\\n  author = \"Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi\",\\n  booktitle = \"Proc. Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)\",\\n  year = \"2020\",\\n  pages = \"131--138\",\\n  address = \"Marseille, France\"\\n}\\n', description='INDspeech_NEWSTRA_EthnicSR is a collection of graphemically balanced and parallel speech corpora of four major Indonesian ethnic languages: Javanese, Sundanese, Balinese, and Bataks. It was developed in 2013 by the Nara Institute of Science and Technology (NAIST, Japan) [Sakti et al., 2013]. The data has been used to develop Indonesian ethnic speech recognition in supervised learning [Sakti et al., 2014] and semi-supervised learning [Novitasari et al., 2020] based on Machine Speech Chain framework [Tjandra et al., 2020].\\n', homepage='https://github.com/s-sakti/data_indsp_newstra_ethnicsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_teldialog_lvcsr/indspeech_teldialog_lvcsr.py', dataset_name='indspeech_teldialog_lvcsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_teldialog_lvcsr_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='indspeech_teldialog_lvcsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_teldialog_lvcsr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-tcast-2008,\\n    title = \"Development of {I}ndonesian Large Vocabulary Continuous Speech Recognition System within {A-STAR} Project\",\\n    author = \"Sakti, Sakriani and Kelana, Eka and Riza, Hammam and Sakai, Shinsuke and Markov, Konstantin and Nakamura, Satoshi\",\\n    booktitle = \"Proc. IJCNLP Workshop on Technologies and Corpora for Asia-Pacific Speech Translation (TCAST)\",\\n    year = \"2008\",\\n    pages = \"19--24\"\\n    address = \"Hyderabad, India\"\\n}\\n\\n\\n@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n\\n@article{sakti-s2st-csl-2013,\\n    title = \"{A-STAR}: Toward Tranlating Asian Spoken Languages\",\\n    author = \"Sakti, Sakriani and Paul, Michael and Finch, Andrew and Sakai, Shinsuke and Thang, Tat Vu, and Kimura, Noriyuki \\n    and Hori, Chiori and Sumita, Eiichiro and Nakamura, Satoshi and Park, Jun and Wutiwiwatchai, Chai and Xu, Bo and Riza, Hammam \\n    and Arora, Karunesh and Luong, Chi Mai and Li, Haizhou\",\\n    journal = \"Special issue on Speech-to-Speech Translation, Computer Speech and Language Journal\",\\n    volume = \"27\",\\n    number =\"2\",\\n    pages = \"509--527\",\\n    year = \"2013\",\\n    publisher = \"Elsevier\"\\n}\\n', description='\\nINDspeech_TELDIALOG_LVCSR is one of the first Indonesian speech datasets for large vocabulary continuous speech recognition (LVCSR) based on telephon application. R&D Division of PT Telekomunikasi Indonesia developed the data in 2005-2006, in collaboration with Advanced Telecommunication Research Institute International (ATR) Japan, as the continuation of the Asia-Pacific Telecommunity (APT) project [Sakti et al., 2004]. It has also been successfully used for developing Indonesian LVCSR in the Asian speech translation advanced research (A-STAR) project [Sakti et al., 2013].\\n', homepage='https://github.com/s-sakti/data_indsp_teldialog_lvcsr', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indspeech_teldialog_svcsr/indspeech_teldialog_svcsr.py', dataset_name='indspeech_teldialog_svcsr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='indspeech_teldialog_svcsr_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='indspeech_teldialog_svcsr Nusantara schema', schema='nusantara_sptext', subset_id='indspeech_teldialog_svcsr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sakti-icslp-2004,\\n    title = \"Indonesian Speech Recognition for Hearing and Speaking Impaired People\",\\n    author = \"Sakti, Sakriani and Hutagaol, Paulus and Arman, Arry Akhmad and Nakamura, Satoshi\",\\n    booktitle = \"Proc. International Conference on Spoken Language Processing (INTERSPEECH - ICSLP)\",\\n    year = \"2004\",\\n    pages = \"1037--1040\"\\n    address = \"Jeju Island, Korea\"\\n}\\n', description='This is the first Indonesian speech dataset for small vocabulary continuous speech recognition (SVCSR).\\nThe data was developed by TELKOMRisTI (R&D Division, PT Telekomunikasi Indonesia) in collaboration with Advanced\\nTelecommunication Research Institute International (ATR) Japan and Bandung Institute of Technology (ITB) under the\\nAsia-Pacific Telecommunity (APT) project in 2004 [Sakti et al., 2004]. Although it was originally developed for\\na telecommunication system for hearing and speaking impaired people, it can be used for other applications,\\ni.e., automatic call centers. Furthermore, as all speakers utter the same sentences,\\nit can also be used for voice conversion tasks.\\n\\nThe text is based on a word vocabulary which is derived from some necessary dialog calls,\\nsuch as dialog calls with the 119 emergency department, 108 telephone information department,\\nand ticket reservation department. In total, it consists of 20,000 utterances (about 18 hours of speech) from the\\n70-word dialog vocabulary of 100 sentences (including single word sentences) each uttered by 200 speakers\\n(100 Females, 100 Males). The age is limited to middle age (20-40 years), but they present a wide range of spoken\\ndialects from different ethnic groups. The recording is conducted in parallel for both clean and telephone speech,\\nbut we open only the clean speech due to quality issues on telephone speech.\\nEach audio file is a single-channel 16-bit PCM WAV with a sample rate of 16000 Hz.\\nThese utterances are equally split into training and test sets with 100 speakers (50 Females, 50 Males) in each set.\\n', homepage='https://github.com/s-sakti/data_indsp_teldialog_svcsr/', license='CC-BY-NC-SA-4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/inset_lexicon/inset_lexicon.py', dataset_name='inset_lexicon', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='inset_lexicon_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Inset Lexicon Nusantara schema', schema='nusantara_text', subset_id='inset_lexicon'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=True, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Koto, Fajri and Rahmaningtyas, Gemala},\\nyear = {2017},\\nmonth = {12},\\npages = {},\\ntitle = {InSet Lexicon: Evaluation of a Word List for Indonesian Sentiment Analysis in Microblogs},\\ndoi = {10.1109/IALP.2017.8300625}\\n}\\n', description='InSet, an Indonesian sentiment lexicon built to identify written opinion and categorize it into positive or negative opinion,\\nwhich could be utilized to analyze public sentiment towards particular topic, event, or product. Composed using collection\\nof words from Indonesian tweet, InSet was constructed by manually weighting each words and enhanced by adding stemming and synonym set\\n', homepage='https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jadi_ide/jadi_ide.py', dataset_name='jadi_ide', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='jadi_ide_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='JaDi-Ide Nusantara schema', schema='nusantara_text', subset_id='jadi_ide'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{hidayatullah2020attention,\\n  title={Attention-based cnn-bilstm for dialect identification on javanese text},\\n  author={Hidayatullah, Ahmad Fathan and Cahyaningtyas, Siwi and Pamungkas, Rheza Daffa},\\n  journal={Kinetik: Game Technology, Information System, Computer Network, Computing, Electronics, and Control},\\n  pages={317--324},\\n  year={2020}\\n}\\n', description='The JaDi-Ide dataset is a Twitter dataset for Javanese dialect identification, containing 16,498 \\ndata samples. The dialect is classified into `Standard Javanese`, `Ngapak Javanese`, and `East \\nJavanese` dialects.\\n', homepage='https://github.com/fathanick/Javanese-Dialect-Identification-from-Twitter-Data', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jv_id_asr/jv_id_asr.py', dataset_name='jv_id_asr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['jav'], config=NusantaraConfig(name='jv_id_asr_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='jv_id_asr Nusantara schema', schema='nusantara_sptext', subset_id='jv_id_asr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{kjartansson-etal-sltu2018,\\n    title = {{Crowd-Sourced Speech Corpora for Javanese, Sundanese,  Sinhala, Nepali, and Bangladeshi Bengali}},\\n    author = {Oddur Kjartansson and Supheakmungkol Sarin and Knot Pipatsrisawat and Martin Jansche and Linne Ha},\\n    booktitle = {Proc. The 6th Intl. Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU)},\\n    year  = {2018},\\n    address = {Gurugram, India},\\n    month = aug,\\n    pages = {52--55},\\n    URL   = {http://dx.doi.org/10.21437/SLTU.2018-11},\\n  }\\n', description='This data set contains transcribed audio data for Javanese. The data set consists of wave files, and a TSV file.\\nThe file utt_spk_text.tsv contains a FileID, UserID and the transcription of audio in the file.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Reykjavik University and Universitas Gadjah Mada in Indonesia.\\n', homepage='http://openslr.org/35/', license='Attribution-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/jv_id_tts/jv_id_tts.py', dataset_name='jv_id_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['jav'], config=NusantaraConfig(name='jv_id_tts_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='JV_ID_TTS Nusantara schema', schema='nusantara_sptext', subset_id='jv_id_tts'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='This data set contains high-quality transcribed audio data for Javanese.\\nThe data set consists of wave files, and a TSV file.\\nThe file line_index.tsv contains a filename and the transcription of audio in the file.\\nEach filename is prepended with a speaker identification number.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Gadjah Mada University in Indonesia.\\n', homepage='http://openslr.org/41/', license='See https://www.openslr.org/resources/41/LICENSE file for license information. Attribution-ShareAlike 4.0 (CC BY-SA 4.0).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kamus_alay/kamus_alay.py', dataset_name='kamus_alay', tasks=set(), languages=['ind'], config=NusantaraConfig(name='kamus_alay_nusantara_pairs_multi', version=1.0.0, data_dir=None, data_files=None, description='Kamus Alay Nusantara schema', schema='nusantara_pairs_multi', subset_id='kamus_alay'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629151,\\nauthor={Aliyah Salsabila, Nikmatun and Ardhito Winatmoko, Yosef and Akbar Septiandri, Ali and Jamal, Ade},\\nbooktitle={2018 International Conference on Asian Language Processing (IALP)},\\ntitle={Colloquial Indonesian Lexicon},\\nyear={2018},\\nvolume={},\\nnumber={},\\npages={226-229},\\ndoi={10.1109/IALP.2018.8629151}}\\n', description='Kamus Alay provide a lexicon for text normalization of Indonesian colloquial words.\\nIt contains 3,592 unique colloquial words-also known as “bahasa alay” -and manually annotated them\\nwith the normalized form. We built this lexicon from Instagram comments provided by Septiandri & Wibisono (2017)\\n', homepage='https://ieeexplore.ieee.org/abstract/document/8629151', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/karonese_sentiment/karonese_sentiment.py', dataset_name='karonese_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['btx'], config=NusantaraConfig(name='karonese_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Karonese Sentiment Nusantara schema', schema='nusantara_text', subset_id='karonese_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{karo2022sentiment,\\n  title={Sentiment Analysis in Karonese Tweet using Machine Learning},\\n  author={Karo, Ichwanul Muslim Karo and Fudzee, Mohd Farhan Md and Kasim, Shahreen and Ramli, Azizul Azhar},\\n  journal={Indonesian Journal of Electrical Engineering and Informatics (IJEEI)},\\n  volume={10},\\n  number={1},\\n  pages={219--231},\\n  year={2022}\\n}\\n', description='Karonese sentiment was crawled from Twitter between 1 January 2021 and 31 October 2021.\\nThe first crawling process used several keywords related to the Karonese, such as\\n\"deleng sinabung, Sinabung mountain\", \"mejuah-juah, greeting welcome\", \"Gundaling\",\\nand so on. However, due to the insufficient number of tweets obtained using such\\nkeywords, a second crawling process was done based on several hashtags, such as\\n#kalakkaro, # #antonyginting, and #lyodra.\\n', homepage='http://section.iaesonline.com/index.php/IJEEI/article/view/3565', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/keps/keps.py', dataset_name='keps', tasks={<Tasks.KEYWORD_EXTRACTION: 'KE'>}, languages=['ind'], config=NusantaraConfig(name='keps_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='KEPS Nusantara schema', schema='nusantara_seq_label', subset_id='keps'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mahfuzh2019improving,\\n  title={Improving Joint Layer RNN based Keyphrase Extraction by Using Syntactical Features},\\n  author={Miftahul Mahfuzh, Sidik Soleman, and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='The KEPS dataset (Mahfuzh, Soleman and Purwarianti, 2019) consists of text from Twitter\\ndiscussing banking products and services and is written in the Indonesian language. A phrase\\ncontaining important information is considered a keyphrase. Text may contain one or more\\nkeyphrases since important phrases can be located at different positions.\\n- tokens: a list of string features.\\n- seq_label: a list of classification labels, with possible values including O, B, I.\\nThe labels use Inside-Outside-Beginning (IOB) tagging.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for all-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for all-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for all-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_all-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for all-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_10-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_10-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_10-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_10-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_17-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_17-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_17-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_17-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_17-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_21-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_21-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_21-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_21-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_21-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_25-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_25-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_25-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_25-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_25-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_31-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_31-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_31-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_31-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_31-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_39-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_39-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_39-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_39-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_39-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_43-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_43-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_43-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_43-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_43-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_49-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_49-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2021_49-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2021_49-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_05-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_05-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_05-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_05-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_05-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_21-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_21-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_21-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_21-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_21-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_27-raw', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_27-dedup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_27-neardup', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc/kopi_cc.py', dataset_name='kopi_cc', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_2022_27-neardup_clean_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC with nusantara_ssp schema for 2022_27-neardup_clean', schema='nusantara_ssp', subset_id='kopi_cc'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='       @ARTICLE{2022arXiv220106642A,\\n       author = {{Abadji}, Julien and {Ortiz Suarez}, Pedro and {Romary}, Laurent and {Sagot}, Benoit},\\n        title = \"{Towards a Cleaner Document-Oriented Multilingual Crawled Corpus}\",\\n      journal = {arXiv e-prints},\\n     keywords = {Computer Science - Computation and Language},\\n         year = 2022,\\n        month = jan,\\n          eid = {arXiv:2201.06642},\\n        pages = {arXiv:2201.06642},\\narchivePrefix = {arXiv},\\n       eprint = {2201.06642},\\n primaryClass = {cs.CL},\\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220106642A},\\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\\n}\\n@inproceedings{AbadjiOrtizSuarezRomaryetal.2021,\\n  author    = {Julien Abadji and Pedro Javier Ortiz Su{\\'a}rez and Laurent Romary and Benoit Sagot},\\n  title     = {Ungoliant: An optimized pipeline for the generation of a very large-scale multilingual web corpus},\\n  series = {Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-9) 2021. Limerick, 12 July 2021 (Online-Event)},\\n  editor    = {Harald L{\"u}ngen and Marc Kupietz and Piotr Bański and Adrien Barbaresi and Simon Clematide and Ines Pisetta},\\n  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},\\n  address   = {Mannheim},\\n  doi       = {10.14618/ids-pub-10468},\\n  url       = {https://nbn-resolving.org/urn:nbn:de:bsz:mh39-104688},\\n  pages     = {1 -- 9},\\n  year      = {2021},\\n  abstract  = {Since the introduction of large language models in Natural Language Processing, large raw corpora have played a crucial role in Computational Linguistics.},\\n  language  = {en}\\n}\\n\\n', description='    KoPI-CC (Korpus Perayapan Indonesia)-CC is Indonesian Only Extract from Common Crawl snapshots ,each snapshots get extracted using ungoliant and get extra \"filtering\" using deduplication technique\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2016_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2016', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2017_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2017', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2018_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2018', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2019_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2019', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2020_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2020', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2021_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2021', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_2022_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for 2022', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_cc_news/kopi_cc_news.py', dataset_name='kopi_cc_news', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind'], config=NusantaraConfig(name='kopi_cc_news_all_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-CC_News with nusantara_ssp schema for all', schema='nusantara_ssp', subset_id='kopi_cc_news'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='\\n', description='    KoPI(Korpus Perayapan Indonesia)-CC_News is Indonesian Only Extract from CC NEWS Common Crawl from 2016-2022(july) ,each snapshots get extracted using warcio,trafilatura and filter using fasttext\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-CC_News', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for all-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for all-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_all-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for all-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ace_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ace_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ace_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ace_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ban_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ban_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ban_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ban_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for bjn_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for bjn_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_bjn_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for bjn_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ind_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ind_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_ind_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for ind_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for jav_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for jav_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_jav_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for jav_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for min_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for min_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_min_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for min_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-raw_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for sun_Latn-raw', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-dedup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for sun_Latn-dedup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/kopi_nllb/kopi_nllb.py', dataset_name='kopi_nllb', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'ace', 'ban', 'bjn', 'min', 'sun'], config=NusantaraConfig(name='kopi_nllb_sun_Latn-neardup_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='KoPI-NLLB with nusantara_ssp schema for sun_Latn-neardup', schema='nusantara_ssp', subset_id='kopi_nllb'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2022.09.13', citation='\\n\\nHefferman et al, Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages. Arxiv https://arxiv.org/abs/2205.12654, 2022.\\nNLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, Arxiv https://arxiv.org/abs/2207.04672, 2022.\\n\\n', description='\\nKopI(Korpus Perayapan Indonesia)-NLLB, is Indonesian family language(aceh,bali,banjar,indonesia,jawa,minang,sunda) only extracted from NLLB Dataset, allenai/nllb\\n\\neach language set also filtered using some some deduplicate technique such as exact hash(md5) dedup technique and minhash LSH neardup\\n\\n', homepage='https://huggingface.co/datasets/munggok/KoPI-NLLB', license='ODC_C')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2jav Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_day_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2day Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bug Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2sun Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2mad Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bin_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bin Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2bbc Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_khek_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2khek Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_msa_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2msa Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2min Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_ind_tiociu_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara ind2tiociu Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_jav_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara jav2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_day_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara day2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bug_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bug2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_sun_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara sun2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_mad_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara mad2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bin_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bin2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_bbc_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara bbc2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_khek_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara khek2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_msa_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara msa2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_min_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara min2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/korpus_nusantara/korpus_nusantara.py', dataset_name='korpus_nusantara', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav', 'day', 'bug', 'sun', 'mad', 'bin', 'bbc', 'khek', 'msa', 'min', 'tiociu'], config=NusantaraConfig(name='korpus_nusantara_tiociu_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Korpus_Nusantara tiociu2ind Nusantara schema', schema='nusantara_t2t', subset_id='korpus_nusantara'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{sujaini2020improving,\\n  title={Improving the role of language model in statistical machine translation (Indonesian-Javanese)},\\n  author={Sujaini, Herry},\\n  journal={International Journal of Electrical and Computer Engineering},\\n  volume={10},\\n  number={2},\\n  pages={2102},\\n  year={2020},\\n  publisher={IAES Institute of Advanced Engineering and Science}\\n}\\n', description='This parallel corpus was collected from several studies, assignments, and thesis of \\nstudents of the Informatics Study Program, Tanjungpura University. Some of the corpus \\nare used in the translation machine from Indonesian to local languages http://nustor.untan.ac.id/cammane/. \\nThis corpus can be used freely for research purposes by citing the paper \\nhttps://ijece.iaescore.com/index.php/IJECE/article/download/20046/13738.\\n\\nThe dataset is a combination of multiple machine translation works from the author, \\nHerry Sujaini, covering Indonesian to 25 local dialects in Indonesia. Since not all \\ndialects have ISO639-3 standard coding, as agreed with Pak Herry , we decided to \\ngroup the dataset into the closest language family, i.e.: Javanese, Dayak, Buginese, \\nSundanese, Madurese, Banjar, Batak Toba, Khek, Malay, Minangkabau, and Tiociu.\\n', homepage='https://github.com/herrysujaini/korpusnusantara', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for all languages', schema='nusantara_sptext', subset_id='librivox_indonesia'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ind_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for indonesian languages', schema='nusantara_sptext', subset_id='librivox_indonesia_ind'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ban_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for balinese languages', schema='nusantara_sptext', subset_id='librivox_indonesia_ban'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_bug_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for bugisnese languages', schema='nusantara_sptext', subset_id='librivox_indonesia_bug'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_sun_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for sundanese languages', schema='nusantara_sptext', subset_id='librivox_indonesia_sun'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_ace_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for acehnese languages', schema='nusantara_sptext', subset_id='librivox_indonesia_ace'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_min_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for minangkabau languages', schema='nusantara_sptext', subset_id='librivox_indonesia_min'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/librivox_indonesia/librivox_indonesia.py', dataset_name='librivox_indonesia', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages={'ind', 'ban', 'bug', 'sun', 'ace', 'min', 'jav'}, config=NusantaraConfig(name='librivox_indonesia_jav_nusantara_sptext', version='1.0.0', data_dir=None, data_files=None, description='Librivox-Indonesia Nusantara schema for javanese languages', schema='nusantara_sptext', subset_id='librivox_indonesia_jav'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{\\n   research, \\n   title={indonesian-nlp/librivox-indonesia · datasets at hugging face}, \\n   url={https://huggingface.co/datasets/indonesian-nlp/librivox-indonesia},\\n   author={Indonesian-nlp}\\n} \\n', description=\"The LibriVox Indonesia dataset consists of MP3 audio and a corresponding text file we generated from the public domain audiobooks LibriVox. \\nWe collected only languages in Indonesia for this dataset. \\nThe original LibriVox audiobooks or sound files' duration varies from a few minutes to a few hours. \\nEach audio file in the speech dataset now lasts from a few seconds to a maximum of 20 seconds.\\nWe converted the audiobooks to speech datasets using the forced alignment software we developed. \\nIt supports multilingual, including low-resource languages, such as Acehnese, Balinese, or Minangkabau. \\nWe can also use it for other languages without additional work to train the model.\\nThe dataset currently consists of 8 hours in 7 languages from Indonesia. \\nWe will add more languages or audio files as we collect them. \\n\", homepage='https://huggingface.co/indonesian-nlp/librivox-indonesia', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/liputan6/liputan6.py', dataset_name='liputan6', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='liputan6_canonical_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='liputan6 Nusantara schema', schema='nusantara_t2t', subset_id='liputan6_canonical'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto2020liputan6,\\n  title={Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\\n  author={Koto, Fajri and Lau, Jey Han and Baldwin, Timothy},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={598--608},\\n  year={2020}\\n}\\n', description='\\nA large-scale Indonesian summarization dataset consisting of harvested articles from Liputan6.com, an online news portal, resulting in 215,827 document-summary pairs.\\n', homepage='https://github.com/fajri91/sum_liputan6', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/liputan6/liputan6.py', dataset_name='liputan6', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='liputan6_xtreme_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='liputan6 Nusantara schema', schema='nusantara_t2t', subset_id='liputan6_xtreme'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto2020liputan6,\\n  title={Liputan6: A Large-scale Indonesian Dataset for Text Summarization},\\n  author={Koto, Fajri and Lau, Jey Han and Baldwin, Timothy},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={598--608},\\n  year={2020}\\n}\\n', description='\\nA large-scale Indonesian summarization dataset consisting of harvested articles from Liputan6.com, an online news portal, resulting in 215,827 document-summary pairs.\\n', homepage='https://github.com/fajri91/sum_liputan6', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/local_id_abusive/local_id_abusive.py', dataset_name='local_id_abusive', tasks=set(), languages=['jav', 'sun'], config=NusantaraConfig(name='local_id_abusive_jav_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='local_id_abusive Nusantara schema Javanese', schema='nusantara_text_multi', subset_id='local_id_abusive_jav'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{putri2021abusive,\\n  title={Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},\\n  author={Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},\\n  booktitle={2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},\\n  pages={461--465},\\n  year={2021},\\n  organization={International Workshop on Computer Science and Engineering (WCSE)},\\n  abstract={Indonesia’s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages.}\\n}\\n', description='This dataset is for abusive and hate speech detection, using Twitter text containing Javanese and Sundanese words.\\n\\n(from the publication source)\\nThe Indonesian local language dataset collection was conducted using Twitter search API to collect the tweets and then\\nimplemented using Tweepy Library. The tweets were collected using queries from the list of abusive words in Indonesian\\ntweets. The abusive words were translated into local Indonesian languages, which are Javanese and Sundanese. The\\ntranslated words are then used as queries to collect tweets containing Indonesian and local languages. The translation\\nprocess involved native speakers for each local language. The crawling process has collected a total of more than 5000\\ntweets. Then, the crawled data were filtered to get tweets that contain local’s vocabulary and/or sentences in Javanese\\nand Sundanese. Next, after the filtering process, the data will be labeled whether the tweets are labeled as hate speech\\nand abusive language or not.\\n', homepage='https://github.com/Shofianina/local-indonesian-abusive-hate-speech-dataset', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/local_id_abusive/local_id_abusive.py', dataset_name='local_id_abusive', tasks=set(), languages=['jav', 'sun'], config=NusantaraConfig(name='local_id_abusive_sun_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='local_id_abusive Nusantara schema Sundanese', schema='nusantara_text_multi', subset_id='local_id_abusive_sun'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{putri2021abusive,\\n  title={Abusive language and hate speech detection for Javanese and Sundanese languages in tweets: Dataset and preliminary study},\\n  author={Putri, Shofianina Dwi Ananda and Ibrohim, Muhammad Okky and Budi, Indra},\\n  booktitle={2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},\\n  pages={461--465},\\n  year={2021},\\n  organization={International Workshop on Computer Science and Engineering (WCSE)},\\n  abstract={Indonesia’s demography as an archipelago with lots of tribes and local languages added variances in their communication style. Every region in Indonesia has its own distinct culture, accents, and languages. The demographical condition can influence the characteristic of the language used in social media, such as Twitter. It can be found that Indonesian uses their own local language for communicating and expressing their mind in tweets. Nowadays, research about identifying hate speech and abusive language has become an attractive and developing topic. Moreover, the research related to Indonesian local languages still rarely encountered. This paper analyzes the use of machine learning approaches such as Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest Decision Tree (RFDT) in detecting hate speech and abusive language in Sundanese and Javanese as Indonesian local languages. The classifiers were used with the several term weightings features, such as word n-grams and char n-grams. The experiments are evaluated using the F-measure. It achieves over 60 % for both local languages.}\\n}\\n', description='This dataset is for abusive and hate speech detection, using Twitter text containing Javanese and Sundanese words.\\n\\n(from the publication source)\\nThe Indonesian local language dataset collection was conducted using Twitter search API to collect the tweets and then\\nimplemented using Tweepy Library. The tweets were collected using queries from the list of abusive words in Indonesian\\ntweets. The abusive words were translated into local Indonesian languages, which are Javanese and Sundanese. The\\ntranslated words are then used as queries to collect tweets containing Indonesian and local languages. The translation\\nprocess involved native speakers for each local language. The crawling process has collected a total of more than 5000\\ntweets. Then, the crawled data were filtered to get tweets that contain local’s vocabulary and/or sentences in Javanese\\nand Sundanese. Next, after the filtering process, the data will be labeled whether the tweets are labeled as hate speech\\nand abusive language or not.\\n', homepage='https://github.com/Shofianina/local-indonesian-abusive-hate-speech-dataset', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation Nusantara schema', schema='nusantara_t2t', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/multilexnorm/multilexnorm.py', dataset_name='multilexnorm', tasks={<Tasks.MULTILEXNORM: 'MLN'>}, languages=['ind'], config=NusantaraConfig(name='multilexnorm_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='multilexnorm Nusantara schema', schema='nusantara_t2t', subset_id='multilexnorm'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{multilexnorm,\\n  title= {MultiLexNorm: A Shared Task on Multilingual Lexical Normalization,\\n  author = \"van der Goot, Rob and Ramponi et al.\",\\n  booktitle = \"Proceedings of the 7th Workshop on Noisy User-generated Text (W-NUT 2021)\",\\n  year = \"2021\",\\n  publisher = \"Association for Computational Linguistics\",\\n  address = \"Punta Cana, Dominican Republic\"\\n}\\n', description='MULTILEXNPRM is a new benchmark dataset for multilingual lexical normalization\\nincluding 12 language variants,\\nwe here specifically work on the Indonisian-english language.\\n', homepage='https://bitbucket.org/robvanderg/multilexnorm/src/master/', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_ner_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_ner'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_sentiment_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_statement_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_statement'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nerp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERP Nusantara schema', schema='nusantara_seq_label', subset_id='nerp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/netifier/netifier.py', dataset_name='netifier', tasks=set(), languages=['ind'], config=NusantaraConfig(name='netifier_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='Netifier Nusantara schema', schema='nusantara_text_multi', subset_id='netifier'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='', description='Netifier dataset is a collection of scraped posts on famous social media sites in Indonesia,\\nsuch as Instagram, Twitter, and Kaskus aimed to do multi-label toxicity classification.\\nThe dataset consists of 7,773 texts. The author manually labelled ~7k samples into 4 categories:\\npornography, hate speech, racism, and radicalism.\\n', homepage='https://github.com/ahmadizzan/netifier', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='News En-Id Nusantara schema', schema='nusantara_t2t', subset_id='news_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed nusantara_t2t schema for Aceh language', schema='nusantara_t2t', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed nusantara_t2t schema for Banjar language', schema='nusantara_t2t', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nllb_seed/nllb_seed.py', dataset_name='nllb_seed', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ace', 'bjn', 'bug', 'eng'], config=NusantaraConfig(name='nllb_seed_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nllb_seed nusantara_t2t schema for Bugis language', schema='nusantara_t2t', subset_id='nllb_seed'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nllb2022,\\n  author    = {NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi,  Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, Jeff Wang},\\n  title     = {No Language Left Behind: Scaling Human-Centered Machine Translation},\\n  year      = {2022}\\n}\\n', description='No Language Left Behind Seed Data\\nNLLB Seed is a set of professionally-translated sentences in the Wikipedia domain. Data for NLLB-Seed was sampled from Wikimedia’s List of articles every Wikipedia should have, a collection of topics in different fields of knowledge and human activity. NLLB-Seed consists of around six thousand sentences in 39 languages. NLLB-Seed is meant to be used for training rather than model evaluation. Due to this difference, NLLB-Seed does not go through the human quality assurance process present in FLORES-200.\\n', homepage='https://github.com/facebookresearch/flores/tree/main/nllb_seed', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ace_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ace source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ban_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ban source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bjn_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bjn source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bug_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bug source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_eng_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for eng source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_ind_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for ind source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_jav_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for jav source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_mad_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for mad source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_min_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for min source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nij_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for nij source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_sun_bbc_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for sun source language and  bbc target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ace_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  ace target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ban_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  ban target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_bjn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  bjn target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_bug_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  bug target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  eng target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  ind target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_jav_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  jav target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_mad_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  mad target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_min_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  min target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_nij_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  nij target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_bbc_sun_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for bbc source language and  sun target language', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_mt/nusax_mt.py', dataset_name='nusax_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_mt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='nusax_mt with nusantara_t2t schema for all 132 language pairs', schema='nusantara_t2t', subset_id='nusax_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-MT is a parallel corpus for training and benchmarking machine translation models across 10 Indonesian local languages + Indonesian and English. The data is presented in csv format with 12 columns, one column for each language.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/mt', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ace language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ban language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bjn language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bug language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for eng language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ind language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for jav language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for mad language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for min language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for nij language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for sun language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bbc language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for all 12 languages', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/paracotta_id/paracotta_id.py', dataset_name='paracotta_id', tasks={<Tasks.PARAPHRASING: 'PARA'>}, languages=['ind'], config=NusantaraConfig(name='paracotta_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='paracotta_id Nusantara schema', schema='nusantara_t2t', subset_id='paracotta_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{aji2022paracotta,\\n  title={ParaCotta: Synthetic Multilingual Paraphrase Corpora from the Most Diverse Translation Sample Pair},\\n  author={Aji, Alham Fikri and Fatyanosa, Tirana Noor and Prasojo, Radityo Eko and Arthur, Philip and Fitriany, Suci and Qonitah, Salma and Zulfa, Nadhifa and Santoso, Tomi and Data, Mahendra},\\n  journal={arXiv preprint arXiv:2205.04651},\\n  year={2022}\\n}\\n', description='ParaCotta is a synthetic parallel paraphrase corpus across 17 languages: Arabic, Catalan, Czech, German, English, Spanish, Estonian, French, Hindi, Indonesian, Italian, Dutch, Ro- manian, Russian, Swedish, Vietnamese, and Chinese.\\n', homepage='https://github.com/afaji/paracotta-paraphrase', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/parallel_su_id/parallel_su_id.py', dataset_name='parallel_su_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'sun'], config=NusantaraConfig(name='parallel_su_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Parallel Su-Id Nusantara schema', schema='nusantara_t2t', subset_id='parallel_su_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{7437678,\\n  author={Suryani, Arie Ardiyanti and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n  booktitle={2015 International Conference on Information Technology Systems and Innovation (ICITSI)}, \\n  title={Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian}, \\n  year={2015},\\n  volume={},\\n  number={},\\n  pages={1-6},\\n  doi={10.1109/ICITSI.2015.7437678}}\\n', description='This data contains 3616 lines of Sundanese sentences taken from the online Sundanese language magazine Mangle, West Java Dakwah Council, and Balebat, and translated into Indonesian by several students of the Sundanese language study program UPI Bandung.\\n', homepage='https://dataverse.telkomuniversity.ac.id/dataset.xhtml?persistentId=doi:10.34820/FK2/HDYWXW', license='Creative Commons CC0 - No Rights Reserved')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/pos_sun_mono/pos_sun_mono.py', dataset_name='pos_sun_mono', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['sun'], config=NusantaraConfig(name='pos_sun_mono_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='pos_sun_mono Nusantara Seq Label schema', schema='nusantara_seq_label', subset_id='pos_sun_mono'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@data{FK2/VTAHRH_2022,\\n    author = {ARDIYANTI SURYANI, ARIE and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n    publisher = {Telkom University Dataverse},\\n    title = {{PoSTagged Sundanese Monolingual Corpus}},\\n    year = {2022},\\n    version = {DRAFT VERSION},\\n    doi = {10.34820/FK2/VTAHRH},\\n    url = {https://doi.org/10.34820/FK2/VTAHRH}\\n}\\n\\n@INPROCEEDINGS{7437678,\\n  author={Suryani, Arie Ardiyanti and Widyantoro, Dwi Hendratmo and Purwarianti, Ayu and Sudaryat, Yayat},\\n  booktitle={2015 International Conference on Information Technology Systems and Innovation (ICITSI)},\\n  title={Experiment on a phrase-based statistical machine translation using PoS Tag information for Sundanese into Indonesian},\\n  year={2015},\\n  volume={},\\n  number={},\\n  pages={1-6},\\n  doi={10.1109/ICITSI.2015.7437678}\\n}\\n', description='This dataset contains 3616 lines of Sundanese sentences taken from several online magazines (Mangle, Dewan Dakwah Jabar, and Balebat). Annotated with PoS Labels by several undergraduates of the Sundanese Language Education Study Program (PPBS), UPI Bandung.\\n', homepage='https://dataverse.telkomuniversity.ac.id/dataset.xhtml?persistentId=doi:10.34820/FK2/VTAHRH', license='CC0 - \"Public Domain Dedication\"')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/posp/posp.py', dataset_name='posp', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='posp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='POSP Nusantara schema', schema='nusantara_seq_label', subset_id='posp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/sentiment_nathasa_review/sentiment_nathasa_review.py', dataset_name='sentiment_nathasa_review', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='sentiment_nathasa_review_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='sentiment_nathasa_review Nusantara schema', schema='nusantara_text', subset_id='sentiment_nathasa_review'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{nurlaila2018classification,\\n  title={CLASSIFICATION OF CUSTOMERS EMOTION USING NA{\"I}VE BAYES CLASSIFIER (Case Study: Natasha Skin Care)},\\n  author={Nurlaila, Afifah and Wiranto, Wiranto and Saptono, Ristu},\\n  journal={ITSMART: Jurnal Teknologi dan Informasi},\\n  volume={6},\\n  number={2},\\n  pages={92--97},\\n  year={2018}\\n}\\n', description='Customer Review (Natasha Skincare) is a customers emotion dataset, with amounted to 19,253 samples with the division for each class is 804 joy, 43 surprise, 154 anger, 61 fear, 287 sad, 167 disgust, and 17736 no-emotions.\\n', homepage='https://jurnal.uns.ac.id/itsmart/article/viewFile/17328/15082', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='singgalang_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='singgalang Nusantara schema', schema='nusantara_seq_label', subset_id='singgalang'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='smsa_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='SMSA Nusantara schema', schema='nusantara_text', subset_id='smsa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/squad_id/squad_id.py', dataset_name='squad_id', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='squad_id_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='SQUAD_ID Nusantara schema', schema='nusantara_qa', subset_id='squad_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{muis2020sequence,\\n  title={Sequence-to-sequence learning for indonesian automatic question generator},\\n  author={Muis, Ferdiant Joshua and Purwarianti, Ayu},\\n  booktitle={2020 7th International Conference on Advance Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='    This dataset contains Indonesian SQuAD v2.0 dataset (Google-translated).\\n    The dataset can be used for automatic question generation (AQG),\\n    or machine reading comphrehension(MRC) task.\\n', homepage='https://github.com/FerdiantJoshua/question-generator', license='TBD')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks={<Tasks.PARAPHRASING: 'PARA'>}, languages=['ind'], config=NusantaraConfig(name='stif_indonesia_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia Nusantara schema', schema='nusantara_t2t', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_emot/su_emot.py', dataset_name='su_emot', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['sun'], config=NusantaraConfig(name='su_emot_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='Sundanese Twitter Dataset for Emotion Nusantara schema', schema='nusantara_text', subset_id='su_emot'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{\\n9297929,  \\nauthor={Putra, Oddy Virgantara and Wasmanson, Fathin Muhammad and Harmini, Triana and Utama, Shoffin Nahwa},  \\nbooktitle={2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM)},   \\ntitle={Sundanese Twitter Dataset for Emotion Classification},   \\nyear={2020},  \\nvolume={},  \\nnumber={},  \\npages={391--395},  \\ndoi={10.1109/CENIM51130.2020.9297929}\\n}\\n', description='This is a dataset for emotion classification of Sundanese text. The dataset is gathered from Twitter API between January and March 2019 with 2518 tweets in total. \\nThe tweets filtered by using some hashtags which are represented Sundanese emotion, for instance, #persib, #corona, #saredih, #nyakakak, #garoblog, #sangsara, #gumujeng, #bungah, #sararieun, #ceurik, and #hariwang. \\nThis dataset contains four distinctive emotions: anger, joy, fear, and sadness. Each tweet is annotated using related emotion. For data\\nvalidation, the authors consulted a Sundanese language teacher for expert validation.\\n', homepage='https://github.com/virgantara/sundanese-twitter-dataset', license='UNKNOWN')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_id_asr/su_id_asr.py', dataset_name='su_id_asr', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['sun'], config=NusantaraConfig(name='su_id_asr_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='SU_ID_ASR Nusantara schema', schema='nusantara_sptext', subset_id='su_id_asr'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='Sundanese ASR training data set containing ~220K utterances.\\nThis dataset was collected by Google in Indonesia.\\n\\n\\n', homepage='https://indonlp.github.io/nusa-catalogue/card.html?su_id_asr', license='Attribution-ShareAlike 4.0 International.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/su_id_tts/su_id_tts.py', dataset_name='su_id_tts', tasks={<Tasks.TEXT_TO_SPEECH: 'TTS'>}, languages=['sun'], config=NusantaraConfig(name='su_id_tts_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='SU_ID_TTS Nusantara schema', schema='nusantara_sptext', subset_id='su_id_tts'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{sodimana18_sltu,\\n  author={Keshan Sodimana and Pasindu {De Silva} and Supheakmungkol Sarin and Oddur Kjartansson and Martin Jansche and Knot Pipatsrisawat and Linne Ha},\\n  title={{A Step-by-Step Process for Building TTS Voices Using Open Source Data and Frameworks for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese}},\\n  year=2018,\\n  booktitle={Proc. 6th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2018)},\\n  pages={66--70},\\n  doi={10.21437/SLTU.2018-14}\\n}\\n', description='This data set contains high-quality transcribed audio data for Sundanese. The data set consists of wave files, and a TSV file. The file line_index.tsv contains a filename and the transcription of audio in the file. Each filename is prepended with a speaker identification number.\\nThe data set has been manually quality checked, but there might still be errors.\\nThis dataset was collected by Google in collaboration with Universitas Pendidikan Indonesia.\\n', homepage='http://openslr.org/44/', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_eng_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for eng source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_ind_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for ind source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_jpn_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for jpn source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_kor_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for kor source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_myn_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for myn source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_tha_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for tha source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_vie_zsm_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for vie source language and  zsm target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  eng target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  ind target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_jpn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  jpn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_kor_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  kor target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_myn_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  myn target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_tha_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  tha target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_zsm_vie_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for zsm source language and  vie target language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/talpco/talpco.py', dataset_name='talpco', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['eng', 'ind', 'jpn', 'kor', 'myn', 'tha', 'vie', 'zsm'], config=NusantaraConfig(name='talpco_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='talpco with nusantara_t2t schema for all 7 language pairs from / to ind language', schema='nusantara_t2t', subset_id='talpco'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{published_papers/22434604,\\n  title = {TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and David Moeljadi and Hideo Sawada},\\n  journal = {言語処理学会 第24回年次大会 発表論文集},\\n  pages = {436--439},\\n  year = {2018}\\n}\\n@article{published_papers/22434603,\\n  title = {Interpersonal meaning annotation for Asian language corpora: The case of TUFS Asian Language Parallel Corpus (TALPCo)},\\n  author = {Hiroki Nomoto and Kenji Okano and Sunisa Wittayapanyanon and Junta Nomura},\\n  journal = {言語処理学会 第25回年次大会 発表論文集},\\n  pages = {846--849},\\n  year = {2019}\\n}\\n', description='The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences\\nand their translations into Korean, Burmese (Myanmar; the official language of the Republic of the Union of Myanmar),\\nMalay (the national language of Malaysia, Singapore and Brunei), Indonesian, Thai, Vietnamese and English.\\n', homepage='https://github.com/matbahasa/TALPCo', license='CC-BY 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id Nusantara schema', schema='nusantara_t2t', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks={<Tasks.KEYWORD_TAGGING: 'KT'>}, languages=['ind'], config=NusantaraConfig(name='term_a_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='TermA Nusantara schema', schema='nusantara_seq_label', subset_id='term_a'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for default language pair (eng-ind)', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_ara_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-ara language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_spa_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-spa language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_fra_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-fra language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_hin_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-hin language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_por_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-por language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_rus_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-rus language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_zho_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-zho language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ind_eng_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ind-eng language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_ara_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for ara-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_spa_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for spa-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_fra_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for fra-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_hin_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for hin-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_por_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for por-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_rus_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for rus-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_zho_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for zho-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tico_19/tico_19.py', dataset_name='tico_19', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'ara', 'spa', 'fra', 'hin', 'por', 'rus', 'zho', 'eng'], config=NusantaraConfig(name='tico_19_eng_ind_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='tico_19 nusantara_t2t schema for eng-ind language pair', schema='nusantara_t2t', subset_id='tico_19'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{anastasopoulos-etal-2020-tico,\\n    title = \"{TICO}-19: the Translation Initiative for {CO}vid-19\",\\n    author = {Anastasopoulos, Antonios  and\\n      Cattelan, Alessandro  and\\n      Dou, Zi-Yi  and\\n      Federico, Marcello  and\\n      Federmann, Christian  and\\n      Genzel, Dmitriy  and\\n      Guzm{\\'a}n, Franscisco  and\\n      Hu, Junjie  and\\n      Hughes, Macduff  and\\n      Koehn, Philipp  and\\n      Lazar, Rosie  and\\n      Lewis, Will  and\\n      Neubig, Graham  and\\n      Niu, Mengmeng  and\\n      {\"O}ktem, Alp  and\\n      Paquin, Eric  and\\n      Tang, Grace  and\\n      Tur, Sylwia},\\n    booktitle = \"Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.nlpcovid19-2.5\",\\n    doi = \"10.18653/v1/2020.nlpcovid19-2.5\",\\n}\\n', description='TICO-19 (Translation Initiative for COVID-19) is sampled from a variety of public sources containing \\nCOVID-19 related content, representing different domains (e.g., news, wiki articles, and others). TICO-19 \\nincludes 30 documents (3071 sentences, 69.7k words) translated from English into 36 languages: Amharic, \\nArabic (Modern Standard), Bengali, Chinese (Simplified), Dari, Dinka, Farsi, French (European), Hausa, \\nHindi, Indonesian, Kanuri, Khmer (Central), Kinyarwanda, Kurdish Kurmanji, Kurdish Sorani, Lingala, \\nLuganda, Malay, Marathi, Myanmar, Nepali, Nigerian Fulfulde, Nuer, Oromo, Pashto, Portuguese (Brazilian), \\nRussian, Somali, Spanish (Latin American), Swahili, Congolese Swahili, Tagalog, Tamil, Tigrinya, Urdu, Zulu.\\n', homepage='https://tico-19.github.io', license='CC0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='titml_idn_nusantara_sptext', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN Nusantara schema', schema='nusantara_sptext', subset_id='titml_idn'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SPTEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/tydiqa_id/tydiqa_id.py', dataset_name='tydiqa_id', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='tydiqa_id_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='TyDiQA Id Nusantara schema', schema='nusantara_qa', subset_id='tydiqa_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{clark-etal-2020-tydi,\\n    title = \"{T}y{D}i {QA}: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages\",\\n    author = \"Clark, Jonathan H.  and\\n      Choi, Eunsol  and\\n      Collins, Michael  and\\n      Garrette, Dan  and\\n      Kwiatkowski, Tom  and\\n      Nikolaev, Vitaly  and\\n      Palomaki, Jennimaria\",\\n    journal = \"Transactions of the Association for Computational Linguistics\",\\n    volume = \"8\",\\n    year = \"2020\",\\n    address = \"Cambridge, MA\",\\n    publisher = \"MIT Press\",\\n    url = \"https://aclanthology.org/2020.tacl-1.30\",\\n    doi = \"10.1162/tacl_a_00317\",\\n    pages = \"454--470\",\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\"\\n}\\n', description='TyDiQA dataset is collected from Wikipedia articles with human-annotated question and answer pairs covering 11 languages. \\nThe question-answer pairs are collected for each language without using translation services.\\nIndoNLG uses the Indonesian data from the secondary Gold passage task of the original TyDiQA dataset and\\nrandomly split off 15% of the training data and use it as the test set.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ud_id_csui/ud_id_csui.py', dataset_name='ud_id_csui', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='ud_id_csui_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='ud_id_csui Nusantara KB schema', schema='nusantara_kb', subset_id='ud_id_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article {10.3844/jcssp.2020.1585.1597,\\nauthor = {Alfina, Ika and Budi, Indra and Suhartanto, Heru},\\ntitle = {Tree Rotations for Dependency Trees: Converting the Head-Directionality of Noun Phrases},\\narticle_type = {journal},\\nvolume = {16},\\nnumber = {11},\\nyear = {2020},\\nmonth = {Nov},\\npages = {1585-1597},\\ndoi = {10.3844/jcssp.2020.1585.1597},\\nurl = {https://thescipub.com/abstract/jcssp.2020.1585.1597},\\njournal = {Journal of Computer Science},\\npublisher = {Science Publications}\\n}\\n', description='UD Indonesian-CSUI is a conversion from an Indonesian constituency treebank in the Penn Treebank format named Kethu that was also a conversion from a constituency treebank built by Dinakaramani et al. (2015).\\nThis treebank is named after the place where treebanks were built: Faculty of Computer Science (CS), Universitas Indonesia (UI).\\n\\nAbout this treebank:\\n- Genre is news in formal Indonesian (the majority is economic news)\\n- 1030 sentences (28K words) divided into testing and training dataset of around 10K words and around 18K words respectively.\\n- Average of 27.4 words per-sentence.\\n', homepage='https://github.com/UniversalDependencies/UD_Indonesian-CSUI', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ud_id_csui/ud_id_csui.py', dataset_name='ud_id_csui', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='ud_id_csui_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='ud_id_csui Nusantara Text to Text schema', schema='nusantara_t2t', subset_id='ud_id_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article {10.3844/jcssp.2020.1585.1597,\\nauthor = {Alfina, Ika and Budi, Indra and Suhartanto, Heru},\\ntitle = {Tree Rotations for Dependency Trees: Converting the Head-Directionality of Noun Phrases},\\narticle_type = {journal},\\nvolume = {16},\\nnumber = {11},\\nyear = {2020},\\nmonth = {Nov},\\npages = {1585-1597},\\ndoi = {10.3844/jcssp.2020.1585.1597},\\nurl = {https://thescipub.com/abstract/jcssp.2020.1585.1597},\\njournal = {Journal of Computer Science},\\npublisher = {Science Publications}\\n}\\n', description='UD Indonesian-CSUI is a conversion from an Indonesian constituency treebank in the Penn Treebank format named Kethu that was also a conversion from a constituency treebank built by Dinakaramani et al. (2015).\\nThis treebank is named after the place where treebanks were built: Faculty of Computer Science (CS), Universitas Indonesia (UI).\\n\\nAbout this treebank:\\n- Genre is news in formal Indonesian (the majority is economic news)\\n- 1030 sentences (28K words) divided into testing and training dataset of around 10K words and around 18K words respectively.\\n- Average of 27.4 words per-sentence.\\n', homepage='https://github.com/UniversalDependencies/UD_Indonesian-CSUI', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/ud_id_csui/ud_id_csui.py', dataset_name='ud_id_csui', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='ud_id_csui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='ud_id_csui Nusantara Seq Label schema', schema='nusantara_seq_label', subset_id='ud_id_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article {10.3844/jcssp.2020.1585.1597,\\nauthor = {Alfina, Ika and Budi, Indra and Suhartanto, Heru},\\ntitle = {Tree Rotations for Dependency Trees: Converting the Head-Directionality of Noun Phrases},\\narticle_type = {journal},\\nvolume = {16},\\nnumber = {11},\\nyear = {2020},\\nmonth = {Nov},\\npages = {1585-1597},\\ndoi = {10.3844/jcssp.2020.1585.1597},\\nurl = {https://thescipub.com/abstract/jcssp.2020.1585.1597},\\njournal = {Journal of Computer Science},\\npublisher = {Science Publications}\\n}\\n', description='UD Indonesian-CSUI is a conversion from an Indonesian constituency treebank in the Penn Treebank format named Kethu that was also a conversion from a constituency treebank built by Dinakaramani et al. (2015).\\nThis treebank is named after the place where treebanks were built: Faculty of Computer Science (CS), Universitas Indonesia (UI).\\n\\nAbout this treebank:\\n- Genre is news in formal Indonesian (the majority is economic news)\\n- 1030 sentences (28K words) divided into testing and training dataset of around 10K words and around 18K words respectively.\\n- Average of 27.4 words per-sentence.\\n', homepage='https://github.com/UniversalDependencies/UD_Indonesian-CSUI', license='CC BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/unimorph_id/unimorph_id.py', dataset_name='unimorph_id', tasks=set(), languages=['ind'], config=NusantaraConfig(name='unimorph_id_nusantara_pairs_multi', version=1.0.0, data_dir=None, data_files=None, description='unimorph_id Nusantara schema', schema='nusantara_pairs_multi', subset_id='unimorph_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{pimentel-ryskina-etal-2021-sigmorphon,\\n    title = \"SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages\",\\n    author = \"Pimentel, Tiago  and\\n      Ryskina, Maria  and\\n      Mielke, Sabrina J.  and\\n      Wu, Shijie  and\\n      Chodroff, Eleanor  and\\n      Leonard, Brian  and\\n      Nicolai, Garrett  and\\n      Ghanggo Ate, Yustinus  and\\n      Khalifa, Salam  and\\n      Habash, Nizar  and\\n      El-Khaissi, Charbel  and\\n      Goldman, Omer  and\\n      Gasser, Michael  and\\n      Lane, William  and\\n      Coler, Matt  and\\n      Oncevay, Arturo  and\\n      Montoya Samame, Jaime Rafael  and\\n      Silva Villegas, Gema Celeste  and\\n      Ek, Adam  and\\n      Bernardy, Jean-Philippe  and\\n      Shcherbakov, Andrey  and\\n      Bayyr-ool, Aziyana  and\\n      Sheifer, Karina  and\\n      Ganieva, Sofya  and\\n      Plugaryov, Matvey  and\\n      Klyachko, Elena  and\\n      Salehi, Ali  and\\n      Krizhanovsky, Andrew  and\\n      Krizhanovsky, Natalia  and\\n      Vania, Clara  and\\n      Ivanova, Sardana  and\\n      Salchak, Aelita  and\\n      Straughn, Christopher  and\\n      Liu, Zoey  and\\n      Washington, Jonathan North  and\\n      Ataman, Duygu  and\\n      Kiera{\\'s}, Witold  and\\n      Woli{\\'n}ski, Marcin  and\\n      Suhardijanto, Totok  and\\n      Stoehr, Niklas  and\\n      Nuriah, Zahroh  and\\n      Ratan, Shyam  and\\n      Tyers, Francis M.  and\\n      Ponti, Edoardo M.  and\\n      Aiton, Grant  and\\n      Hatcher, Richard J.  and\\n      Prud\\'hommeaux, Emily  and\\n      Kumar, Ritesh  and\\n      Hulden, Mans  and\\n      Barta, Botond  and\\n      Lakatos, Dorina  and\\n      Szolnok, G{\\'a}bor  and\\n      {\\'A}cs, Judit  and\\n      Raj, Mohit  and\\n      Yarowsky, David  and\\n      Cotterell, Ryan  and\\n      Ambridge, Ben  and\\n      Vylomova, Ekaterina\",\\n    booktitle = \"Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology\",\\n    month = aug,\\n    year = \"2021\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.sigmorphon-1.25\",\\n    doi = \"10.18653/v1/2021.sigmorphon-1.25\",\\n    pages = \"229--259\"\\n}', description='The UniMorph project, Indonesian chapter.\\nDue to sparsity of UniMorph original parsing, raw source is used instead.\\nOriginal parsing can be found on https://huggingface.co/datasets/universal_morphologies/blob/2.3.2/universal_morphologies.py\\n', homepage='https://github.com/unimorph/ind', license='Creative Commons Attribution-ShareAlike 3.0 Unported (CC BY-SA 3.0)')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for eng language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ind language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for jav language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for min language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for sun language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ace language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for mly language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for map_bms language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikilingua/wikilingua.py', dataset_name='wikilingua', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='wikilingua_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='wikilingua Nusantara schema', schema='nusantara_t2t', subset_id='wikilingua'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{\\n    ladhak-wiki-2020,\\n    title={WikiLingua: A New Benchmark Dataset for Multilingual Abstractive Summarization},\\n    author={Faisal Ladhak, Esin Durmus, Claire Cardie and Kathleen McKeown},\\n    booktitle={Findings of EMNLP, 2020},\\n    year={2020}\\n}\\n', description='We introduce WikiLingua, a large-scale, multilingual dataset for the evaluation of crosslingual abstractive \\nsummarization systems. We extract article and summary pairs in 18 languages from WikiHow12, a high quality, \\ncollaborative resource of how-to guides on a diverse set of topics written by human authors. We create gold-standard \\narticle summary alignments across languages by aligning the images that are used to describe each how-to step in an \\narticle.\\n', homepage='https://github.com/esdurmus/Wikilingua', license='CC-BY-NC-SA 3.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wrete/wrete.py', dataset_name='wrete', tasks={<Tasks.TEXTUAL_ENTAILMENT: 'TE'>}, languages=['ind'], config=NusantaraConfig(name='wrete_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='WReTe Nusantara schema', schema='nusantara_pairs', subset_id='wrete'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='WReTe, The Wiki Revision Edits Textual Entailment dataset (Setya and Mahendra, 2018) consists of 450 sentence pairs constructed from Wikipedia revision history. The dataset contains pairs of sentences and binary semantic relations between the pairs. The data are labeled as entailed when the meaning of the second sentence can be derived from the first one, and not entailed otherwise\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xcopa/xcopa.py', dataset_name='xcopa', tasks={<Tasks.QUESTION_ANSWERING: 'QA'>}, languages=['ind'], config=NusantaraConfig(name='xcopa_nusantara_qa', version=1.0.0, data_dir=None, data_files=None, description='XCOPA Nusantara schema', schema='nusantara_qa', subset_id='xcopa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='QA', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation=\"@inproceedings{ponti2020xcopa,\\n  title={{XCOPA: A} Multilingual Dataset for Causal Commonsense Reasoning},\\n  author={Edoardo M. Ponti, Goran Glava\\x0b{s}, Olga Majewska, Qianchu Liu, Ivan Vuli'{c} and Anna Korhonen},\\n  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},\\n  year={2020},\\n  url={https://ducdauge.github.io/files/xcopa.pdf}\\n}\\n@inproceedings{roemmele2011choice,\\n  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},\\n  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},\\n  booktitle={2011 AAAI Spring Symposium Series},\\n  year={2011},\\n  url={https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF},\\n}\\n\", description='  XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning\\nThe Cross-lingual Choice of Plausible Alternatives dataset is a benchmark to evaluate the ability of machine learning models to transfer commonsense reasoning across\\nlanguages. The dataset is the translation and reannotation of the English COPA (Roemmele et al. 2011) and covers 11 languages from 11 families and several areas around\\nthe globe. The dataset is challenging as it requires both the command of world knowledge and the ability to generalise to new languages. All the details about the\\ncreation of XCOPA and the implementation of the baselines are available in the paper.\\n', homepage='https://github.com/cambridgeltl/xcopa', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='xl_sum Nusantara schema', schema='nusantara_t2t', subset_id='xl_sum'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xpersona_id/xpersona_id.py', dataset_name='xpersona_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='xpersona_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='XPersona ID Nusantara schema', schema='nusantara_t2t', subset_id='xpersona_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{lin2020xpersona,\\n  title={XPersona: Evaluating multilingual personalized chatbot},\\n  author={Lin, Zhaojiang and Liu, Zihan and Winata, Genta Indra and Cahyawijaya, Samuel and Madotto, Andrea and Bang, Yejin and Ishii, Etsuko and Fung, Pascale},\\n  journal={arXiv preprint arXiv:2003.07568},\\n  year={2020}\\n}\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\"\\n}\\n', description='XPersona is a multi-lingual extension of Persona-Chat. \\nXPersona dataset includes persona conversations in six different languages other than English for building and evaluating multilingual personalized agents.\\n', homepage='', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xsid/xsid.py', dataset_name='xsid', tasks={<Tasks.INTENT_CLASSIFICATION: 'INT'>}, languages=['ind'], config=NusantaraConfig(name='xsid_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='xSID Nusantara intent classification schema', schema='nusantara_text', subset_id='xsid'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='0.3.0', citation='@inproceedings{van-der-goot-etal-2020-cross,\\n      title={From Masked-Language Modeling to Translation: Non-{E}nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding},\\n      author={van der Goot, Rob and Sharaf, Ibrahim and Imankulova, Aizhan and {\"U}st{\"u}n, Ahmet and Stepanovic, Marija and Ramponi, Alan and Khairunnisa, Siti Oryza and Komachi, Mamoru and Plank, Barbara},\\n    booktitle = \"Proceedings of the 2021 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\\n    year = \"2021\",\\n    address = \"Mexico City, Mexico\",\\n    publisher = \"Association for Computational Linguistics\"\\n}\\n', description='XSID is a new benchmark for cross-lingual (X) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect.\\n', homepage='https://bitbucket.org/robvanderg/xsid/src/master/', license='CC-BY-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/xsid/xsid.py', dataset_name='xsid', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='xsid_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='xSID Nusantara pos tagging schema', schema='nusantara_seq_label', subset_id='xsid'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='0.3.0', citation='@inproceedings{van-der-goot-etal-2020-cross,\\n      title={From Masked-Language Modeling to Translation: Non-{E}nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding},\\n      author={van der Goot, Rob and Sharaf, Ibrahim and Imankulova, Aizhan and {\"U}st{\"u}n, Ahmet and Stepanovic, Marija and Ramponi, Alan and Khairunnisa, Siti Oryza and Komachi, Mamoru and Plank, Barbara},\\n    booktitle = \"Proceedings of the 2021 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\\n    year = \"2021\",\\n    address = \"Mexico City, Mexico\",\\n    publisher = \"Association for Computational Linguistics\"\\n}\\n', description='XSID is a new benchmark for cross-lingual (X) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect.\\n', homepage='https://bitbucket.org/robvanderg/xsid/src/master/', license='CC-BY-SA 4.0')\n",
      "Nusantara NER public datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indonlu_nergrit/indonlu_nergrit.py', dataset_name='indonlu_nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indonlu_nergrit_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='IndoNLU NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='indonlu_nergrit'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n@online{nergrit2019,\\n  title={NERGrit Corpus},\\n  author={NERGrit Developers},\\n  year={2019},\\n  url={https://github.com/grit-id/nergrit-corpus}\\n}\\n', description='This NER dataset is taken from the Grit-ID repository, and the labels are spans in IOB chunking representation.\\nThe dataset consists of three kinds of named entity tags, PERSON (name of person), PLACE (name of location), and\\nORGANIZATION (name of organization).\\n', homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indqner/indqner.py', dataset_name='indqner', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indqner_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NER dataset from Indonesian translation Quran Nusantara schema', schema='nusantara_seq_label', subset_id='indqner'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{,\\nauthor = {Ria Hari Gusmita, Asep Fajar Firmansyah, Khodijah Khuliyah},\\ntitle = {{IndQNER: a NER Benchmark Dataset on Indonesian Translation of Quran}},\\nurl = {https://github.com/RiaGusmita/IndQNER},\\nyear = {2022}\\n}\\n', description='IndQNER is a NER dataset created by manually annotating the Indonesian translation of Quran text.\\nThe dataset contains 18 named entity categories as follow:\\n    \"Allah\": Allah (including synonim of Allah such as Yang maha mengetahui lagi mahabijaksana)\\n    \"Throne\": Throne of Allah (such as \\'Arasy)\\n    \"Artifact\": Artifact (such as Ka\\'bah, Baitullah)\\n    \"AstronomicalBody\": Astronomical body (such as bumi, matahari)\\n    \"Event\": Event (such as hari akhir, kiamat)\\n    \"HolyBook\": Holy book (such as AlQur\\'an)\\n    \"Language\": Language (such as bahasa Arab\\n    \"Angel\": Angel (such as Jibril, Mikail)\\n    \"Person\": Person (such as Bani Israil, Fir\\'aun)\\n    \"Messenger\": Messenger (such as Isa, Muhammad, Musa)\\n    \"Prophet\": Prophet (such as Adam, Sulaiman)\\n    \"AfterlifeLocation\": Afterlife location (such as Jahanam, Jahim, Padang Mahsyar)\\n    \"GeographicalLocation\": Geographical location (such as Sinai, negeru Babilonia)\\n    \"Color\": Color (such as kuning tua)\\n    \"Religion\": Religion (such as Islam, Yahudi, Nasrani)\\n    \"Food\": Food (such as manna, salwa)\\n', homepage='https://github.com/RiaGusmita/IndQNER', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_ner_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_ner'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_sentiment_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nergrit/nergrit.py', dataset_name='nergrit', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nergrit_statement_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERGrit Nusantara schema', schema='nusantara_seq_label', subset_id='nergrit_statement'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{Fahmi_NERGRIT_CORPUS_2019,\\nauthor = {Fahmi, Husni and Wibisono, Yudi and Kusumawati, Riyanti},\\ntitle = {{NERGRIT CORPUS}},\\nurl = {https://github.com/grit-id/nergrit-corpus},\\nyear = {2019}\\n}\\n', description=\"Nergrit Corpus is a dataset collection of Indonesian Named Entity Recognition (NER), Statement Extraction,\\nand Sentiment Analysis developed by PT Gria Inovasi Teknologi (GRIT).\\nThe Named Entity Recognition contains 18 entities as follow:\\n    'CRD': Cardinal\\n    'DAT': Date\\n    'EVT': Event\\n    'FAC': Facility\\n    'GPE': Geopolitical Entity\\n    'LAW': Law Entity (such as Undang-Undang)\\n    'LOC': Location\\n    'MON': Money\\n    'NOR': Political Organization\\n    'ORD': Ordinal\\n    'ORG': Organization\\n    'PER': Person\\n    'PRC': Percent\\n    'PRD': Product\\n    'QTY': Quantity\\n    'REG': Religion\\n    'TIM': Time\\n    'WOA': Work of Art\\n    'LAN': Language\\n\", homepage='https://github.com/grit-id/nergrit-corpus', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nerp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERP Nusantara schema', schema='nusantara_seq_label', subset_id='nerp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='singgalang_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='singgalang Nusantara schema', schema='nusantara_seq_label', subset_id='singgalang'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for eng language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ind language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for jav language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for min language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for sun language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ace language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for mly language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for map_bms language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "IndoLEM datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks={<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ntp_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP Nusantara schema', schema='nusantara_pairs', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment Nusantara schema', schema='nusantara_text', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks={<Tasks.SENTENCE_ORDERING: 'SO'>}, languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_gsd/indolem_ud_id_gsd.py', dataset_name='indolem_ud_id_gsd', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_gsd_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='indolem_ud_id_gsd Nusantara KB schema', schema='nusantara_kb', subset_id='indolem_ud_id_gsd'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{mcdonald-etal-2013-universal,\\n    title = \"{U}niversal {D}ependency Annotation for Multilingual Parsing\",\\n    author = {McDonald, Ryan  and\\n      Nivre, Joakim  and\\n      Quirmbach-Brundage, Yvonne  and\\n      Goldberg, Yoav  and\\n      Das, Dipanjan  and\\n      Ganchev, Kuzman  and\\n      Hall, Keith  and\\n      Petrov, Slav  and\\n      Zhang, Hao  and\\n      T{\"a}ckstr{\"o}m, Oscar  and\\n      Bedini, Claudia  and\\n      Bertomeu Castell{\\'o}, N{\\'u}ria  and\\n      Lee, Jungmee},\\n    booktitle = \"Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\\n    month = aug,\\n    year = \"2013\",\\n    address = \"Sofia, Bulgaria\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/P13-2017\",\\n    pages = \"92--97\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='The Indonesian-GSD treebank consists of 5598 sentences and 122k words split into train/dev/test of 97k/12k/11k words.\\nThe treebank was originally converted from the content head version of the universal dependency treebank v2.0 (legacy) in 2015.In order to comply with the latest Indonesian annotation guidelines, the treebank has undergone a major revision between UD releases v2.8 and v2.9 (2021).\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud default fold ('0') of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_0_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '0' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_1_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '1' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_2_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '2' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_3_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '3' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusacrowd/nusa_datasets/indolem_ud_id_pud/indolem_ud_id_pud.py', dataset_name='indolem_ud_id_pud', tasks={<Tasks.DEPENDENCY_PARSING: 'DEP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ud_id_pud_4_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description=\"indolem_ud_id_pud fold '4' of Nusantara KB schema\", schema='nusantara_kb', subset_id='indolem_ud_id_pud_4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@conference{2f8c7438a7f44f6b85b773586cff54e8,\\n    title = \"A gold standard dependency treebank for Indonesian\",\\n    author = \"Ika Alfina and Arawinda Dinakaramani and Fanany, {Mohamad Ivan} and Heru Suhartanto\",\\n    note = \"Publisher Copyright: {\\textcopyright} 2019 Proceedings of the 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019. All rights reserved.; 33rd Pacific Asia Conference on Language, Information and Computation, PACLIC 2019 ; Conference date: 13-09-2019 Through 15-09-2019\",\\n    year = \"2019\",\\n    month = jan,\\n    day = \"1\",\\n    language = \"English\",\\n    pages = \"1--9\",\\n}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n    author    = {Fajri Koto and\\n                 Afshin Rahimi and\\n                 Jey Han Lau and\\n                 Timothy Baldwin},\\n    title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n                 Model for Indonesian {NLP}},\\n    journal   = {CoRR},\\n    volume    = {abs/2011.00677},\\n    year      = {2020},\\n    url       = {https://arxiv.org/abs/2011.00677},\\n    eprinttype = {arXiv},\\n    eprint    = {2011.00677},\\n    timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n    biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n    bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='1 of 8 sub-datasets of IndoLEM, a comprehensive dataset encompassing 7 NLP tasks (Koto et al., 2020).\\nThis dataset is part of [Parallel Universal Dependencies (PUD)](http://universaldependencies.org/conll17/) project.\\nThis is based on the first corrected version by Alfina et al. (2019), contains 1,000 sentences.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "print('All Configs')\n",
    "print(conhelps)\n",
    "\n",
    "# filter and load datasets\n",
    "# ====================================================================\n",
    "print('Retrieve SMSA')\n",
    "print([helper for helper in conhelps.filtered(lambda x: (\"smsa\" in x.dataset_name and x.is_nusantara_schema))])\n",
    "smsa_datasets = [\n",
    "    helper.load_dataset()\n",
    "    for helper in conhelps.filtered(\n",
    "        lambda x: (\"smsa\" in x.dataset_name and x.is_nusantara_schema)\n",
    "    )\n",
    "]\n",
    "print(smsa_datasets)\n",
    "\n",
    "# examples of other filters\n",
    "# ====================================================================\n",
    "\n",
    "# get all source schema config helpers\n",
    "print('Source datasets')\n",
    "source_helpers = conhelps.filtered(lambda x: x.config.schema == \"source\")\n",
    "print(source_helpers)\n",
    "\n",
    "# get all nusantara config helpers\n",
    "print('Nusantara datasets')\n",
    "nusantara_helpers = conhelps.filtered(lambda x: x.is_nusantara_schema)\n",
    "print(nusantara_helpers)\n",
    "\n",
    "# nusantara NER public tasks\n",
    "print('Nusantara NER public datasets')\n",
    "nc_ner_public_helpers = conhelps.filtered(\n",
    "    lambda x: (\n",
    "        x.is_nusantara_schema\n",
    "        and Tasks.NAMED_ENTITY_RECOGNITION in x.tasks\n",
    "        and not x.is_local\n",
    "    )\n",
    ")\n",
    "print(nc_ner_public_helpers)\n",
    "\n",
    "# indolem datasets\n",
    "print('IndoLEM datasets')\n",
    "nc_indolem_helpers = conhelps.filtered(\n",
    "    lambda x: (\"indolem\" in x.dataset_name and x.is_nusantara_schema)\n",
    ")\n",
    "print(nc_indolem_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55195cb-c91d-4edb-8423-338901002e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_helper = NusantaraMetadataHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142a4212-ee66-4f70-9679-ef456737e34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nusantara.config_helper.NusantaraMetadataHelper at 0x7f7ad20432b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b65e3b7c-0879-4ba9-b1c5-2447e9bf7f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bible_en_id_nusantara_t2t', 'bible_jv_id_nusantara_t2t', 'bible_su_id_nusantara_t2t', 'covost2_ind_eng_nusantara_t2t', 'covost2_eng_ind_nusantara_t2t', 'id_panl_bppt_nusantara_t2t', 'id_qqp_nusantara_t2t', 'id_wiki_parallel_jav_ind_nusantara_t2t', 'id_wiki_parallel_min_ind_nusantara_t2t', 'id_wiki_parallel_sun_ind_nusantara_t2t', 'indo_general_mt_en_id_nusantara_t2t', 'indo_religious_mt_en_id_nusantara_t2t', 'indosum_fold0_nusantara_t2t', 'indosum_fold1_nusantara_t2t', 'indosum_fold2_nusantara_t2t', 'indosum_fold3_nusantara_t2t', 'indosum_fold4_nusantara_t2t', 'korpus_nusantara_ind_jav_nusantara_t2t', 'korpus_nusantara_ind_day_nusantara_t2t', 'korpus_nusantara_ind_bug_nusantara_t2t', 'korpus_nusantara_ind_sun_nusantara_t2t', 'korpus_nusantara_ind_mad_nusantara_t2t', 'korpus_nusantara_ind_bin_nusantara_t2t', 'korpus_nusantara_ind_bbc_nusantara_t2t', 'korpus_nusantara_ind_khek_nusantara_t2t', 'korpus_nusantara_ind_msa_nusantara_t2t', 'korpus_nusantara_ind_min_nusantara_t2t', 'korpus_nusantara_ind_tiociu_nusantara_t2t', 'korpus_nusantara_jav_ind_nusantara_t2t', 'korpus_nusantara_day_ind_nusantara_t2t', 'korpus_nusantara_bug_ind_nusantara_t2t', 'korpus_nusantara_sun_ind_nusantara_t2t', 'korpus_nusantara_mad_ind_nusantara_t2t', 'korpus_nusantara_bin_ind_nusantara_t2t', 'korpus_nusantara_bbc_ind_nusantara_t2t', 'korpus_nusantara_khek_ind_nusantara_t2t', 'korpus_nusantara_msa_ind_nusantara_t2t', 'korpus_nusantara_min_ind_nusantara_t2t', 'korpus_nusantara_tiociu_ind_nusantara_t2t', 'minangnlp_mt_nusantara_t2t', 'multilexnorm_nusantara_t2t', 'news_en_id_nusantara_t2t', 'nllb_seed_ace_nusantara_t2t', 'nllb_seed_bjn_nusantara_t2t', 'nllb_seed_bug_nusantara_t2t', 'nusax_mt_ace_ind_nusantara_t2t', 'nusax_mt_ban_ind_nusantara_t2t', 'nusax_mt_bjn_ind_nusantara_t2t', 'nusax_mt_bug_ind_nusantara_t2t', 'nusax_mt_eng_ind_nusantara_t2t', 'nusax_mt_ind_ace_nusantara_t2t', 'nusax_mt_ind_ban_nusantara_t2t', 'nusax_mt_ind_bjn_nusantara_t2t', 'nusax_mt_ind_bug_nusantara_t2t', 'nusax_mt_ind_eng_nusantara_t2t', 'nusax_mt_ind_jav_nusantara_t2t', 'nusax_mt_ind_mad_nusantara_t2t', 'nusax_mt_ind_min_nusantara_t2t', 'nusax_mt_ind_nij_nusantara_t2t', 'nusax_mt_ind_sun_nusantara_t2t', 'nusax_mt_ind_bbc_nusantara_t2t', 'nusax_mt_jav_ind_nusantara_t2t', 'nusax_mt_mad_ind_nusantara_t2t', 'nusax_mt_min_ind_nusantara_t2t', 'nusax_mt_nij_ind_nusantara_t2t', 'nusax_mt_sun_ind_nusantara_t2t', 'nusax_mt_bbc_ind_nusantara_t2t', 'paracotta_id_nusantara_t2t', 'parallel_su_id_nusantara_t2t', 'stif_indonesia_nusantara_t2t', 'talpco_eng_ind_nusantara_t2t', 'talpco_eng_jpn_nusantara_t2t', 'talpco_eng_kor_nusantara_t2t', 'talpco_eng_myn_nusantara_t2t', 'talpco_eng_tha_nusantara_t2t', 'talpco_eng_vie_nusantara_t2t', 'talpco_eng_zsm_nusantara_t2t', 'talpco_ind_eng_nusantara_t2t', 'talpco_ind_jpn_nusantara_t2t', 'talpco_ind_kor_nusantara_t2t', 'talpco_ind_myn_nusantara_t2t', 'talpco_ind_tha_nusantara_t2t', 'talpco_ind_vie_nusantara_t2t', 'talpco_ind_zsm_nusantara_t2t', 'talpco_jpn_eng_nusantara_t2t', 'talpco_jpn_ind_nusantara_t2t', 'talpco_jpn_kor_nusantara_t2t', 'talpco_jpn_myn_nusantara_t2t', 'talpco_jpn_tha_nusantara_t2t', 'talpco_jpn_vie_nusantara_t2t', 'talpco_jpn_zsm_nusantara_t2t', 'talpco_kor_eng_nusantara_t2t', 'talpco_kor_ind_nusantara_t2t', 'talpco_kor_jpn_nusantara_t2t', 'talpco_kor_myn_nusantara_t2t', 'talpco_kor_tha_nusantara_t2t', 'talpco_kor_vie_nusantara_t2t', 'talpco_kor_zsm_nusantara_t2t', 'talpco_myn_eng_nusantara_t2t', 'talpco_myn_ind_nusantara_t2t', 'talpco_myn_jpn_nusantara_t2t', 'talpco_myn_kor_nusantara_t2t', 'talpco_myn_tha_nusantara_t2t', 'talpco_myn_vie_nusantara_t2t', 'talpco_myn_zsm_nusantara_t2t', 'talpco_tha_eng_nusantara_t2t', 'talpco_tha_ind_nusantara_t2t', 'talpco_tha_jpn_nusantara_t2t', 'talpco_tha_kor_nusantara_t2t', 'talpco_tha_myn_nusantara_t2t', 'talpco_tha_vie_nusantara_t2t', 'talpco_tha_zsm_nusantara_t2t', 'talpco_vie_eng_nusantara_t2t', 'talpco_vie_ind_nusantara_t2t', 'talpco_vie_jpn_nusantara_t2t', 'talpco_vie_kor_nusantara_t2t', 'talpco_vie_myn_nusantara_t2t', 'talpco_vie_tha_nusantara_t2t', 'talpco_vie_zsm_nusantara_t2t', 'talpco_zsm_eng_nusantara_t2t', 'talpco_zsm_ind_nusantara_t2t', 'talpco_zsm_jpn_nusantara_t2t', 'talpco_zsm_kor_nusantara_t2t', 'talpco_zsm_myn_nusantara_t2t', 'talpco_zsm_tha_nusantara_t2t', 'talpco_zsm_vie_nusantara_t2t', 'talpco_nusantara_t2t', 'ted_en_id_nusantara_t2t', 'ud_id_csui_nusantara_t2t', 'xl_sum_nusantara_t2t', 'xpersona_id_nusantara_t2t']\n"
     ]
    }
   ],
   "source": [
    "print([helper.config.name for helper in conhelps.filtered(lambda x: (\n",
    "    't2t' in x.config.name\n",
    "    and x.is_nusantara_schema\n",
    "    and ('ind' in x.config.name if 'nusax_mt' in x.dataset_name else True)\n",
    "    and not x.is_resource))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816f260a-6f20-41ab-a000-790884061878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casa_nusantara_text_multi', 'emot_nusantara_text', 'emotcmt_nusantara_text', 'emotion_id_opinion_nusantara_text', 'hoasa_nusantara_text_multi', 'id_abusive_nusantara_text', 'id_abusive_news_comment_nusantara_text', 'id_clickbait_nusantara_text', 'id_google_play_review_nusantara_text', 'id_google_play_review_posneg_nusantara_text', 'id_hatespeech_nusantara_text', 'id_hoax_news_nusantara_text', 'id_multilabel_hs_nusantara_text_multi', 'id_short_answer_grading_nusantara_pairs', 'id_stance_nusantara_pairs', 'id_sts_nusantara_pairs_score', 'imdb_jv_nusantara_text', 'indolem_ntp_nusantara_pairs', 'indolem_sentiment_nusantara_text', 'indonli_nusantara_pairs', 'jadi_ide_nusantara_text', 'local_id_abusive_jav_nusantara_text_multi', 'local_id_abusive_sun_nusantara_text_multi', 'netifier_nusantara_text_multi', 'nusax_senti_ace_nusantara_text', 'nusax_senti_ban_nusantara_text', 'nusax_senti_bjn_nusantara_text', 'nusax_senti_bug_nusantara_text', 'nusax_senti_eng_nusantara_text', 'nusax_senti_ind_nusantara_text', 'nusax_senti_jav_nusantara_text', 'nusax_senti_mad_nusantara_text', 'nusax_senti_min_nusantara_text', 'nusax_senti_nij_nusantara_text', 'nusax_senti_sun_nusantara_text', 'nusax_senti_bbc_nusantara_text', 'nusax_senti_nusantara_text', 'sentiment_nathasa_review_nusantara_text', 'smsa_nusantara_text', 'wrete_nusantara_pairs']\n"
     ]
    }
   ],
   "source": [
    "print([helper.config.name for helper in conhelps.filtered(lambda x: (\n",
    "    ('_text' in x.config.name or '_pair' in x.config.name)\n",
    "    and x.is_nusantara_schema\n",
    "    and not x.is_resource))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb5fd8d-fcdc-4203-b704-094aae284aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MetaDict:\n",
    "    data: dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d14640d3-6f18-49f9-a026-ca57982bb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('https://docs.google.com/spreadsheets/d/17o83IvWxmtGLYridZis0nEprHhsZIMeFtHGtXV35h6M/export?format=csv&gid=879729812', skiprows=1)\n",
    "meta_df = meta_df[meta_df['Implemented'] != 0].rename({\n",
    "    'No.': 'id', 'Name': 'name', 'Subsets': 'subsets', 'Link': 'source_link', 'Description': 'description',\n",
    "    'HF Link': 'hf_link', 'License': 'license', 'Year': 'year', 'Collection Style': 'collection_style',\n",
    "    'Language': 'language', 'Dialect': 'dialect', 'Domain': 'domain', 'Form': 'modality', 'Tasks': 'tasks',\n",
    "    'Volume': 'volume', 'Unit': 'unit', 'Ethical Risks': 'ethical_risk', 'Provider': 'provider',\n",
    "    'Paper Title': 'paper_title', 'Paper Link': 'paper_link', 'Access': 'access', 'Derived From': 'derived_from', \n",
    "    'Test Split': 'is_splitted', 'Notes': 'notes', 'Dataloader': 'dataloader', 'Implemented': 'implemented'\n",
    "}, axis=1)\n",
    "meta_df['is_splitted'] = meta_df['is_splitted'].apply(lambda x: True if x =='Yes' else False)\n",
    "# [\n",
    "#  'No.', 'Name', 'Subsets', 'Link', 'HF Link', 'License', 'Year',\n",
    "#  'Language', 'Dialect', 'Domain', 'Form', 'Collection Style',\n",
    "#  'Description', 'Volume', 'Unit', 'Ethical Risks', 'Provider',\n",
    "#  'Paper Title', 'Paper Link', 'Access', 'Derived From', 'Tasks',\n",
    "#  'Test Split', 'Notes', 'Dataloader', 'Implemented'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce44a6d9-0b40-49f9-9b2d-5c91b69a0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_meta_map = {}\n",
    "for cfg_meta in conhelps:\n",
    "    # Assign metadata to meta dataframe\n",
    "    meta_df.loc[meta_df.dataloader == cfg_meta.dataset_name, [\n",
    "        'is_large', 'is_resource', 'is_default', 'is_broken',\n",
    "        'is_local', 'citation', 'license', 'homepage', 'tasks'\n",
    "    ]] = [\n",
    "        cfg_meta.is_large, cfg_meta.is_resource, cfg_meta.is_default, cfg_meta.is_broken, \n",
    "        cfg_meta.is_local, cfg_meta.citation, cfg_meta.license, cfg_meta.homepage, '|'.join([task.value for task in cfg_meta.tasks])\n",
    "    ]\n",
    "    \n",
    "    if cfg_meta.dataset_name not in name_to_meta_map:\n",
    "        name_to_meta_map[cfg_meta.dataset_name] = {}\n",
    "    if cfg_meta.config.schema not in name_to_meta_map[cfg_meta.dataset_name]:\n",
    "        name_to_meta_map[cfg_meta.dataset_name][cfg_meta.config.schema] = []\n",
    "    name_to_meta_map[cfg_meta.dataset_name][cfg_meta.config.schema].append(cfg_meta)\n",
    "    \n",
    "meta_df = meta_df.fillna(False)\n",
    "\n",
    "for dset_name in name_to_meta_map.keys():\n",
    "    meta_df.loc[meta_df.dataloader == dset_name, 'metadata'] = MetaDict(data=name_to_meta_map[dset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04571177-ca67-4e86-a1a9-1ae0fc24d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset sentiment_nathasa_review (/home/samuel/.cache/huggingface/datasets/sentiment_nathasa_review/sentiment_nathasa_review_nusantara_text/1.0.0/30eb0ea3a17ed2a9baea98645648c8f32804db498c2d57a7e376d733f0f9b89f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6fd52667d044c9a337745549c43793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indolem_sentiment_dataset (/home/samuel/.cache/huggingface/datasets/indolem_sentiment_dataset/indolem_sentiment_nusantara_text/1.0.0/b9050e6fcb7b7fa40f4dd502c92dc8c1df0ef30e067f1664af76c908c7b47467)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2312b38fdd2c4a1ba9e6a80e162695e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_x_senti (/home/samuel/.cache/huggingface/datasets/nusa_x_senti/nusax_senti_ind_nusantara_text/1.0.0/3c834957d94e799c678f9be42ee6def4fcdbfdd0407b6add0d1bc875067b2ff9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93465d742c864a2e92651c197fe987ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset smsa (/home/samuel/.cache/huggingface/datasets/smsa/smsa_nusantara_text/1.0.0/c4914239fa9f7683736a2df989690905e1551838621298d799f0d1c78097a349)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eac36d0daa4c1e81330f4c39ab9163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentiment_nathasa_review_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 62132\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 62131\n",
       "     })\n",
       " }),\n",
       " 'indolem_sentiment_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 3638\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1011\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 399\n",
       "     })\n",
       " }),\n",
       " 'nusax_senti_ind_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'smsa_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 11000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1260\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all Indonesian sentiment analysis task\n",
    "lang = 'ind'\n",
    "task = Tasks.SENTIMENT_ANALYSIS\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & (~meta_df.is_resource) &\n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02fafbb2-0a92-44f8-abb2-c2c1bd95264b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indo_general_mt_en_id (/home/samuel/.cache/huggingface/datasets/indo_general_mt_en_id/indo_general_mt_en_id_nusantara_t2t/1.0.0/8997ff3f81a5107662a8a4d0e405a1e053a076327735146c76b56dd6c263e4c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfb28684dfd4db6842abd239f70a0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ace_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9aebd180ae4f41b0008ce41618b5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ban_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63199a6569984ab1bc06cbf9f8f0c7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bjn_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de148d27485f4423930374041840e681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bug_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733cf0d06bfd45f08de4e8743806284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_ace_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b42fa9d6374b4e882fe035161f010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_ban_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e7c4acc7f241f2ab024821e2b14426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_bjn_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b03766aa2a46b0a213a3f30fa5f077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_bug_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2ce1e8a96e45b5964b5479b8d4e0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180c9747baac4f28a3ee7eecb2103716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_jav_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac7f667242c4e89a876b3467ac58d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_mad_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70212851f5a34594a9eff799d9fe5a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_min_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867f508faad447149af027519cce3352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_nij_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb4e7bf54d94e7e9220f22ccfef8442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_sun_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3698a06451c4eaa8c81badfc406a945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_bbc_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1bd9e8ac60459b91c4bb0277d8fda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22f53a080bd45f2bccad78ff3938668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_jav_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e9f6cfa3894da8933f63d0339f30c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_mad_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e5c74f8f7742ac8fb9a326e393b5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_min_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc4a94a0ac0459c8edab8fef21c4f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_nij_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5041c936a409414bb0cfbf15bc1b34ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_sun_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a35f6f3b974311855fbb68ec610846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_xmt (/home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bbc_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a17186c0f264f7ba0392e8f338228b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'indo_general_mt_en_id_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 1821716\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_ace_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_ban_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_bjn_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_bug_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_ace_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_ban_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_bjn_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_bug_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_ind_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_jav_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_mad_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_min_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_nij_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_sun_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_eng_bbc_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_ind_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_jav_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_mad_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_min_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_nij_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_sun_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'nusax_mt_bbc_eng_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all splitted English sentiment analysis task\n",
    "lang = 'eng'\n",
    "task = Tasks.MACHINE_TRANSLATION\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & \n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "                \n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123a219f-007f-44c0-b490-376eb94c873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>subsets</th>\n",
       "      <th>source_link</th>\n",
       "      <th>hf_link</th>\n",
       "      <th>license</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>dialect</th>\n",
       "      <th>domain</th>\n",
       "      <th>...</th>\n",
       "      <th>dataloader</th>\n",
       "      <th>implemented</th>\n",
       "      <th>is_large</th>\n",
       "      <th>is_resource</th>\n",
       "      <th>is_default</th>\n",
       "      <th>is_broken</th>\n",
       "      <th>is_local</th>\n",
       "      <th>citation</th>\n",
       "      <th>homepage</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27</td>\n",
       "      <td>Idn-tagged-corpus-CSUI</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/ir-nlp-csui/idn-tagged-corp...</td>\n",
       "      <td>https://huggingface.co/datasets/indonlu</td>\n",
       "      <td>Creative Commons Attribution Share-Alike 4.0 I...</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>formal</td>\n",
       "      <td>news articles</td>\n",
       "      <td>...</td>\n",
       "      <td>idn_tagged_corpus_csui</td>\n",
       "      <td>17.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{dinakaramani2014designing,\\n  t...</td>\n",
       "      <td>https://bahasa.cs.ui.ac.id/postag/corpus</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>116</td>\n",
       "      <td>UD_Indonesian-CSUI</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>False</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>General, News articles</td>\n",
       "      <td>...</td>\n",
       "      <td>ud_id_csui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article {10.3844/jcssp.2020.1585.1597,\\nautho...</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                    name subsets  \\\n",
       "29    27  Idn-tagged-corpus-CSUI   False   \n",
       "153  116      UD_Indonesian-CSUI   False   \n",
       "\n",
       "                                           source_link  \\\n",
       "29   https://github.com/ir-nlp-csui/idn-tagged-corp...   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "\n",
       "                                     hf_link  \\\n",
       "29   https://huggingface.co/datasets/indonlu   \n",
       "153                                    False   \n",
       "\n",
       "                                               license    year language  \\\n",
       "29   Creative Commons Attribution Share-Alike 4.0 I...  2014.0      ind   \n",
       "153                                       CC BY-SA 4.0  2020.0      ind   \n",
       "\n",
       "    dialect                  domain  ...              dataloader implemented  \\\n",
       "29   formal           news articles  ...  idn_tagged_corpus_csui        17.0   \n",
       "153   False  General, News articles  ...              ud_id_csui         1.0   \n",
       "\n",
       "    is_large is_resource is_default is_broken is_local  \\\n",
       "29     False       False      False     False    False   \n",
       "153    False       False      False     False    False   \n",
       "\n",
       "                                              citation  \\\n",
       "29   @inproceedings{dinakaramani2014designing,\\n  t...   \n",
       "153  @article {10.3844/jcssp.2020.1585.1597,\\nautho...   \n",
       "\n",
       "                                              homepage  \\\n",
       "29            https://bahasa.cs.ui.ac.id/postag/corpus   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "\n",
       "                                              metadata  \n",
       "29   MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "153  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.loc[\n",
    "    (meta_df.name.str.contains('CSUI'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ef7b46-2598-40ac-9cbc-61ff2f64d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset sentiment_nathasa_review (/home/samuel/.cache/huggingface/datasets/sentiment_nathasa_review/sentiment_nathasa_review_nusantara_text/1.0.0/30eb0ea3a17ed2a9baea98645648c8f32804db498c2d57a7e376d733f0f9b89f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848485ef6ad4644b74393ba0a273b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indolem_sentiment_dataset (/home/samuel/.cache/huggingface/datasets/indolem_sentiment_dataset/indolem_sentiment_nusantara_text/1.0.0/b9050e6fcb7b7fa40f4dd502c92dc8c1df0ef30e067f1664af76c908c7b47467)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe55d1e564e641c2b23d652d16fe39c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset inset_lexicon (/home/samuel/.cache/huggingface/datasets/inset_lexicon/inset_lexicon_nusantara_text/1.0.0/337c7878219884751038f73a138360c5973ad6a454289b1d5e0572220d443fa0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c9b52e51cc4779b7df2518ef8a54df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_x_senti (/home/samuel/.cache/huggingface/datasets/nusa_x_senti/nusax_senti_ind_nusantara_text/1.0.0/3c834957d94e799c678f9be42ee6def4fcdbfdd0407b6add0d1bc875067b2ff9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6333ac0c7a2040eeb38cc70a81e9db19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset smsa (/home/samuel/.cache/huggingface/datasets/smsa/smsa_nusantara_text/1.0.0/c4914239fa9f7683736a2df989690905e1551838621298d799f0d1c78097a349)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8a58d41cef468895e5385fa5cb7025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sentiment_nathasa_review_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 62132\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 62131\n",
       "     })\n",
       " }),\n",
       " 'indolem_sentiment_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 3638\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1011\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 399\n",
       "     })\n",
       " }),\n",
       " 'inset_lexicon_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 10218\n",
       "     })\n",
       " }),\n",
       " 'nusax_senti_ind_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'smsa_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 11000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1260\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all Indonesian sentiment analysis task\n",
    "lang = 'ind'\n",
    "task = Tasks.SENTIMENT_ANALYSIS\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & \n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3958ab4b-3567-4170-aaa6-4fa3bd8da47d",
   "metadata": {},
   "source": [
    "If there is multiple tasks on a dataset, split it and filter schema out of it resulting in\n",
    "config meta from the original dataset meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "630f8fb1-840b-48e8-84ad-bfc0fa43a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>subsets</th>\n",
       "      <th>source_link</th>\n",
       "      <th>hf_link</th>\n",
       "      <th>license</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>dialect</th>\n",
       "      <th>domain</th>\n",
       "      <th>...</th>\n",
       "      <th>dataloader</th>\n",
       "      <th>implemented</th>\n",
       "      <th>is_large</th>\n",
       "      <th>is_resource</th>\n",
       "      <th>is_default</th>\n",
       "      <th>is_broken</th>\n",
       "      <th>is_local</th>\n",
       "      <th>citation</th>\n",
       "      <th>homepage</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>False</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>MIT</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind, sun, jav</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>cc100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{conneau-etal-2020-unsup...</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Javanese</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>jav</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Sundanese</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>sun</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>Customer Review (Natasha Skincare)</td>\n",
       "      <td>False</td>\n",
       "      <td>https://drive.google.com/file/d/1D1pHX7CxrI-eI...</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>...</td>\n",
       "      <td>sentiment_nathasa_review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article{nurlaila2018classification,\\n  title=...</td>\n",
       "      <td>https://jurnal.uns.ac.id/itsmart/article/viewF...</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>116</td>\n",
       "      <td>UD_Indonesian-CSUI</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>False</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>General, News articles</td>\n",
       "      <td>...</td>\n",
       "      <td>ud_id_csui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article {10.3844/jcssp.2020.1585.1597,\\nautho...</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>121</td>\n",
       "      <td>WikiAnn</td>\n",
       "      <td>ind, jav, bug, min, bjn, sun, ace, tet, ms, ma...</td>\n",
       "      <td>https://drive.google.com/drive/folders/1Q-xdT9...</td>\n",
       "      <td>https://huggingface.co/datasets/wikiann</td>\n",
       "      <td>Apache-2.0 license</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ind, eng, sun, jav, min, bug, bjn, tpi, ace, t...</td>\n",
       "      <td>Banyumasan</td>\n",
       "      <td>Wiki articles</td>\n",
       "      <td>...</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{pan-etal-2017-cross,\\n    title...</td>\n",
       "      <td>https://github.com/afshinrahimi/mmner</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>125</td>\n",
       "      <td>XCOPA</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://github.com/cambridgeltl/xcopa</td>\n",
       "      <td>https://huggingface.co/datasets/xcopa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>General</td>\n",
       "      <td>...</td>\n",
       "      <td>xcopa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{ponti2020xcopa,\\n  title={{XCOP...</td>\n",
       "      <td>https://github.com/cambridgeltl/xcopa</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>126</td>\n",
       "      <td>XL-Sum</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://github.com/csebuetnlp/xl-sum</td>\n",
       "      <td>https://huggingface.co/datasets/csebuetnlp/xlsum</td>\n",
       "      <td>CC-BY-NC-SA 4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>News articles</td>\n",
       "      <td>...</td>\n",
       "      <td>xl_sum</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{hasan2021xl,\\n  title={XL-Sum: ...</td>\n",
       "      <td>https://github.com/csebuetnlp/xl-sum</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>127</td>\n",
       "      <td>XPersona Id</td>\n",
       "      <td>False</td>\n",
       "      <td>https://storage.googleapis.com/babert-pretrain...</td>\n",
       "      <td>-</td>\n",
       "      <td>CC-BY-SA 4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>conversational</td>\n",
       "      <td>...</td>\n",
       "      <td>xpersona_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article{lin2020xpersona,\\n  title={XPersona: ...</td>\n",
       "      <td></td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                name  \\\n",
       "3      4                               CC100   \n",
       "4      4                               CC100   \n",
       "5      4                               CC100   \n",
       "6      4                               CC100   \n",
       "11     9  Customer Review (Natasha Skincare)   \n",
       "..   ...                                 ...   \n",
       "153  116                  UD_Indonesian-CSUI   \n",
       "158  121                             WikiAnn   \n",
       "162  125                               XCOPA   \n",
       "163  126                              XL-Sum   \n",
       "164  127                         XPersona Id   \n",
       "\n",
       "                                               subsets  \\\n",
       "3                                                False   \n",
       "4                                           Indonesian   \n",
       "5                                             Javanese   \n",
       "6                                            Sundanese   \n",
       "11                                               False   \n",
       "..                                                 ...   \n",
       "153                                              False   \n",
       "158  ind, jav, bug, min, bjn, sun, ace, tet, ms, ma...   \n",
       "162                                         Indonesian   \n",
       "163                                         Indonesian   \n",
       "164                                              False   \n",
       "\n",
       "                                           source_link  \\\n",
       "3                      https://data.statmt.org/cc-100/   \n",
       "4                      https://data.statmt.org/cc-100/   \n",
       "5                      https://data.statmt.org/cc-100/   \n",
       "6                      https://data.statmt.org/cc-100/   \n",
       "11   https://drive.google.com/file/d/1D1pHX7CxrI-eI...   \n",
       "..                                                 ...   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "158  https://drive.google.com/drive/folders/1Q-xdT9...   \n",
       "162              https://github.com/cambridgeltl/xcopa   \n",
       "163               https://github.com/csebuetnlp/xl-sum   \n",
       "164  https://storage.googleapis.com/babert-pretrain...   \n",
       "\n",
       "                                              hf_link                 license  \\\n",
       "3               https://huggingface.co/datasets/cc100                     MIT   \n",
       "4               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "5               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "6               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "11                                              False                 Unknown   \n",
       "..                                                ...                     ...   \n",
       "153                                             False            CC BY-SA 4.0   \n",
       "158           https://huggingface.co/datasets/wikiann      Apache-2.0 license   \n",
       "162             https://huggingface.co/datasets/xcopa                 Unknown   \n",
       "163  https://huggingface.co/datasets/csebuetnlp/xlsum         CC-BY-NC-SA 4.0   \n",
       "164                                                 -            CC-BY-SA 4.0   \n",
       "\n",
       "       year                                           language     dialect  \\\n",
       "3    2020.0                                      ind, sun, jav       other   \n",
       "4    2020.0                                                ind       other   \n",
       "5    2020.0                                                jav       other   \n",
       "6    2020.0                                                sun       other   \n",
       "11   2017.0                                                ind       False   \n",
       "..      ...                                                ...         ...   \n",
       "153  2020.0                                                ind       False   \n",
       "158  2017.0  ind, eng, sun, jav, min, bug, bjn, tpi, ace, t...  Banyumasan   \n",
       "162  2021.0                                                ind       False   \n",
       "163  2021.0                                                ind       False   \n",
       "164  2021.0                                                ind  colloquial   \n",
       "\n",
       "                     domain  ...                dataloader implemented  \\\n",
       "3              multi domain  ...                     cc100         1.0   \n",
       "4              multi domain  ...                     False       False   \n",
       "5              multi domain  ...                     False       False   \n",
       "6              multi domain  ...                     False       False   \n",
       "11             Social media  ...  sentiment_nathasa_review         1.0   \n",
       "..                      ...  ...                       ...         ...   \n",
       "153  General, News articles  ...                ud_id_csui         1.0   \n",
       "158           Wiki articles  ...                   wikiann         1.0   \n",
       "162                 General  ...                     xcopa         1.0   \n",
       "163           News articles  ...                    xl_sum         1.0   \n",
       "164          conversational  ...               xpersona_id         1.0   \n",
       "\n",
       "    is_large is_resource is_default is_broken is_local  \\\n",
       "3      False       False      False     False    False   \n",
       "4      False       False      False     False    False   \n",
       "5      False       False      False     False    False   \n",
       "6      False       False      False     False    False   \n",
       "11     False       False      False     False    False   \n",
       "..       ...         ...        ...       ...      ...   \n",
       "153    False       False      False     False    False   \n",
       "158    False       False      False     False    False   \n",
       "162    False       False      False     False    False   \n",
       "163    False       False      False     False    False   \n",
       "164    False       False      False     False    False   \n",
       "\n",
       "                                              citation  \\\n",
       "3            @inproceedings{conneau-etal-2020-unsup...   \n",
       "4                                                False   \n",
       "5                                                False   \n",
       "6                                                False   \n",
       "11   @article{nurlaila2018classification,\\n  title=...   \n",
       "..                                                 ...   \n",
       "153  @article {10.3844/jcssp.2020.1585.1597,\\nautho...   \n",
       "158  @inproceedings{pan-etal-2017-cross,\\n    title...   \n",
       "162  @inproceedings{ponti2020xcopa,\\n  title={{XCOP...   \n",
       "163  @inproceedings{hasan2021xl,\\n  title={XL-Sum: ...   \n",
       "164  @article{lin2020xpersona,\\n  title={XPersona: ...   \n",
       "\n",
       "                                              homepage  \\\n",
       "3                      https://data.statmt.org/cc-100/   \n",
       "4                                                False   \n",
       "5                                                False   \n",
       "6                                                False   \n",
       "11   https://jurnal.uns.ac.id/itsmart/article/viewF...   \n",
       "..                                                 ...   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "158              https://github.com/afshinrahimi/mmner   \n",
       "162              https://github.com/cambridgeltl/xcopa   \n",
       "163               https://github.com/csebuetnlp/xl-sum   \n",
       "164                                                      \n",
       "\n",
       "                                              metadata  \n",
       "3    MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "4                                                  NaN  \n",
       "5                                                  NaN  \n",
       "6                                                  NaN  \n",
       "11   MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "..                                                 ...  \n",
       "153  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "158  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "162  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "163  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "164  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "\n",
       "[98 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all Indonesian sentiment analysis task\n",
    "lang = 'ind'\n",
    "task = Tasks.SENTIMENT_ANALYSIS\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663f21ff-a18b-4448-ab25-5764939c8826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>subsets</th>\n",
       "      <th>source_link</th>\n",
       "      <th>hf_link</th>\n",
       "      <th>license</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>dialect</th>\n",
       "      <th>domain</th>\n",
       "      <th>...</th>\n",
       "      <th>dataloader</th>\n",
       "      <th>implemented</th>\n",
       "      <th>is_large</th>\n",
       "      <th>is_resource</th>\n",
       "      <th>is_default</th>\n",
       "      <th>is_broken</th>\n",
       "      <th>is_local</th>\n",
       "      <th>citation</th>\n",
       "      <th>homepage</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>False</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>MIT</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind, sun, jav</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>cc100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{conneau-etal-2020-unsup...</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Javanese</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>jav</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>CC100</td>\n",
       "      <td>Sundanese</td>\n",
       "      <td>https://data.statmt.org/cc-100/</td>\n",
       "      <td>https://huggingface.co/datasets/cc100</td>\n",
       "      <td>Common Crawl's license</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>sun</td>\n",
       "      <td>other</td>\n",
       "      <td>multi domain</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>Customer Review (Natasha Skincare)</td>\n",
       "      <td>False</td>\n",
       "      <td>https://drive.google.com/file/d/1D1pHX7CxrI-eI...</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>...</td>\n",
       "      <td>sentiment_nathasa_review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article{nurlaila2018classification,\\n  title=...</td>\n",
       "      <td>https://jurnal.uns.ac.id/itsmart/article/viewF...</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>116</td>\n",
       "      <td>UD_Indonesian-CSUI</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>False</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>General, News articles</td>\n",
       "      <td>...</td>\n",
       "      <td>ud_id_csui</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article {10.3844/jcssp.2020.1585.1597,\\nautho...</td>\n",
       "      <td>https://github.com/UniversalDependencies/UD_In...</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>121</td>\n",
       "      <td>WikiAnn</td>\n",
       "      <td>ind, jav, bug, min, bjn, sun, ace, tet, ms, ma...</td>\n",
       "      <td>https://drive.google.com/drive/folders/1Q-xdT9...</td>\n",
       "      <td>https://huggingface.co/datasets/wikiann</td>\n",
       "      <td>Apache-2.0 license</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>ind, eng, sun, jav, min, bug, bjn, tpi, ace, t...</td>\n",
       "      <td>Banyumasan</td>\n",
       "      <td>Wiki articles</td>\n",
       "      <td>...</td>\n",
       "      <td>wikiann</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{pan-etal-2017-cross,\\n    title...</td>\n",
       "      <td>https://github.com/afshinrahimi/mmner</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>125</td>\n",
       "      <td>XCOPA</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://github.com/cambridgeltl/xcopa</td>\n",
       "      <td>https://huggingface.co/datasets/xcopa</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>General</td>\n",
       "      <td>...</td>\n",
       "      <td>xcopa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{ponti2020xcopa,\\n  title={{XCOP...</td>\n",
       "      <td>https://github.com/cambridgeltl/xcopa</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>126</td>\n",
       "      <td>XL-Sum</td>\n",
       "      <td>Indonesian</td>\n",
       "      <td>https://github.com/csebuetnlp/xl-sum</td>\n",
       "      <td>https://huggingface.co/datasets/csebuetnlp/xlsum</td>\n",
       "      <td>CC-BY-NC-SA 4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>False</td>\n",
       "      <td>News articles</td>\n",
       "      <td>...</td>\n",
       "      <td>xl_sum</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@inproceedings{hasan2021xl,\\n  title={XL-Sum: ...</td>\n",
       "      <td>https://github.com/csebuetnlp/xl-sum</td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>127</td>\n",
       "      <td>XPersona Id</td>\n",
       "      <td>False</td>\n",
       "      <td>https://storage.googleapis.com/babert-pretrain...</td>\n",
       "      <td>-</td>\n",
       "      <td>CC-BY-SA 4.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>conversational</td>\n",
       "      <td>...</td>\n",
       "      <td>xpersona_id</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>@article{lin2020xpersona,\\n  title={XPersona: ...</td>\n",
       "      <td></td>\n",
       "      <td>MetaDict(data={'source': [NusantaraMetadata(sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                name  \\\n",
       "3      4                               CC100   \n",
       "4      4                               CC100   \n",
       "5      4                               CC100   \n",
       "6      4                               CC100   \n",
       "11     9  Customer Review (Natasha Skincare)   \n",
       "..   ...                                 ...   \n",
       "153  116                  UD_Indonesian-CSUI   \n",
       "158  121                             WikiAnn   \n",
       "162  125                               XCOPA   \n",
       "163  126                              XL-Sum   \n",
       "164  127                         XPersona Id   \n",
       "\n",
       "                                               subsets  \\\n",
       "3                                                False   \n",
       "4                                           Indonesian   \n",
       "5                                             Javanese   \n",
       "6                                            Sundanese   \n",
       "11                                               False   \n",
       "..                                                 ...   \n",
       "153                                              False   \n",
       "158  ind, jav, bug, min, bjn, sun, ace, tet, ms, ma...   \n",
       "162                                         Indonesian   \n",
       "163                                         Indonesian   \n",
       "164                                              False   \n",
       "\n",
       "                                           source_link  \\\n",
       "3                      https://data.statmt.org/cc-100/   \n",
       "4                      https://data.statmt.org/cc-100/   \n",
       "5                      https://data.statmt.org/cc-100/   \n",
       "6                      https://data.statmt.org/cc-100/   \n",
       "11   https://drive.google.com/file/d/1D1pHX7CxrI-eI...   \n",
       "..                                                 ...   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "158  https://drive.google.com/drive/folders/1Q-xdT9...   \n",
       "162              https://github.com/cambridgeltl/xcopa   \n",
       "163               https://github.com/csebuetnlp/xl-sum   \n",
       "164  https://storage.googleapis.com/babert-pretrain...   \n",
       "\n",
       "                                              hf_link                 license  \\\n",
       "3               https://huggingface.co/datasets/cc100                     MIT   \n",
       "4               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "5               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "6               https://huggingface.co/datasets/cc100  Common Crawl's license   \n",
       "11                                              False                 Unknown   \n",
       "..                                                ...                     ...   \n",
       "153                                             False            CC BY-SA 4.0   \n",
       "158           https://huggingface.co/datasets/wikiann      Apache-2.0 license   \n",
       "162             https://huggingface.co/datasets/xcopa                 Unknown   \n",
       "163  https://huggingface.co/datasets/csebuetnlp/xlsum         CC-BY-NC-SA 4.0   \n",
       "164                                                 -            CC-BY-SA 4.0   \n",
       "\n",
       "       year                                           language     dialect  \\\n",
       "3    2020.0                                      ind, sun, jav       other   \n",
       "4    2020.0                                                ind       other   \n",
       "5    2020.0                                                jav       other   \n",
       "6    2020.0                                                sun       other   \n",
       "11   2017.0                                                ind       False   \n",
       "..      ...                                                ...         ...   \n",
       "153  2020.0                                                ind       False   \n",
       "158  2017.0  ind, eng, sun, jav, min, bug, bjn, tpi, ace, t...  Banyumasan   \n",
       "162  2021.0                                                ind       False   \n",
       "163  2021.0                                                ind       False   \n",
       "164  2021.0                                                ind  colloquial   \n",
       "\n",
       "                     domain  ...                dataloader implemented  \\\n",
       "3              multi domain  ...                     cc100         1.0   \n",
       "4              multi domain  ...                     False       False   \n",
       "5              multi domain  ...                     False       False   \n",
       "6              multi domain  ...                     False       False   \n",
       "11             Social media  ...  sentiment_nathasa_review         1.0   \n",
       "..                      ...  ...                       ...         ...   \n",
       "153  General, News articles  ...                ud_id_csui         1.0   \n",
       "158           Wiki articles  ...                   wikiann         1.0   \n",
       "162                 General  ...                     xcopa         1.0   \n",
       "163           News articles  ...                    xl_sum         1.0   \n",
       "164          conversational  ...               xpersona_id         1.0   \n",
       "\n",
       "    is_large is_resource is_default is_broken is_local  \\\n",
       "3      False       False      False     False    False   \n",
       "4      False       False      False     False    False   \n",
       "5      False       False      False     False    False   \n",
       "6      False       False      False     False    False   \n",
       "11     False       False      False     False    False   \n",
       "..       ...         ...        ...       ...      ...   \n",
       "153    False       False      False     False    False   \n",
       "158    False       False      False     False    False   \n",
       "162    False       False      False     False    False   \n",
       "163    False       False      False     False    False   \n",
       "164    False       False      False     False    False   \n",
       "\n",
       "                                              citation  \\\n",
       "3            @inproceedings{conneau-etal-2020-unsup...   \n",
       "4                                                False   \n",
       "5                                                False   \n",
       "6                                                False   \n",
       "11   @article{nurlaila2018classification,\\n  title=...   \n",
       "..                                                 ...   \n",
       "153  @article {10.3844/jcssp.2020.1585.1597,\\nautho...   \n",
       "158  @inproceedings{pan-etal-2017-cross,\\n    title...   \n",
       "162  @inproceedings{ponti2020xcopa,\\n  title={{XCOP...   \n",
       "163  @inproceedings{hasan2021xl,\\n  title={XL-Sum: ...   \n",
       "164  @article{lin2020xpersona,\\n  title={XPersona: ...   \n",
       "\n",
       "                                              homepage  \\\n",
       "3                      https://data.statmt.org/cc-100/   \n",
       "4                                                False   \n",
       "5                                                False   \n",
       "6                                                False   \n",
       "11   https://jurnal.uns.ac.id/itsmart/article/viewF...   \n",
       "..                                                 ...   \n",
       "153  https://github.com/UniversalDependencies/UD_In...   \n",
       "158              https://github.com/afshinrahimi/mmner   \n",
       "162              https://github.com/cambridgeltl/xcopa   \n",
       "163               https://github.com/csebuetnlp/xl-sum   \n",
       "164                                                      \n",
       "\n",
       "                                              metadata  \n",
       "3    MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "4                                                  NaN  \n",
       "5                                                  NaN  \n",
       "6                                                  NaN  \n",
       "11   MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "..                                                 ...  \n",
       "153  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "158  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "162  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "163  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "164  MetaDict(data={'source': [NusantaraMetadata(sc...  \n",
       "\n",
       "[98 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcfaff7-0688-484c-b5af-f35636b0906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_CLASSIFICATION_TASKS = [\n",
    "    # Single Label Classification\n",
    "    'emot_nusantara_text',\n",
    "    'emotcmt_nusantara_text',\n",
    "    'emotion_id_opinion_nusantara_text',\n",
    "    'id_abusive_nusantara_text',\n",
    "    'id_clickbait_nusantara_text',\n",
    "    'id_google_play_review_nusantara_text',\n",
    "    'id_google_play_review_posneg_nusantara_text',\n",
    "    'id_hatespeech_nusantara_text',\n",
    "    'imdb_jv_nusantara_text',\n",
    "    'indolem_sentiment_nusantara_text',\n",
    "    'jadi_ide_nusantara_text',\n",
    "    'nusax_senti_ace_nusantara_text',\n",
    "    'nusax_senti_ban_nusantara_text',\n",
    "    'nusax_senti_bjn_nusantara_text',\n",
    "    'nusax_senti_bug_nusantara_text',\n",
    "    'nusax_senti_eng_nusantara_text',\n",
    "    'nusax_senti_ind_nusantara_text',\n",
    "    'nusax_senti_jav_nusantara_text',\n",
    "    'nusax_senti_mad_nusantara_text',\n",
    "    'nusax_senti_min_nusantara_text',\n",
    "    'nusax_senti_nij_nusantara_text',\n",
    "    'nusax_senti_sun_nusantara_text',\n",
    "    'nusax_senti_bbc_nusantara_text',\n",
    "    'nusax_senti_nusantara_text',\n",
    "    'sentiment_nathasa_review_nusantara_text',\n",
    "    'smsa_nusantara_text',\n",
    "    # Pair Sentence Classification\n",
    "    'id_stance_nusantara_pairs',\n",
    "    'indolem_ntp_nusantara_pairs',\n",
    "    'indonli_nusantara_pairs',\n",
    "    'id_sts_nusantara_pairs_score',\n",
    "    # Multilabel Classification\n",
    "    'casa_nusantara_text_multi',\n",
    "    'hoasa_nusantara_text_multi',\n",
    "    'netifier_nusantara_text_multi',\n",
    "    'id_multilabel_hs_nusantara_text_multi',\n",
    "]\n",
    "\n",
    "TEXT_GENERATION_TASKS = [\n",
    "    # MT\n",
    "    'bible_en_id_nusantara_t2t',\n",
    "    'bible_jv_id_nusantara_t2t',\n",
    "    'bible_su_id_nusantara_t2t',\n",
    "    'id_panl_bppt_nusantara_t2t',\n",
    "    'indo_general_mt_en_id_nusantara_t2t',\n",
    "    'indo_religious_mt_en_id_nusantara_t2t',\n",
    "    'minangnlp_mt_nusantara_t2t',\n",
    "    'news_en_id_nusantara_t2t',\n",
    "    'nusax_mt_ace_ind_nusantara_t2t',\n",
    "    'nusax_mt_ban_ind_nusantara_t2t',\n",
    "    'nusax_mt_bjn_ind_nusantara_t2t',\n",
    "    'nusax_mt_bug_ind_nusantara_t2t',\n",
    "    'nusax_mt_eng_ind_nusantara_t2t',\n",
    "    'nusax_mt_ind_ace_nusantara_t2t',\n",
    "    'nusax_mt_ind_ban_nusantara_t2t',\n",
    "    'nusax_mt_ind_bjn_nusantara_t2t',\n",
    "    'nusax_mt_ind_bug_nusantara_t2t',\n",
    "    'nusax_mt_ind_eng_nusantara_t2t',\n",
    "    'nusax_mt_ind_jav_nusantara_t2t',\n",
    "    'nusax_mt_ind_mad_nusantara_t2t',\n",
    "    'nusax_mt_ind_min_nusantara_t2t',\n",
    "    'nusax_mt_ind_nij_nusantara_t2t',\n",
    "    'nusax_mt_ind_sun_nusantara_t2t',\n",
    "    'nusax_mt_ind_bbc_nusantara_t2t',\n",
    "    'nusax_mt_jav_ind_nusantara_t2t',\n",
    "    'nusax_mt_mad_ind_nusantara_t2t',\n",
    "    'nusax_mt_min_ind_nusantara_t2t',\n",
    "    'nusax_mt_nij_ind_nusantara_t2t',\n",
    "    'nusax_mt_sun_ind_nusantara_t2t',\n",
    "    'nusax_mt_bbc_ind_nusantara_t2t',\n",
    "    'parallel_su_id_nusantara_t2t',\n",
    "    'ted_en_id_nusantara_t2t',\n",
    "    'ud_id_csui_nusantara_t2t',\n",
    "    # Paraphrasing\n",
    "    # 'id_qqp_nusantara_t2t',\n",
    "    # 'paracotta_id_nusantara_t2t',\n",
    "    'stif_indonesia_nusantara_t2t',\n",
    "    # Summarization\n",
    "    'indosum_fold0_nusantara_t2t',\n",
    "    'xl_sum_nusantara_t2t',\n",
    "    # Dialogue System\n",
    "    'xpersona_id_nusantara_t2t',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97830753-c594-44b2-99f3-aa36dfbe310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_tasks = [\n",
    "    Tasks.QUESTION_ANSWERING,\n",
    "    Tasks.TEXTUAL_ENTAILMENT,\n",
    "    Tasks.SEMANTIC_SIMILARITY,\n",
    "    Tasks.NEXT_SENTENCE_PREDICTION,\n",
    "    Tasks.SHORT_ANSWER_GRADING,\n",
    "    Tasks.MORPHOLOGICAL_INFLECTION,\n",
    "    Tasks.SENTIMENT_ANALYSIS,\n",
    "    Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS,\n",
    "    Tasks.TAX_COURT_VERDICT,\n",
    "    Tasks.EMOTION_CLASSIFICATION,\n",
    "    Tasks.LEGAL_CLASSIFICATION,\n",
    "    Tasks.INTENT_CLASSIFICATION,\n",
    "    Tasks.HOAX_NEWS_CLASSIFICATION\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b474b49-db85-4e43-b44a-97b5204b5643",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = []\n",
    "for conhelp in conhelps.filtered(lambda x: x.is_nusantara_schema):\n",
    "    for task in conhelp.tasks:\n",
    "        if task in nlu_tasks:\n",
    "            configs.append(conhelp.config.name)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5de369-08c0-4b61-a798-c8fda2db64f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code_mixed_jv_id_jv_nusantara_text',\n",
       " 'code_mixed_jv_id_id_nusantara_text',\n",
       " 'emot_nusantara_text',\n",
       " 'emotcmt_nusantara_text',\n",
       " 'emotion_id_opinion_nusantara_text',\n",
       " 'facqa_nusantara_qa',\n",
       " 'id_abusive_nusantara_text',\n",
       " 'id_abusive_news_comment_nusantara_text',\n",
       " 'id_clickbait_nusantara_text',\n",
       " 'id_google_play_review_nusantara_text',\n",
       " 'id_google_play_review_posneg_nusantara_text',\n",
       " 'id_hatespeech_nusantara_text',\n",
       " 'id_hoax_news_nusantara_text',\n",
       " 'id_hsd_nofaaulia_nusantara_text',\n",
       " 'id_stance_nusantara_pairs',\n",
       " 'idk_mrc_nusantara_qa',\n",
       " 'idk_mrc_baseline_trans_squad_nusantara_qa',\n",
       " 'idk_mrc_baseline_tydiqa_nusantara_qa',\n",
       " 'idk_mrc_baseline_model_gen_nusantara_qa',\n",
       " 'idk_mrc_baseline_human_filt_nusantara_qa',\n",
       " 'imdb_jv_nusantara_text',\n",
       " 'indo_law_nusantara_text',\n",
       " 'indolem_ntp_nusantara_pairs',\n",
       " 'indolem_sentiment_nusantara_text',\n",
       " 'indonli_nusantara_pairs',\n",
       " 'indotacos_nusantara_text',\n",
       " 'inset_lexicon_nusantara_text',\n",
       " 'jadi_ide_nusantara_text',\n",
       " 'karonese_sentiment_nusantara_text',\n",
       " 'nusax_senti_ace_nusantara_text',\n",
       " 'nusax_senti_ban_nusantara_text',\n",
       " 'nusax_senti_bjn_nusantara_text',\n",
       " 'nusax_senti_bug_nusantara_text',\n",
       " 'nusax_senti_eng_nusantara_text',\n",
       " 'nusax_senti_ind_nusantara_text',\n",
       " 'nusax_senti_jav_nusantara_text',\n",
       " 'nusax_senti_mad_nusantara_text',\n",
       " 'nusax_senti_min_nusantara_text',\n",
       " 'nusax_senti_nij_nusantara_text',\n",
       " 'nusax_senti_sun_nusantara_text',\n",
       " 'nusax_senti_bbc_nusantara_text',\n",
       " 'nusax_senti_nusantara_text',\n",
       " 'sentiment_nathasa_review_nusantara_text',\n",
       " 'smsa_nusantara_text',\n",
       " 'squad_id_nusantara_qa',\n",
       " 'su_emot_nusantara_text',\n",
       " 'tydiqa_id_nusantara_qa',\n",
       " 'wrete_nusantara_pairs',\n",
       " 'xcopa_nusantara_qa',\n",
       " 'xsid_nusantara_text']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd918a-f1c4-4274-9080-cb70f4d21d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classification_datasets = {helper.config.name: helper.load_dataset() for helper in .filtered(lambda x: x.config.name in TEXT_CLASSIFICATION_TASKS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0882dbf-34ac-4023-9d4b-685cdec44772",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bible_en_id/bible_en_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/bible_en_id/bible_en_id_nusantara_t2t/1.0.0/0914cfc955aeb37cf55222ac526adcdeea078a3d4fac89b7e24be78197f28584...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bible_en_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/bible_en_id/bible_en_id_nusantara_t2t/1.0.0/0914cfc955aeb37cf55222ac526adcdeea078a3d4fac89b7e24be78197f28584. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db973464135549458604b3d3ce6e7a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bible_en_id/bible_jv_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/bible_en_id/bible_jv_id_nusantara_t2t/1.0.0/94cb64872abc2af5dbc51e125560e3584ad3490a12276f6274811ffc690b6577...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bible_en_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/bible_en_id/bible_jv_id_nusantara_t2t/1.0.0/94cb64872abc2af5dbc51e125560e3584ad3490a12276f6274811ffc690b6577. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83f81947d144346b6c6c23f8cdcc28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bible_su_id/bible_su_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/bible_su_id/bible_su_id_nusantara_t2t/1.0.0/afe00cbc1bbbc8c3fdcbfa5d75ef6d8eca68cbb42bfdfbefb1efe66777190b55...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bible_su_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/bible_su_id/bible_su_id_nusantara_t2t/1.0.0/afe00cbc1bbbc8c3fdcbfa5d75ef6d8eca68cbb42bfdfbefb1efe66777190b55. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d448372a7de24622ab81feca5b93985b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset id_panl_bppt/id_panl_bppt_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/id_panl_bppt/id_panl_bppt_nusantara_t2t/1.0.0/3e0338dbc7d5c3b44c5ca68d5374c363476db1453d10206c1c04f1bbc4b57d0b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328d45f130a74580bcb3ff4ced833057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset id_panl_bppt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/id_panl_bppt/id_panl_bppt_nusantara_t2t/1.0.0/3e0338dbc7d5c3b44c5ca68d5374c363476db1453d10206c1c04f1bbc4b57d0b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a59e93113e04000a24e13145c919635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset id_quora_question_pairs/id_qqp_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/id_quora_question_pairs/id_qqp_nusantara_t2t/1.0.0/eed59379992ba1ede73b9720cadb64df39bbe8f05c831517b241e7920135147d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec168bf731634fe6916744420661c9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59b6f2ef32943d3a0a6a445b58e6b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset id_quora_question_pairs downloaded and prepared to /home/samuel/.cache/huggingface/datasets/id_quora_question_pairs/id_qqp_nusantara_t2t/1.0.0/eed59379992ba1ede73b9720cadb64df39bbe8f05c831517b241e7920135147d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30c3a25e6cc4284b282b2c839dc9868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indo_general_mt_en_id (/home/samuel/.cache/huggingface/datasets/indo_general_mt_en_id/indo_general_mt_en_id_nusantara_t2t/1.0.0/8997ff3f81a5107662a8a4d0e405a1e053a076327735146c76b56dd6c263e4c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbd3e4a4d324fcea4f39a64811f322c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset indo_religious_mt_en_id/indo_religious_mt_en_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/indo_religious_mt_en_id/indo_religious_mt_en_id_nusantara_t2t/1.0.0/3436a2763dcd62dd8a14e3c8d12e1b99fad9e4d82b32d68131c87b5b77b581f7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b76578a045b4d60a57e9a4f8d61b68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/164k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcec99f0268c4e7f837b57ffec37be14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4e8c995c2b4e98ac7abeaa33ec796e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/169k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402a70ed1dc94416993288b00d1e0695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/186k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095fff00d0934d4bbc7f7593b6e8b653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a59023c7c12416aa11852a22520c39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221242f50e9c4d38b48d881feab5a7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/16.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd69a3449544ed3ad4f5d1b8cfa5626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indo_religious_mt_en_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/indo_religious_mt_en_id/indo_religious_mt_en_id_nusantara_t2t/1.0.0/3436a2763dcd62dd8a14e3c8d12e1b99fad9e4d82b32d68131c87b5b77b581f7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce79a4a6eb24dc292920c69aa22f410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset indo_sum/indosum_fold0_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/indo_sum/indosum_fold0_nusantara_t2t/1.0.0/f779ca1f657fd0562f1534b73b03183ed41ad8f80f4b8003b0a19bd0e0888633...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa22e23877d2466db5f51c9c9a7b4621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/96.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bdfa1245054979a74ec92becc481bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset indo_sum downloaded and prepared to /home/samuel/.cache/huggingface/datasets/indo_sum/indosum_fold0_nusantara_t2t/1.0.0/f779ca1f657fd0562f1534b73b03183ed41ad8f80f4b8003b0a19bd0e0888633. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b5ec95dba54bdca36569523e6c242b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset minang_nl_pmt/minangnlp_mt_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/minang_nl_pmt/minangnlp_mt_nusantara_t2t/1.0.0/d95956ac1d04411db5056a7f3824a31458a4accf72975e82173cdb4686dd1c84...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17949647f365450eb50474469f367eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baba513d62164e1b8ea269ac04cbb582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd06104d2694abcbd82b76f5eed3615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b05eddcf8b47368f02f9acf7945762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset minang_nl_pmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/minang_nl_pmt/minangnlp_mt_nusantara_t2t/1.0.0/d95956ac1d04411db5056a7f3824a31458a4accf72975e82173cdb4686dd1c84. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce7d0dafd640759889fba3c7b231e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset news_en_id/news_en_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/news_en_id/news_en_id_nusantara_t2t/1.0.0/a5c9608bc6314f138f35d229f18bd181d0f95902da4efb90106a8a3cd02a9f74...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e285e237f04a46f5b3309e0f495f82df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9b37b38ca847d595b92beacf4ad5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b3fd269a8e46dfb6637e5eb78e9a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset news_en_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/news_en_id/news_en_id_nusantara_t2t/1.0.0/a5c9608bc6314f138f35d229f18bd181d0f95902da4efb90106a8a3cd02a9f74. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d485307be92c453b94ea2c4a9bcea6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ace_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ace_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5068f04edcc400aa1f7ea643b795d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/354k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b8d163319a4c559c442c2f711728bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/70.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc9f87b67b041dda57c428eb0f41aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/285k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3397580e89490b96f245c73828e66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f5e886aac14f519e1507bb4c2f1355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fa13741cc244f9a76969fcaba5e831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ace_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4be0d5247b42c29e747579bcd9bed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ban_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ban_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb961608e294708a82c72da2c397a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4ca10afb641418c17af2ad48128f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc2342ccd244459da5af416ff5d517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ban_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c90c45870a45789fd496dffc6f7392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_bjn_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bjn_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b24f88d4a524a8db75cb2e146942984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2961c31c35cc411d9ef04e71361b0810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c98a119a4246a8af1111c559f62c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bjn_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1ff6fd67b64dbca25aca1518ae40c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_bug_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bug_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe70c44a4cc4192b09495e802e2fcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d191a24827b450eb887c09b45fecc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ec231f10d04c63b3f645bfb3ed29b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bug_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494e8c65d17b43e3bbf99749a4d06f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_eng_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a42e6b4c839471e86e9e2c358c3e0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0453a7a7edc4c3a8d6ca15b97efa908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de652d4b7999467c893a270486330201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_eng_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0ef781628644b894fae5784eb39533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_ace_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_ace_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc11b6ae9bbb4d0a906fd76c1b903a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b402195dbcd046aca96e6c4be5f63e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d340d5eb2046e2a6cdab1eb97ef2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_ace_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd8d3965247470da22e7d7f52310de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_ban_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_ban_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb625a017c6491aa42312ff79a74484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7385309c3a44f028a67ef99a4d1a6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fad734d13a2426cbca92923ef316f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_ban_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e65f0befd44b7ca15a3c1e802b58d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_bjn_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bjn_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c1ce9ddbcf42b4b195644e5fcb033c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d899ad02fcc46258d8951cd4d87a983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f01a63a11a481195244cf37458bc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bjn_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad707fd5a0a43da8b581691dafd75ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_bug_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bug_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b382151dd24c57aa9ce13d7e161d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450df42a67e6426c81b9152c6ad6a498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3209eadbd04c0680bd0f83b2673339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bug_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee88236a89f64c74bfd9d9a8170364f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_eng_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abad40569a246918a90d8443e773aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613bf63485e8433f9f3bfb7d4f8baee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b1f81f9ff6473694f580876bd8d116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_eng_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f074a098a42d4a0472683cc568850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_jav_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_jav_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2634a06127574baf8379f66368629dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d452f93aa17247b1a9daefef324e3c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b8e648f19e4a2dbb2fb7283f02cccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_jav_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444170dc187b450d9703165461388919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_mad_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_mad_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4e4e35ffa4335a12b725f89f5ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464faf0b3d4745448b9f820b9964abf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe452fda90af4ec192bbf9547a20a819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_mad_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9624a121bb44bda6112a2e83aeff5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_min_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_min_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9963e687ebb845819356e9be4a261796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21790038c8d345d2afd4881d0ce4f6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5f819b5829407b859ca075d40d552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_min_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081c7452d81e4749838ad2cea6a8af79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_nij_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_nij_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f308f556cd25465eb5ba2371401f8990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1cb7fc50f41eca1090ba453386608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df09c05ff0d148b08f157bdf47a9d3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_nij_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5b0aab03b9492f85700a0963b5b80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_sun_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_sun_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851e926ee8c84e22bf9808e038b613e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d67d740d294042ada13a01c3f1c95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d49bf8497eb4827966eac07b283fbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_sun_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbc7a22086e46d8914185f30fa48c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_ind_bbc_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bbc_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7cf6e0b6c74433bb16bfcf695fafc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef4ff8e440486d996bddd1a824ee3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569d93c502bd4586a71b46f45f0e724f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_ind_bbc_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1c676cb1ae4051abdadb227aa75cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_jav_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_jav_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec340414a6ec40a1a048a134b954d99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a75e126dec442294c99c6d291a24a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3fc1d167da4fe8aabec617a2e31c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_jav_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b073264680174215bd4ac85a250d5820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_mad_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_mad_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70a04fe78b4418c94ab5f014a6bb76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd41ae2f3a64d7eb1f3334c52ec750b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c7f2fab2fd484e88baed37785f4931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_mad_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ddf2f760f422cad310dbd88ea332b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_min_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_min_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c9f4fcbf354828942ee71f55b91d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf118ee8432472ab1550b5da80dedc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee586a0c2a94e12929276714879550f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_min_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e532a7593c40a4b7d2023dc0ef151e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_nij_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_nij_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ca88e175e74d2fad0fe42974f2f079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27d3aa640294129ab7783e4af40f496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1498cf6642c1401182cf0d5c4001dce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_nij_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69b86c84007463f8521b09c36c7ba05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_sun_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_sun_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a218e45414846bfa5a2f75cb3f2a6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58dd4b0999d4a3ba54510a5f665db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb15ae764cb54ca3afa75e35f634c92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_sun_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b9cf2fc1154ec5bd9f18a8e4bb5c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset nusa_xmt/nusax_mt_bbc_ind_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bbc_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a347ed0c19f74c838a821850fcb40914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb0a662fff4f61861ab15ab9da006e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7a5d09672547afb280f80563f6f5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset nusa_xmt downloaded and prepared to /home/samuel/.cache/huggingface/datasets/nusa_xmt/nusax_mt_bbc_ind_nusantara_t2t/1.0.0/8e5cd18bf2771dbfe991f0c4db45678ec7aaecf94420cd375f211b46495e81cf. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5be9a5be5624a1281a5b51ab0614f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset para_cotta/paracotta_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/para_cotta/paracotta_id_nusantara_t2t/1.0.0/4b63c156f44006c55c9c4a8eee3cea966db5c075d4afc914be994f3251ddd8e2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905f9454b5f841188a44919fa54bb7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/889M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset para_cotta downloaded and prepared to /home/samuel/.cache/huggingface/datasets/para_cotta/paracotta_id_nusantara_t2t/1.0.0/4b63c156f44006c55c9c4a8eee3cea966db5c075d4afc914be994f3251ddd8e2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153f2fb09bb34395bb6a99b56a9f9fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset parallel_su_id (/home/samuel/.cache/huggingface/datasets/parallel_su_id/parallel_su_id_nusantara_t2t/1.0.0/f370015e1234edb5d6820b49517dcd52a1acce9f675b453ce05ffbba2e8b34c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b49af88a114b00bf45f18ccdcd871f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset stif_indonesia/stif_indonesia_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/stif_indonesia/stif_indonesia_nusantara_t2t/1.0.0/e2a7ca266edc3e1906afc3d121b172498d5b6ae74bd39b7b1b46535c58d48255...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b14e67af53471d96eb35e2e5bc3e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0232c509154a4fabeefc31c9eaf8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943f028e162c4a90bff1faee6ea3f7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b97ba748fe4442fba5cca730708919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e217a0a601734342aff74f175d8c7f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c3677683f145d78704a7bef11eee11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/58.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset stif_indonesia downloaded and prepared to /home/samuel/.cache/huggingface/datasets/stif_indonesia/stif_indonesia_nusantara_t2t/1.0.0/e2a7ca266edc3e1906afc3d121b172498d5b6ae74bd39b7b1b46535c58d48255. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421a6754fcc743f191ac648a6d57fd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ted_en_id/ted_en_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/ted_en_id/ted_en_id_nusantara_t2t/1.0.0/238640abbb8d60a5c5e091a85d78eb1b939b81afab21f385b61834e9137b34b5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ted_en_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/ted_en_id/ted_en_id_nusantara_t2t/1.0.0/238640abbb8d60a5c5e091a85d78eb1b939b81afab21f385b61834e9137b34b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a2f10e201d4b8895e6f4beeb6e9972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ud_id_csui_dataset/ud_id_csui_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/ud_id_csui_dataset/ud_id_csui_nusantara_t2t/1.0.0/617f7a6ffc44867d5cb6ca1b90f92468f5d7eac873c290392071ea76abecd637...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a67934ee8c49a78998596bfd333cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ud_id_csui_dataset downloaded and prepared to /home/samuel/.cache/huggingface/datasets/ud_id_csui_dataset/ud_id_csui_nusantara_t2t/1.0.0/617f7a6ffc44867d5cb6ca1b90f92468f5d7eac873c290392071ea76abecd637. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f6bb4f7edf48a0aeec66e8c3488982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xl_sum/xl_sum_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/xl_sum/xl_sum_nusantara_t2t/1.0.0/76624c668cf6d1c08c111c12ef243a9d87b01fdff321ec667bd87016705c4a2e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xl_sum downloaded and prepared to /home/samuel/.cache/huggingface/datasets/xl_sum/xl_sum_nusantara_t2t/1.0.0/76624c668cf6d1c08c111c12ef243a9d87b01fdff321ec667bd87016705c4a2e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972ef38470cd44b696004c09b1d8754b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset x_persona_id/xpersona_id_nusantara_t2t to /home/samuel/.cache/huggingface/datasets/x_persona_id/xpersona_id_nusantara_t2t/1.0.0/421f069a8f9e1c2b6fdfcd287bf16582ef6a4154ed2cfb6c724bf19e0369db8b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset x_persona_id downloaded and prepared to /home/samuel/.cache/huggingface/datasets/x_persona_id/xpersona_id_nusantara_t2t/1.0.0/421f069a8f9e1c2b6fdfcd287bf16582ef6a4154ed2cfb6c724bf19e0369db8b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f01b8ee093a4359976389d39da94ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_generation_datasets = {\n",
    "    helper.config.name: helper.load_dataset() for helper in conhelps.filtered(lambda x: x.config.name in TEXT_GENERATION_TASKS)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2d2cf-55fc-4d1a-a13a-ed7e9332244b",
   "metadata": {},
   "source": [
    "# Count TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e4dc7f-cce7-420d-b370-bd67eac64a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_count = {}\n",
    "for dset_name in text_classification_datasets.keys():\n",
    "    dset_count[dset_name] = {'train': 0, 'validation': 0, 'test': 0}\n",
    "    for split in text_classification_datasets[dset_name].keys():\n",
    "        dset_count[dset_name][split] = len(text_classification_datasets[dset_name][split])\n",
    "tc_df = pd.DataFrame(dset_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652dd702-9db4-4d2a-97b5-635598b8d527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "casa_nusantara_text_multi                        1080.0\n",
       "emot_nusantara_text                              4401.0\n",
       "emotcmt_nusantara_text                            582.0\n",
       "emotion_id_opinion_nusantara_text                7080.0\n",
       "hoasa_nusantara_text_multi                       2854.0\n",
       "id_abusive_nusantara_text                        2016.0\n",
       "id_clickbait_nusantara_text                     15000.0\n",
       "id_google_play_review_nusantara_text            10040.0\n",
       "id_google_play_review_posneg_nusantara_text     10040.0\n",
       "id_hatespeech_nusantara_text                      713.0\n",
       "id_multilabel_hs_nusantara_text_multi           13169.0\n",
       "id_stance_nusantara_pairs                         337.0\n",
       "id_sts_nusantara_pairs_score                    12901.0\n",
       "imdb_jv_nusantara_text                         100000.0\n",
       "indolem_ntp_nusantara_pairs                     33528.0\n",
       "indolem_sentiment_nusantara_text                 5048.0\n",
       "indonli_nusantara_pairs                         17709.0\n",
       "jadi_ide_nusantara_text                         16498.0\n",
       "netifier_nusantara_text_multi                    7773.0\n",
       "nusax_senti_ace_nusantara_text                   1000.0\n",
       "nusax_senti_ban_nusantara_text                   1000.0\n",
       "nusax_senti_bjn_nusantara_text                   1000.0\n",
       "nusax_senti_bug_nusantara_text                   1000.0\n",
       "nusax_senti_eng_nusantara_text                   1000.0\n",
       "nusax_senti_ind_nusantara_text                   1000.0\n",
       "nusax_senti_jav_nusantara_text                   1000.0\n",
       "nusax_senti_mad_nusantara_text                   1000.0\n",
       "nusax_senti_min_nusantara_text                   1000.0\n",
       "nusax_senti_nij_nusantara_text                   1000.0\n",
       "nusax_senti_sun_nusantara_text                   1000.0\n",
       "nusax_senti_bbc_nusantara_text                   1000.0\n",
       "nusax_senti_nusantara_text                      12000.0\n",
       "sentiment_nathasa_review_nusantara_text        124263.0\n",
       "smsa_nusantara_text                             12760.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4934c679-8038-4595-b224-7cc4a2680a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train           239623.0\n",
       "validation       16338.0\n",
       "test            115831.0\n",
       "unsupervised     50000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_df.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dfc4b86-cdf0-4c20-ac08-f1b88b6a3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_metadata = {}\n",
    "for row in tc_df.T.itertuples():\n",
    "    if row.test != 0:\n",
    "        tc_metadata[row.Index] = ('test', row.test)\n",
    "    elif row.validation != 0:\n",
    "        tc_metadata[row.Index] = ('validation', row.validation)\n",
    "    elif row.train != 0:\n",
    "        tc_metadata[row.Index] = ('train', row.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b13f95f-f36a-437a-80b7-a8de63f820f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>casa_nusantara_text_multi</th>\n",
       "      <td>test</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emot_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotcmt_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_id_opinion_nusantara_text</th>\n",
       "      <td>train</td>\n",
       "      <td>7080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoasa_nusantara_text_multi</th>\n",
       "      <td>test</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_abusive_nusantara_text</th>\n",
       "      <td>train</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_clickbait_nusantara_text</th>\n",
       "      <td>train</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_google_play_review_nusantara_text</th>\n",
       "      <td>validation</td>\n",
       "      <td>3012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_google_play_review_posneg_nusantara_text</th>\n",
       "      <td>validation</td>\n",
       "      <td>3012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_hatespeech_nusantara_text</th>\n",
       "      <td>train</td>\n",
       "      <td>713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_multilabel_hs_nusantara_text_multi</th>\n",
       "      <td>train</td>\n",
       "      <td>13169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_stance_nusantara_pairs</th>\n",
       "      <td>train</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_sts_nusantara_pairs_score</th>\n",
       "      <td>test</td>\n",
       "      <td>2580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_jv_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indolem_ntp_nusantara_pairs</th>\n",
       "      <td>test</td>\n",
       "      <td>7560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indolem_sentiment_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>1011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indonli_nusantara_pairs</th>\n",
       "      <td>test</td>\n",
       "      <td>5183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jadi_ide_nusantara_text</th>\n",
       "      <td>train</td>\n",
       "      <td>16498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>netifier_nusantara_text_multi</th>\n",
       "      <td>test</td>\n",
       "      <td>778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_ace_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_ban_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_bjn_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_bug_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_eng_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_ind_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_jav_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_mad_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_min_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_nij_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_sun_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_bbc_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_senti_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>4800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment_nathasa_review_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>62131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smsa_nusantara_text</th>\n",
       "      <td>test</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0        1\n",
       "casa_nusantara_text_multi                          test    180.0\n",
       "emot_nusantara_text                                test    440.0\n",
       "emotcmt_nusantara_text                             test    582.0\n",
       "emotion_id_opinion_nusantara_text                 train   7080.0\n",
       "hoasa_nusantara_text_multi                         test    286.0\n",
       "id_abusive_nusantara_text                         train   2016.0\n",
       "id_clickbait_nusantara_text                       train  15000.0\n",
       "id_google_play_review_nusantara_text         validation   3012.0\n",
       "id_google_play_review_posneg_nusantara_text  validation   3012.0\n",
       "id_hatespeech_nusantara_text                      train    713.0\n",
       "id_multilabel_hs_nusantara_text_multi             train  13169.0\n",
       "id_stance_nusantara_pairs                         train    337.0\n",
       "id_sts_nusantara_pairs_score                       test   2580.0\n",
       "imdb_jv_nusantara_text                             test  25000.0\n",
       "indolem_ntp_nusantara_pairs                        test   7560.0\n",
       "indolem_sentiment_nusantara_text                   test   1011.0\n",
       "indonli_nusantara_pairs                            test   5183.0\n",
       "jadi_ide_nusantara_text                           train  16498.0\n",
       "netifier_nusantara_text_multi                      test    778.0\n",
       "nusax_senti_ace_nusantara_text                     test    400.0\n",
       "nusax_senti_ban_nusantara_text                     test    400.0\n",
       "nusax_senti_bjn_nusantara_text                     test    400.0\n",
       "nusax_senti_bug_nusantara_text                     test    400.0\n",
       "nusax_senti_eng_nusantara_text                     test    400.0\n",
       "nusax_senti_ind_nusantara_text                     test    400.0\n",
       "nusax_senti_jav_nusantara_text                     test    400.0\n",
       "nusax_senti_mad_nusantara_text                     test    400.0\n",
       "nusax_senti_min_nusantara_text                     test    400.0\n",
       "nusax_senti_nij_nusantara_text                     test    400.0\n",
       "nusax_senti_sun_nusantara_text                     test    400.0\n",
       "nusax_senti_bbc_nusantara_text                     test    400.0\n",
       "nusax_senti_nusantara_text                         test   4800.0\n",
       "sentiment_nathasa_review_nusantara_text            test  62131.0\n",
       "smsa_nusantara_text                                test    500.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tc_metadata).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33b4cc46-ee91-4300-b023-f6321a6d5b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176668.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tc_metadata).T[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b5e1f-f93b-46bf-9dce-e62f4206e943",
   "metadata": {},
   "source": [
    "# Count TG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47edc71d-4e30-462a-a480-56a0fad4e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_count = {}\n",
    "for dset_name in text_generation_datasets.keys():\n",
    "    dset_count[dset_name] = {'train': 0, 'validation': 0, 'test': 0}\n",
    "    for split in text_generation_datasets[dset_name].keys():\n",
    "        dset_count[dset_name][split] = len(text_generation_datasets[dset_name][split])\n",
    "tg_df = pd.DataFrame(dset_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a832017-a92e-41b3-aa22-83157adae28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bible_en_id_nusantara_t2t                  31078\n",
       "bible_jv_id_nusantara_t2t                   7958\n",
       "bible_su_id_nusantara_t2t                   7957\n",
       "id_panl_bppt_nusantara_t2t                 24021\n",
       "id_qqp_nusantara_t2t                      149011\n",
       "indo_general_mt_en_id_nusantara_t2t      1825716\n",
       "indo_religious_mt_en_id_nusantara_t2t     589368\n",
       "indosum_fold0_nusantara_t2t                18774\n",
       "minangnlp_mt_nusantara_t2t                 16371\n",
       "news_en_id_nusantara_t2t                   42369\n",
       "nusax_mt_ace_ind_nusantara_t2t              1000\n",
       "nusax_mt_ban_ind_nusantara_t2t              1000\n",
       "nusax_mt_bjn_ind_nusantara_t2t              1000\n",
       "nusax_mt_bug_ind_nusantara_t2t              1000\n",
       "nusax_mt_eng_ind_nusantara_t2t              1000\n",
       "nusax_mt_ind_ace_nusantara_t2t              1000\n",
       "nusax_mt_ind_ban_nusantara_t2t              1000\n",
       "nusax_mt_ind_bjn_nusantara_t2t              1000\n",
       "nusax_mt_ind_bug_nusantara_t2t              1000\n",
       "nusax_mt_ind_eng_nusantara_t2t              1000\n",
       "nusax_mt_ind_jav_nusantara_t2t              1000\n",
       "nusax_mt_ind_mad_nusantara_t2t              1000\n",
       "nusax_mt_ind_min_nusantara_t2t              1000\n",
       "nusax_mt_ind_nij_nusantara_t2t              1000\n",
       "nusax_mt_ind_sun_nusantara_t2t              1000\n",
       "nusax_mt_ind_bbc_nusantara_t2t              1000\n",
       "nusax_mt_jav_ind_nusantara_t2t              1000\n",
       "nusax_mt_mad_ind_nusantara_t2t              1000\n",
       "nusax_mt_min_ind_nusantara_t2t              1000\n",
       "nusax_mt_nij_ind_nusantara_t2t              1000\n",
       "nusax_mt_sun_ind_nusantara_t2t              1000\n",
       "nusax_mt_bbc_ind_nusantara_t2t              1000\n",
       "paracotta_id_nusantara_t2t               6000000\n",
       "parallel_su_id_nusantara_t2t                3616\n",
       "stif_indonesia_nusantara_t2t                2499\n",
       "ted_en_id_nusantara_t2t                    93262\n",
       "ud_id_csui_nusantara_t2t                    1030\n",
       "xl_sum_nusantara_t2t                       47802\n",
       "xpersona_id_nusantara_t2t                 131673\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28eab7fc-75ab-4b9d-b14e-01c94b132d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         8925867\n",
       "validation      44585\n",
       "test            44053\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_df.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ab0d4b5-aa36-4405-84f5-fbd79ac5e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_metadata = {}\n",
    "for row in tg_df.T.itertuples():\n",
    "    if row.test != 0:\n",
    "        tg_metadata[row.Index] = ('test', row.test)\n",
    "    elif row.validation != 0:\n",
    "        tg_metadata[row.Index] = ('validation', row.validation)\n",
    "    elif row.train != 0:\n",
    "        tg_metadata[row.Index] = ('train', row.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d8beb7c-d289-4d16-ba12-a30d8290f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bible_en_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible_jv_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bible_su_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_panl_bppt_nusantara_t2t</th>\n",
       "      <td>train</td>\n",
       "      <td>24021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_qqp_nusantara_t2t</th>\n",
       "      <td>validation</td>\n",
       "      <td>14927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indo_general_mt_en_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indo_religious_mt_en_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>4824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indosum_fold0_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>3762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minangnlp_mt_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news_en_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ace_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ban_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_bjn_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_bug_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_eng_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_ace_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_ban_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_bjn_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_bug_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_eng_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_jav_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_mad_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_min_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_nij_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_sun_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_ind_bbc_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_jav_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_mad_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_min_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_nij_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_sun_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nusax_mt_bbc_ind_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paracotta_id_nusantara_t2t</th>\n",
       "      <td>train</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parallel_su_id_nusantara_t2t</th>\n",
       "      <td>train</td>\n",
       "      <td>3616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stif_indonesia_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ted_en_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ud_id_csui_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xl_sum_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xpersona_id_nusantara_t2t</th>\n",
       "      <td>test</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0        1\n",
       "bible_en_id_nusantara_t2t                    test     4661\n",
       "bible_jv_id_nusantara_t2t                    test     1193\n",
       "bible_su_id_nusantara_t2t                    test     1193\n",
       "id_panl_bppt_nusantara_t2t                  train    24021\n",
       "id_qqp_nusantara_t2t                   validation    14927\n",
       "indo_general_mt_en_id_nusantara_t2t          test     2000\n",
       "indo_religious_mt_en_id_nusantara_t2t        test     4824\n",
       "indosum_fold0_nusantara_t2t                  test     3762\n",
       "minangnlp_mt_nusantara_t2t                   test     3200\n",
       "news_en_id_nusantara_t2t                     test     1954\n",
       "nusax_mt_ace_ind_nusantara_t2t               test      400\n",
       "nusax_mt_ban_ind_nusantara_t2t               test      400\n",
       "nusax_mt_bjn_ind_nusantara_t2t               test      400\n",
       "nusax_mt_bug_ind_nusantara_t2t               test      400\n",
       "nusax_mt_eng_ind_nusantara_t2t               test      400\n",
       "nusax_mt_ind_ace_nusantara_t2t               test      400\n",
       "nusax_mt_ind_ban_nusantara_t2t               test      400\n",
       "nusax_mt_ind_bjn_nusantara_t2t               test      400\n",
       "nusax_mt_ind_bug_nusantara_t2t               test      400\n",
       "nusax_mt_ind_eng_nusantara_t2t               test      400\n",
       "nusax_mt_ind_jav_nusantara_t2t               test      400\n",
       "nusax_mt_ind_mad_nusantara_t2t               test      400\n",
       "nusax_mt_ind_min_nusantara_t2t               test      400\n",
       "nusax_mt_ind_nij_nusantara_t2t               test      400\n",
       "nusax_mt_ind_sun_nusantara_t2t               test      400\n",
       "nusax_mt_ind_bbc_nusantara_t2t               test      400\n",
       "nusax_mt_jav_ind_nusantara_t2t               test      400\n",
       "nusax_mt_mad_ind_nusantara_t2t               test      400\n",
       "nusax_mt_min_ind_nusantara_t2t               test      400\n",
       "nusax_mt_nij_ind_nusantara_t2t               test      400\n",
       "nusax_mt_sun_ind_nusantara_t2t               test      400\n",
       "nusax_mt_bbc_ind_nusantara_t2t               test      400\n",
       "paracotta_id_nusantara_t2t                  train  6000000\n",
       "parallel_su_id_nusantara_t2t                train     3616\n",
       "stif_indonesia_nusantara_t2t                 test      363\n",
       "ted_en_id_nusantara_t2t                      test     3179\n",
       "ud_id_csui_nusantara_t2t                     test      374\n",
       "xl_sum_nusantara_t2t                         test     4780\n",
       "xpersona_id_nusantara_t2t                    test     3770"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tg_metadata).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43c609c0-af3d-4e6e-b23f-4f038bf70809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6086617"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tg_metadata).T[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c42454c-d1a3-4b4d-9378-147a5cdb79ab",
   "metadata": {},
   "source": [
    "# Save Count Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3acb817-1297-4211-9118-ef7d13a1e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tg_metadata).T.rename({0: 'split', 1: 'num_data'}, axis=1).reset_index().to_csv('tg_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ce12d8f-ca92-439d-be87-6e13e4c491c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tc_metadata).T.rename({0: 'split', 1: 'num_data'}, axis=1).reset_index().to_csv('tc_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87bac0-017c-4684-986d-ed5043d016d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bdbf8213-c890-4fc0-b52f-de8701a69a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_to_split_name = pd.DataFrame(tc_metadata).T[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a7b7075c-8886-4f36-8b15-12ed044a3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "33805f30-940a-41bc-9315-641a6af0633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logprobs(tokenizer, model, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids, output_ids = inputs[\"input_ids\"], inputs[\"input_ids\"][:, 1:]\n",
    "    outputs = model(**inputs, labels=input_ids)\n",
    "    logits = outputs.logits\n",
    "    logprobs = torch.gather(F.log_softmax(logits, dim=2), 2, output_ids.unsqueeze(2))\n",
    "    return logprobs\n",
    "\n",
    "# Zero-shot evaluation for the Choice of Plausible Alternatives (COPA) task.\n",
    "# A return value of 0 indicates that the first alternative is more plausible,\n",
    "# while 1 indicates that the second alternative is more plausible.\n",
    "def prompt_eval(tokenizer, model, prompt, alternatives):\n",
    "    probs = []\n",
    "    for alt in alternatives:\n",
    "        probs.append(get_logprobs(prompt + \"\\n\" + f\"Choose between ({', '.join(alternatives)})\" + \"\\n\", alt).sum())\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1d41c-e06a-4a5d-9569-f00ff9fc703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# facebook/xglm-564M, facebook/xglm-1.7B, facebook/xglm-2.9B, facebook/xglm-4.5B, facebook/xglm-7.5B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/xglm-7.5B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/xglm-7.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d692e-e0af-4914-b187-dd164d2d2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {}\n",
    "for key, dset in text_classification_datasets.items():\n",
    "    print(f'Evaluating `{key}`')\n",
    "    # Get Idx to Label\n",
    "    if '_text_multi' in key:\n",
    "        labels = dset[cfg_to_split_name[key]].info.features['labels'].feature.names\n",
    "        idx2label = {i: lab for i, lab in enumerate(dset[cfg_to_split_name[key]].info.features['labels'].feature.names)}\n",
    "        # Skip for now\n",
    "        continue\n",
    "    elif '_text' in key:\n",
    "        labels = dset[cfg_to_split_name[key]].info.features['label'].names\n",
    "        idx2label = {i: lab for i, lab in enumerate(dset[cfg_to_split_name[key]].info.features['label'].names)}\n",
    "    elif '_pairs_score' in key:\n",
    "        # Skip for now\n",
    "        continue\n",
    "    elif '_pairs' in key:\n",
    "        labels = dset[cfg_to_split_name[key]].info.features['label'].names\n",
    "        idx2label = {i: lab for i, lab in enumerate(dset[cfg_to_split_name[key]].info.features['label'].names)}\n",
    "    else:\n",
    "        raise ValueError('Unknown Dataset Type')\n",
    "\n",
    "    # Iterate Dataset\n",
    "    preds = []\n",
    "    golds = []\n",
    "    for row in tqdm(dset[cfg_to_split_name[key]]):\n",
    "        if '_text' in key:\n",
    "            prompt = row.text\n",
    "        elif '_pairs' in key:\n",
    "            prompt = row.text_1 + \"\\n\" + row.text_2\n",
    "        \n",
    "        preds.append(prompt_eval(tokenizer, model, prompt, labels))\n",
    "        golds.append(row.label)       \n",
    "        \n",
    "    metrics = {}\n",
    "    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n",
    "    metrics[\"F1-macro\"] = f1_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"REC-macro\"] = recall_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"PRE-macro\"] = precision_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"F1-micro\"] = f1_score(list_label, list_hyp, average='micro')\n",
    "    metrics[\"REC-micro\"] = recall_score(list_label, list_hyp, average='micro')\n",
    "    metrics[\"PRE-micro\"] = precision_score(list_label, list_hyp, average='micro')\n",
    "    \n",
    "    eval_results[key] = metrics\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5280a747-672b-4a40-a8da-4ab2daf3016e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922562d8-773f-4f43-8253-377b768a6762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "nusantara_helpers = conhelps.filtered(\n",
    "    lambda x: x.is_nusantara_schema and not x.is_resource\n",
    ")\n",
    "print(len(nusantara_helpers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9530d443-5d5b-4555-a8ab-fbb8c84716fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "nusantara_helpers = conhelps.filtered(\n",
    "    lambda x: x.is_nusantara_schema \n",
    "        and not x.is_resource \n",
    "        and (x.config.name.endswith('_text') or x.config.name.endswith('_pairs'))\n",
    ")\n",
    "print(len(nusantara_helpers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b9ed53-d4f1-4f67-896c-6bb8a491586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "nusantara_helpers = conhelps.filtered(\n",
    "    lambda x: x.is_nusantara_schema \n",
    "        and not x.is_resource \n",
    "        and x.config.name.endswith('_t2t')\n",
    ")\n",
    "print(len(nusantara_helpers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "406fbc7d-bf15-4c06-812c-551d2a870eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                AM2iCo\n",
       "2                  CASA\n",
       "8      COCO Captions ID\n",
       "9                  CORD\n",
       "10            CoVoST 2 \n",
       "             ...       \n",
       "160               WReTe\n",
       "161              X-FACT\n",
       "162               XCOPA\n",
       "163              XL-Sum\n",
       "164         XPersona Id\n",
       "Name: name, Length: 72, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.read_csv('https://docs.google.com/spreadsheets/d/17o83IvWxmtGLYridZis0nEprHhsZIMeFtHGtXV35h6M/export?format=csv&gid=879729812', skiprows=1)\n",
    "meta_df = meta_df.rename({\n",
    "    'No.': 'id', 'Name': 'name', 'Subsets': 'subsets', 'Link': 'source_link', 'Description': 'description',\n",
    "    'HF Link': 'hf_link', 'License': 'license', 'Year': 'year', 'Collection Style': 'collection_style',\n",
    "    'Language': 'language', 'Dialect': 'dialect', 'Domain': 'domain', 'Form': 'modality', 'Tasks': 'tasks',\n",
    "    'Volume': 'volume', 'Unit': 'unit', 'Ethical Risks': 'ethical_risk', 'Provider': 'provider',\n",
    "    'Paper Title': 'paper_title', 'Paper Link': 'paper_link', 'Access': 'access', 'Derived From': 'derived_from', \n",
    "    'Test Split': 'is_splitted', 'Notes': 'notes', 'Dataloader': 'dataloader', 'Implemented': 'implemented'\n",
    "}, axis=1)\n",
    "meta_df['is_splitted'] = meta_df['is_splitted'].apply(lambda x: True if x =='Yes' else False)\n",
    "# [\n",
    "#  'No.', 'Name', 'Subsets', 'Link', 'HF Link', 'License', 'Year',\n",
    "#  'Language', 'Dialect', 'Domain', 'Form', 'Collection Style',\n",
    "#  'Description', 'Volume', 'Unit', 'Ethical Risks', 'Provider',\n",
    "#  'Paper Title', 'Paper Link', 'Access', 'Derived From', 'Tasks',\n",
    "#  'Test Split', 'Notes', 'Dataloader', 'Implemented'\n",
    "# ]\n",
    "meta_df.loc[meta_df.is_splitted, 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72389399-4675-4b11-8f8e-ea6d579e3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = meta_df.loc[meta_df.is_splitted, 'dataloader'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58be9e82-3230-499f-9eea-b4ec963843d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bible_en_id',\n",
       " 'bible_jv_id',\n",
       " 'bible_su_id',\n",
       " 'covost2_ind_eng',\n",
       " 'covost2_eng_ind',\n",
       " 'id_panl_bppt',\n",
       " 'id_qqp',\n",
       " 'id_wiki_parallel_jav_ind',\n",
       " 'id_wiki_parallel_min_ind',\n",
       " 'id_wiki_parallel_sun_ind',\n",
       " 'indo_general_mt_en_id',\n",
       " 'indo_religious_mt_en_id',\n",
       " 'indosum_fold0',\n",
       " 'indosum_fold1',\n",
       " 'indosum_fold2',\n",
       " 'indosum_fold3',\n",
       " 'indosum_fold4',\n",
       " 'korpus_nusantara_ind_jav',\n",
       " 'korpus_nusantara_ind_day',\n",
       " 'korpus_nusantara_ind_bug',\n",
       " 'korpus_nusantara_ind_sun',\n",
       " 'korpus_nusantara_ind_mad',\n",
       " 'korpus_nusantara_ind_bin',\n",
       " 'korpus_nusantara_ind_bbc',\n",
       " 'korpus_nusantara_ind_khek',\n",
       " 'korpus_nusantara_ind_msa',\n",
       " 'korpus_nusantara_ind_min',\n",
       " 'korpus_nusantara_ind_tiociu',\n",
       " 'korpus_nusantara_jav_ind',\n",
       " 'korpus_nusantara_day_ind',\n",
       " 'korpus_nusantara_bug_ind',\n",
       " 'korpus_nusantara_sun_ind',\n",
       " 'korpus_nusantara_mad_ind',\n",
       " 'korpus_nusantara_bin_ind',\n",
       " 'korpus_nusantara_bbc_ind',\n",
       " 'korpus_nusantara_khek_ind',\n",
       " 'korpus_nusantara_msa_ind',\n",
       " 'korpus_nusantara_min_ind',\n",
       " 'korpus_nusantara_tiociu_ind',\n",
       " 'minangnlp_mt',\n",
       " 'multilexnorm',\n",
       " 'news_en_id',\n",
       " 'nllb_seed_ace',\n",
       " 'nllb_seed_bjn',\n",
       " 'nllb_seed_bug',\n",
       " 'nusax_mt_ace_ind',\n",
       " 'nusax_mt_ban_ind',\n",
       " 'nusax_mt_bjn_ind',\n",
       " 'nusax_mt_bug_ind',\n",
       " 'nusax_mt_eng_ind',\n",
       " 'nusax_mt_ind_ace',\n",
       " 'nusax_mt_ind_ban',\n",
       " 'nusax_mt_ind_bjn',\n",
       " 'nusax_mt_ind_bug',\n",
       " 'nusax_mt_ind_eng',\n",
       " 'nusax_mt_ind_jav',\n",
       " 'nusax_mt_ind_mad',\n",
       " 'nusax_mt_ind_min',\n",
       " 'nusax_mt_ind_nij',\n",
       " 'nusax_mt_ind_sun',\n",
       " 'nusax_mt_ind_bbc',\n",
       " 'nusax_mt_jav_ind',\n",
       " 'nusax_mt_mad_ind',\n",
       " 'nusax_mt_min_ind',\n",
       " 'nusax_mt_nij_ind',\n",
       " 'nusax_mt_sun_ind',\n",
       " 'nusax_mt_bbc_ind',\n",
       " 'paracotta_id',\n",
       " 'parallel_su_id',\n",
       " 'stif_indonesia',\n",
       " 'talpco_eng_ind',\n",
       " 'talpco_ind_eng',\n",
       " 'talpco_ind_jpn',\n",
       " 'talpco_ind_kor',\n",
       " 'talpco_ind_myn',\n",
       " 'talpco_ind_tha',\n",
       " 'talpco_ind_vie',\n",
       " 'talpco_ind_zsm',\n",
       " 'talpco_jpn_ind',\n",
       " 'talpco_kor_ind',\n",
       " 'talpco_myn_ind',\n",
       " 'talpco_tha_ind',\n",
       " 'talpco_vie_ind',\n",
       " 'talpco_zsm_ind',\n",
       " 'ted_en_id',\n",
       " 'ud_id_csui',\n",
       " 'xl_sum',\n",
       " 'xpersona_id']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    helper.config.name.split('_nusantara_t2t')[0] for helper in nusantara_helpers\n",
    "            if (('nusax_mt' not in helper.config.name and 'talpco' not in helper.config.name) or 'ind' in helper.config.name)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a723a1-4036-4010-bbe6-c69f5c762afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_nusantara)",
   "language": "python",
   "name": "env_nusantara"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
