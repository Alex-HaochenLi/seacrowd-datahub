{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022fb7df-e22f-4512-be01-50f8788d2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from nusantara import NusantaraMetadata, NusantaraConfigHelper\n",
    "from nusantara.utils.constants import Tasks, TASK_TO_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5ceeab-64f3-4afb-8539-de28ae08dc20",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset smsa (/home/samuel/.cache/huggingface/datasets/smsa/smsa_nusantara_text/1.0.0/424796f944d7120578eadd5678a5bd371cffc381056363bd88c6b7648399248f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Configs\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id source schema', schema='source', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset\\nfor Javanese and Indonesian translation generated\\nfrom the verse-aligned Bible parallel corpus with\\nthe same split setting. In terms of size, both the\\nSu ↔ Id and Jv ↔ Id datasets are much smaller\\ncompared to the En ↔ Id dataset, because there are\\nBible chapters for which translations are available\\nfor Indonesian, albeit not for the local languages.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset\\nfor Javanese and Indonesian translation generated\\nfrom the verse-aligned Bible parallel corpus with\\nthe same split setting. In terms of size, both the\\nSu ↔ Id and Jv ↔ Id datasets are much smaller\\ncompared to the En ↔ Id dataset, because there are\\nBible chapters for which translations are available\\nfor Indonesian, albeit not for the local languages.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id source schema', schema='source', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for ind language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for jav language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for sun language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for ind language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for jav language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for sun language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emot/emot.py', dataset_name='emot', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emot_source', version=1.0.0, data_dir=None, data_files=None, description='EmoT source schema', schema='source', subset_id='emot'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emot/emot.py', dataset_name='emot', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emot_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmoT Nusantara schema', schema='nusantara_text', subset_id='emot'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emotcmt_source', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT source schema', schema='source', subset_id='emotcmt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emotcmt_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT Nusantara schema', schema='nusantara_text', subset_id='emotcmt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_abusive_source', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive source schema', schema='source', subset_id='id_abusive'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_abusive_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive Nusantara schema', schema='nusantara_text', subset_id='id_abusive'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_clickbait_source', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID source schema', schema='source', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_clickbait_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID Nusantara schema', schema='nusantara_text', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_hatespeech_source', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech source schema', schema='source', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_hatespeech_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech Nusantara schema', schema='nusantara_text', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_source', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS source schema', schema='source', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=set(), languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS Nusantara schema', schema='nusantara_text_multi', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_source', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT source schema', schema='source', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT Nusantara schema', schema='nusantara_t2t', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_source', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI source schema', schema='source', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI Nusantara schema', schema='nusantara_seq_label', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT En-Id source schema', schema='source', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT Nusantara schema', schema='nusantara_t2t', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks=[<Tasks.COREFERENCE_RESOLUTION: 'COREF'>], languages=['ind'], config=NusantaraConfig(name='indocoref_source', version=1.0.0, data_dir=None, data_files=None, description='Indocoref source schema', schema='source', subset_id='indocoref'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks={<Tasks.COREFERENCE_RESOLUTION: 'COREF'>}, languages=['ind'], config=NusantaraConfig(name='indocoref_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='Indocoref Nusantara schema', schema='nusantara_kb', subset_id='indocoref'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks=[<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ntp_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP source schema', schema='source', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks={<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ntp_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP Nusantara schema', schema='nusantara_pairs', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment source schema', schema='source', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment Nusantara schema', schema='nusantara_text', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks=[<Tasks.SENTENCE_ORDERING: 'SO'>], languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering source schema', schema='source', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks={<Tasks.SENTENCE_ORDERING: 'SO'>}, languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks=[<Tasks.TEXTUAL_ENTAILMENT: 'TE'>], languages=['ind'], config=NusantaraConfig(name='indonli_source', version=1.1.0, data_dir=None, data_files=None, description='indonli source schema', schema='source', subset_id='indonli'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='CC-BY-SA 4.0. Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.Please contact authors for any information on the dataset.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks={<Tasks.TEXTUAL_ENTAILMENT: 'TE'>}, languages=['ind'], config=NusantaraConfig(name='indonli_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='indonli Nusantara schema', schema='nusantara_pairs', subset_id='indonli'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='CC-BY-SA 4.0. Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.Please contact authors for any information on the dataset.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold0_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold1_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold2_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold3_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold4_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_source', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation source schema', schema='source', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation Nusantara schema', schema='nusantara_t2t', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nerp_source', version=1.0.0, data_dir=None, data_files=None, description='NERP source schema', schema='source', subset_id='nerp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nerp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERP Nusantara schema', schema='nusantara_seq_label', subset_id='nerp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='News En-Id source schema', schema='source', subset_id='news_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='News En-Id Nusantara schema', schema='nusantara_t2t', subset_id='news_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ace language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ban language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bjn language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bug language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for eng language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ind language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for jav language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for mad language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for min language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for nij language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for sun language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bbc language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ace language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ban language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bjn language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bug language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for eng language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ind language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for jav language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for mad language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for min language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for nij language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for sun language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bbc language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for all 12 languages', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for all 12 languages', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/posp/posp.py', dataset_name='posp', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='posp_source', version=1.0.0, data_dir=None, data_files=None, description='POSP source schema', schema='source', subset_id='posp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/posp/posp.py', dataset_name='posp', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='posp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='POSP Nusantara schema', schema='nusantara_seq_label', subset_id='posp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='singgalang_source', version=1.0.0, data_dir=None, data_files=None, description='singgalang source schema', schema='source', subset_id='singgalang'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='singgalang_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='singgalang Nusantara schema', schema='nusantara_seq_label', subset_id='singgalang'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='smsa_source', version=1.0.0, data_dir=None, data_files=None, description='SMSA source schema', schema='source', subset_id='smsa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='smsa_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='SMSA Nusantara schema', schema='nusantara_text', subset_id='smsa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks=[<Tasks.PARAPHRASING: 'PARA'>], languages=['ind'], config=NusantaraConfig(name='stif_indonesia_source', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia source schema', schema='source', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks={<Tasks.PARAPHRASING: 'PARA'>}, languages=['ind'], config=NusantaraConfig(name='stif_indonesia_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia Nusantara schema', schema='nusantara_t2t', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id source schema', schema='source', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id Nusantara schema', schema='nusantara_t2t', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks=[<Tasks.KEYWORD_TAGGING: 'KT'>], languages=['ind'], config=NusantaraConfig(name='term_a_source', version=1.0.0, data_dir=None, data_files=None, description='TermA source schema', schema='source', subset_id='term_a'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks={<Tasks.KEYWORD_TAGGING: 'KT'>}, languages=['ind'], config=NusantaraConfig(name='term_a_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='TermA Nusantara schema', schema='nusantara_seq_label', subset_id='term_a'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='titml_idn_source', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN source schema', schema='source', subset_id='titml_idn'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='titml_idn_nusantara_asr', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN Nusantara schema', schema='nusantara_asr', subset_id='titml_idn'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='ASR', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for eng language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ind language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for jav language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for min language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for sun language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ace language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for mly language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for map_bms language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for eng language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ind language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for jav language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for min language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for sun language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ace language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for mly language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for map_bms language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_source', version=2.0.0, data_dir=None, data_files=None, description='xl_sum source schema', schema='source', subset_id='xl_sum'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='xl_sum Nusantara schema', schema='nusantara_t2t', subset_id='xl_sum'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "Retrieve SMSA\n",
      "[NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='smsa_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='SMSA Nusantara schema', schema='nusantara_text', subset_id='smsa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d7b1c56ceb46b5ac010401f258b9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 11000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'text', 'label'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})]\n",
      "Source datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id source schema', schema='source', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset\\nfor Javanese and Indonesian translation generated\\nfrom the verse-aligned Bible parallel corpus with\\nthe same split setting. In terms of size, both the\\nSu ↔ Id and Jv ↔ Id datasets are much smaller\\ncompared to the En ↔ Id dataset, because there are\\nBible chapters for which translations are available\\nfor Indonesian, albeit not for the local languages.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id source schema', schema='source', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for ind language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for jav language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks=[<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>], languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_source', version=2018.12.1, data_dir=None, data_files=None, description='CC100 with source schema for sun language', schema='source', subset_id='cc100'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emot/emot.py', dataset_name='emot', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emot_source', version=1.0.0, data_dir=None, data_files=None, description='EmoT source schema', schema='source', subset_id='emot'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks=[<Tasks.EMOTION_CLASSIFICATION: 'EC'>], languages=['ind'], config=NusantaraConfig(name='emotcmt_source', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT source schema', schema='source', subset_id='emotcmt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_abusive_source', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive source schema', schema='source', subset_id='id_abusive'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_clickbait_source', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID source schema', schema='source', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='id_hatespeech_source', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech source schema', schema='source', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=[<Tasks.ASPECT_BASED_SENTIMENT_ANALYSIS: 'ABSA'>], languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_source', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS source schema', schema='source', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_source', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT source schema', schema='source', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_source', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI source schema', schema='source', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT En-Id source schema', schema='source', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id source schema', schema='source', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks=[<Tasks.COREFERENCE_RESOLUTION: 'COREF'>], languages=['ind'], config=NusantaraConfig(name='indocoref_source', version=1.0.0, data_dir=None, data_files=None, description='Indocoref source schema', schema='source', subset_id='indocoref'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm source schema', schema='source', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI source schema', schema='source', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks=[<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>], languages=['ind'], config=NusantaraConfig(name='indolem_ntp_source', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP source schema', schema='source', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment source schema', schema='source', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks=[<Tasks.SENTENCE_ORDERING: 'SO'>], languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_source', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering source schema', schema='source', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks=[<Tasks.TEXTUAL_ENTAILMENT: 'TE'>], languages=['ind'], config=NusantaraConfig(name='indonli_source', version=1.1.0, data_dir=None, data_files=None, description='indonli source schema', schema='source', subset_id='indonli'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='CC-BY-SA 4.0. Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.Please contact authors for any information on the dataset.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold0_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold1_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold2_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold3_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind'], config=NusantaraConfig(name='indosum_fold4_source', version='1.0.0', data_dir=None, data_files=None, description='indosum source schema', schema='source', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_source', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation source schema', schema='source', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='nerp_source', version=1.0.0, data_dir=None, data_files=None, description='NERP source schema', schema='source', subset_id='nerp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='News En-Id source schema', schema='source', subset_id='news_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ace language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ban language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bjn language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bug language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for eng language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for ind language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for jav language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for mad language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for min language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for nij language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for sun language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for bbc language', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_source', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with source schema for all 12 languages', schema='source', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/posp/posp.py', dataset_name='posp', tasks=[<Tasks.POS_TAGGING: 'POS'>], languages=['ind'], config=NusantaraConfig(name='posp_source', version=1.0.0, data_dir=None, data_files=None, description='POSP source schema', schema='source', subset_id='posp'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind'], config=NusantaraConfig(name='singgalang_source', version=1.0.0, data_dir=None, data_files=None, description='singgalang source schema', schema='source', subset_id='singgalang'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks=[<Tasks.SENTIMENT_ANALYSIS: 'SA'>], languages=['ind'], config=NusantaraConfig(name='smsa_source', version=1.0.0, data_dir=None, data_files=None, description='SMSA source schema', schema='source', subset_id='smsa'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks=[<Tasks.PARAPHRASING: 'PARA'>], languages=['ind'], config=NusantaraConfig(name='stif_indonesia_source', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia source schema', schema='source', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks=[<Tasks.MACHINE_TRANSLATION: 'MT'>], languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_source', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id source schema', schema='source', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks=[<Tasks.KEYWORD_TAGGING: 'KT'>], languages=['ind'], config=NusantaraConfig(name='term_a_source', version=1.0.0, data_dir=None, data_files=None, description='TermA source schema', schema='source', subset_id='term_a'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks=[<Tasks.SPEECH_RECOGNITION: 'ASR'>], languages=['ind'], config=NusantaraConfig(name='titml_idn_source', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN source schema', schema='source', subset_id='titml_idn'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for eng language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ind language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for jav language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for min language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for sun language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for ace language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for mly language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks=[<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>], languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_source', version=1.1.0, data_dir=None, data_files=None, description='wikiann with source schema for map_bms language', schema='source', subset_id='wikiann'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks=[<Tasks.SUMMARIZATION: 'SUM'>], languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_source', version=2.0.0, data_dir=None, data_files=None, description='xl_sum source schema', schema='source', subset_id='xl_sum'), is_local=False, is_nusantara_schema=False, nusantara_schema_caps=None, is_large=False, is_resource=False, is_default=True, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "Nusantara datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_en_id/bible_en_id.py', dataset_name='bible_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='bible_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the bible. We also add a Bible dataset to the English Indonesian translation task. Specifically, we collect an Indonesian and an English language Bible and generate a verse-aligned parallel corpus for the English-Indonesian machine translation task. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_jv_id/bible_jv_id.py', dataset_name='bible_jv_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'jav'], config=NusantaraConfig(name='bible_jv_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Jv-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_jv_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Analogous to the En ↔ Id and Su ↔ Id datasets, we create a new dataset\\nfor Javanese and Indonesian translation generated\\nfrom the verse-aligned Bible parallel corpus with\\nthe same split setting. In terms of size, both the\\nSu ↔ Id and Jv ↔ Id datasets are much smaller\\ncompared to the En ↔ Id dataset, because there are\\nBible chapters for which translations are available\\nfor Indonesian, albeit not for the local languages.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/bible_su_id/bible_su_id.py', dataset_name='bible_su_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'sun'], config=NusantaraConfig(name='bible_su_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible Su-Id Nusantara schema', schema='nusantara_t2t', subset_id='bible_su_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='Bible Su-Id is a machine translation dataset containing Indonesian-Sundanese parallel sentences collected from the bible. As there is no existing parallel corpus for Sundanese and Indonesian, we create a new dataset for Sundanese and Indonesian translation generated from the Bible. We create a verse-aligned parallel corpus with a 75%, 10%, and 15% split for the training, validation, and test sets. The dataset is also evaluated in both directions.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_ind_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for ind language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_jav_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for jav language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/cc100/cc100.py', dataset_name='cc100', tasks={<Tasks.SELF_SUPERVISED_PRETRAINING: 'SSP'>}, languages=['ind', 'jav', 'sun'], config=NusantaraConfig(name='cc100_sun_nusantara_ssp', version=1.0.0, data_dir=None, data_files=None, description='CC100 with nusantara_ssp schema for sun language', schema='nusantara_ssp', subset_id='cc100'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SSP', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2018.12.01', citation='        @inproceedings{conneau-etal-2020-unsupervised,\\n    title = \"Unsupervised Cross-lingual Representation Learning at Scale\",\\n    author = \"Conneau, Alexis  and\\n      Khandelwal, Kartikay  and\\n      Goyal, Naman  and\\n      Chaudhary, Vishrav  and\\n      Wenzek, Guillaume  and\\n      Guzm{\\'a}n, Francisco  and\\n      Grave, Edouard  and\\n      Ott, Myle  and\\n      Zettlemoyer, Luke  and\\n      Stoyanov, Veselin\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.747\",\\n    doi = \"10.18653/v1/2020.acl-main.747\",\\n    pages = \"8440--8451\",\\n    abstract = \"This paper shows that pretraining multilingual language models\\n    at scale leads to significant performance gains for a wide range of\\n    cross-lingual transfer tasks. We train a Transformer-based masked language\\n    model on one hundred languages, using more than two terabytes of filtered\\n    CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms\\n    multilingual BERT (mBERT) on a variety of cross-lingual benchmarks,\\n    including +14.6{%} average accuracy on XNLI, +13{%} average F1 score on\\n    MLQA, and +2.4{%} F1 score on NER. XLM-R performs particularly well on\\n    low-resource languages, improving 15.7{%} in XNLI accuracy for Swahili and\\n    11.4{%} for Urdu over previous XLM models. We also present a detailed\\n    empirical analysis of the key factors that are required to achieve these\\n    gains, including the trade-offs between (1) positive transfer and capacity\\n    dilution and (2) the performance of high and low resource languages at\\n    scale. Finally, we show, for the first time, the possibility of\\n    multilingual modeling without sacrificing per-language performance; XLM-R\\n    is very competitive with strong monolingual models on the GLUE and XNLI\\n    benchmarks. We will make our code and models publicly available.\",\\n}\\n\\n@inproceedings{wenzek-etal-2020-ccnet,\\n    title = \"{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data\",\\n    author = \"Wenzek, Guillaume  and\\n      Lachaux, Marie-Anne  and\\n      Conneau, Alexis  and\\n      Chaudhary, Vishrav  and\\n      Guzm{\\'a}n, Francisco  and\\n      Joulin, Armand  and\\n      Grave, Edouard\",\\n    booktitle = \"Proceedings of the 12th Language Resources and Evaluation Conference\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://www.aclweb.org/anthology/2020.lrec-1.494\",\\n    pages = \"4003--4012\",\\n    abstract = \"Pre-training text representations have led to significant\\n    improvements in many areas of natural language processing. The quality of\\n    these models benefits greatly from the size of the pretraining corpora as\\n    long as its quality is preserved. In this paper, we describe an automatic\\n    pipeline to extract massive high-quality monolingual datasets from Common\\n    Crawl for a variety of languages. Our pipeline follows the data processing\\n    introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that\\n    deduplicates documents and identifies their language. We augment this\\n    pipeline with a filtering step to select documents that are close to high\\n    quality corpora like Wikipedia.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-34-4\",\\n}\\n', description='        This corpus is an attempt to recreate the dataset used for training\\n        XLM-R. This corpus comprises of monolingual data for 100+ languages and\\n        also includes data for romanized languages (indicated by *_rom). This\\n        was constructed using the urls and paragraph indices provided by the\\n        CC-Net repository by processing January-December 2018 Commoncrawl\\n        snapshots. Each file comprises of documents separated by\\n        double-newlines and paragraphs within the same document separated by a\\n        newline. The data is generated using the open source CC-Net repository.\\n        No claims of intellectual property are made on the work of preparation\\n        of the corpus.\\n', homepage='https://data.statmt.org/cc-100/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emot/emot.py', dataset_name='emot', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emot_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmoT Nusantara schema', schema='nusantara_text', subset_id='emot'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{saputri2018emotion,\\n  title={Emotion classification on indonesian twitter dataset},\\n  author={Saputri, Mei Silviana and Mahendra, Rahmad and Adriani, Mirna},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={90--95},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='EmoT is an emotion classification dataset collected from the social media platform Twitter. The dataset consists of around 4000 Indonesian colloquial language tweets, covering five different emotion labels: anger, fear, happiness, love, and sadness.\\nEmoT dataset is splitted into 3 sets with 3521 train, 440 validation, 442 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/emotcmt/emotcmt.py', dataset_name='emotcmt', tasks={<Tasks.EMOTION_CLASSIFICATION: 'EC'>}, languages=['ind'], config=NusantaraConfig(name='emotcmt_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='EmotCMT Nusantara schema', schema='nusantara_text', subset_id='emotcmt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{barik-etal-2019-normalization,\\n    title = \"Normalization of {I}ndonesian-{E}nglish Code-Mixed {T}witter Data\",\\n    author = \"Barik, Anab Maulana  and\\n      Mahendra, Rahmad  and\\n      Adriani, Mirna\",\\n    booktitle = \"Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)\",\\n    month = nov,\\n    year = \"2019\",\\n    address = \"Hong Kong, China\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/D19-5554\",\\n    doi = \"10.18653/v1/D19-5554\",\\n    pages = \"417--424\"\\n}\\n\\n@article{Yulianti2021NormalisationOI,\\n  title={Normalisation of Indonesian-English Code-Mixed Text and its Effect on Emotion Classification},\\n  author={Evi Yulianti and Ajmal Kurnia and Mirna Adriani and Yoppy Setyo Duto},\\n  journal={International Journal of Advanced Computer Science and Applications},\\n  year={2021}\\n}\\n', description='EmotCMT is an emotion classification Indonesian-English code-mixing dataset created through an Indonesian-English code-mixed Twitter data pipeline consisting of 4 processing steps, i.e., tokenization, language identification, lexical normalization, and translation. The dataset consists of 825 tweets, 22.736 tokens with 11.204 Indonesian tokens and 5.613 English tokens. Each tweet is labelled with an emotion, i.e., cinta (love), takut (fear), sedih (sadness), senang (joy), or marah (anger).\\n', homepage='https://github.com/ir-nlp-csui/emotcmt', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_abusive/id_abusive.py', dataset_name='id_abusive', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_abusive_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Abusive Nusantara schema', schema='nusantara_text', subset_id='id_abusive'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{IBROHIM2018222,\\ntitle = {A Dataset and Preliminaries Study for Abusive Language Detection in Indonesian Social Media},\\njournal = {Procedia Computer Science},\\nvolume = {135},\\npages = {222-229},\\nyear = {2018},\\nnote = {The 3rd International Conference on Computer Science and Computational Intelligence (ICCSCI 2018) : Empowering Smart Technology in Digital Era for a Better Life},\\nissn = {1877-0509},\\ndoi = {https://doi.org/10.1016/j.procs.2018.08.169},\\nurl = {https://www.sciencedirect.com/science/article/pii/S1877050918314583},\\nauthor = {Muhammad Okky Ibrohim and Indra Budi},\\nkeywords = {abusive language, twitter, machine learning},\\nabstract = {Abusive language is an expression (both oral or text) that contains abusive/dirty words or phrases both in the context of jokes, a vulgar sex conservation or to cursing someone. Nowadays many people on the internet (netizens) write and post an abusive language in the social media such as Facebook, Line, Twitter, etc. Detecting an abusive language in social media is a difficult problem to resolve because this problem can not be resolved just use word matching. This paper discusses a preliminaries study for abusive language detection in Indonesian social media and the challenge in developing a system for Indonesian abusive language detection, especially in social media. We also built reported an experiment for abusive language detection on Indonesian tweet using machine learning approach with a simple word n-gram and char n-gram features. We use Naive Bayes, Support Vector Machine, and Random Forest Decision Tree classifier to identify the tweet whether the tweet is a not abusive language, abusive but not offensive, or offensive language. The experiment results show that the Naive Bayes classifier with the combination of word unigram + bigrams features gives the best result i.e. 70.06% of F1 - Score. However, if we classifying the tweet into two labels only (not abusive language and abusive language), all classifier that we used gives a higher result (more than 83% of F1 - Score for every classifier). The dataset in this experiment is available for other researchers that interest to improved this study.}\\n}\\n', description='The ID_ABUSIVE dataset is collection of 2,016 informal abusive tweets in Indonesian language,\\ndesigned for sentiment analysis NLP task. This dataset is crawled from Twitter, and then filtered\\nand labelled manually by 20 volunteer annotators. The dataset labelled into three labels namely\\nnot abusive language, abusive but not offensive, and offensive language.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S1877050918314583', license='Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_clickbait/id_clickbait.py', dataset_name='id_clickbait', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_clickbait_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='CLICK-ID Nusantara schema', schema='nusantara_text', subset_id='id_clickbait'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{WILLIAM2020106231,\\ntitle = \"CLICK-ID: A novel dataset for Indonesian clickbait headlines\",\\njournal = \"Data in Brief\",\\nvolume = \"32\",\\npages = \"106231\",\\nyear = \"2020\",\\nissn = \"2352-3409\",\\ndoi = \"https://doi.org/10.1016/j.dib.2020.106231\",\\nurl = \"http://www.sciencedirect.com/science/article/pii/S2352340920311252\",\\nauthor = \"Andika William and Yunita Sari\",\\nkeywords = \"Indonesian, Natural Language Processing, News articles, Clickbait, Text-classification\",\\nabstract = \"News analysis is a popular task in Natural Language Processing (NLP). In particular, the problem of clickbait in news analysis has gained attention in recent years [1, 2]. However, the majority of the tasks has been focused on English news, in which there is already a rich representative resource. For other languages, such as Indonesian, there is still a lack of resource for clickbait tasks. Therefore, we introduce the CLICK-ID dataset of Indonesian news headlines extracted from 12 Indonesian online news publishers. It is comprised of 15,000 annotated headlines with clickbait and non-clickbait labels. Using the CLICK-ID dataset, we then developed an Indonesian clickbait classification model achieving favourable performance. We believe that this corpus will be useful for replicable experiments in clickbait detection or other experiments in NLP areas.\"\\n}\\n', description='The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news\\npublishers; detikNews, Fimela, Kapanlagi, Kompas, Liputan6, Okezone, Posmetro-Medan, Republika, Sindonews, Tempo,\\nTribunnews, and Wowkeren. This dataset is comprised of mainly two parts; (i) 46,119 raw article data, and (ii)\\n15,000 clickbait annotated sample headlines. Annotation was conducted with 3 annotator examining each headline.\\nJudgment were based only on the headline. The majority then is considered as the ground truth. In the annotated\\nsample, our annotation shows 6,290 clickbait and 8,710 non-clickbait.\\n', homepage='https://www.sciencedirect.com/science/article/pii/S2352340920311252#!', license='Creative Commons Attribution 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_hatespeech/id_hatespeech.py', dataset_name='id_hatespeech', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='id_hatespeech_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='ID Hatespeech Nusantara schema', schema='nusantara_text', subset_id='id_hatespeech'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{inproceedings,\\nauthor = {Alfina, Ika and Mulia, Rio and Fanany, Mohamad Ivan and Ekanata, Yudo},\\nyear = {2017},\\nmonth = {10},\\npages = {},\\ntitle = {Hate Speech Detection in the Indonesian Language: A Dataset and Preliminary Study},\\ndoi = {10.1109/ICACSIS.2017.8355039}\\n}\\n', description='The ID Hatespeech dataset is collection of 713 tweets related to a political event, the Jakarta Governor Election 2017\\ndesigned for hate speech detection NLP task. This dataset is crawled from Twitter, and then filtered\\nand annotated manually. The dataset labelled into two; HS if the tweet contains hate speech and Non_HS if otherwise\\n', homepage='https://www.researchgate.net/publication/320131169_Hate_Speech_Detection_in_the_Indonesian_Language_A_Dataset_and_Preliminary_Study', license='Unknown')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_multilabel_hs/id_multilabel_hs.py', dataset_name='id_multilabel_hs', tasks=set(), languages=['ind'], config=NusantaraConfig(name='id_multilabel_hs_nusantara_text_multi', version=1.0.0, data_dir=None, data_files=None, description='ID Multilabel HS Nusantara schema', schema='nusantara_text_multi', subset_id='id_multilabel_hs'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{ibrohim-budi-2019-multi,\\n    title = \"Multi-label Hate Speech and Abusive Language Detection in {I}ndonesian {T}witter\",\\n    author = \"Ibrohim, Muhammad Okky  and\\n      Budi, Indra\",\\n    booktitle = \"Proceedings of the Third Workshop on Abusive Language Online\",\\n    month = aug,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/W19-3506\",\\n    doi = \"10.18653/v1/W19-3506\",\\n    pages = \"46--57\",\\n}\\n', description='The ID_MULTILABEL_HS dataset is collection of 13,169 tweets in Indonesian language,\\ndesigned for hate speech detection NLP task. This dataset is combination from previous research and newly crawled data from Twitter.\\nThis is a multilabel dataset with label details as follows:\\n-HS : hate speech label;\\n-Abusive : abusive language label;\\n-HS_Individual : hate speech targeted to an individual;\\n-HS_Group : hate speech targeted to a group;\\n-HS_Religion : hate speech related to religion/creed;\\n-HS_Race : hate speech related to race/ethnicity;\\n-HS_Physical : hate speech related to physical/disability;\\n-HS_Gender : hate speech related to gender/sexual orientation;\\n-HS_Gender : hate related to other invective/slander;\\n-HS_Weak : weak hate speech;\\n-HS_Moderate : moderate hate speech;\\n-HS_Strong : strong hate speech.\\n', homepage='https://aclanthology.org/W19-3506/', license='Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/id_panl_bppt/id_panl_bppt.py', dataset_name='id_panl_bppt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='id_panl_bppt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='PANL BPPT Nusantara schema', schema='nusantara_t2t', subset_id='id_panl_bppt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{id_panl_bppt,\\n  author    = {PAN Localization - BPPT},\\n  title     = {Parallel Text Corpora, English Indonesian},\\n  year      = {2009},\\n  url       = {http://digilib.bppt.go.id/sampul/p92-budiono.pdf},\\n}\\n', description='Parallel Text Corpora for Multi-Domain Translation System created by BPPT (Indonesian Agency for the Assessment and\\nApplication of Technology) for PAN Localization Project (A Regional Initiative to Develop Local Language Computing\\nCapacity in Asia). The dataset contains about 24K sentences in English and Bahasa Indonesia from 4 different topics\\n(Economy, International Affairs, Science & Technology, and Sports).\\n', homepage='http://digilib.bppt.go.id/sampul/p92-budiono.pdf', license='')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/idn_tagged_corpus_csui/idn_tagged_corpus_csui.py', dataset_name='idn_tagged_corpus_csui', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='idn_tagged_corpus_csui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Idn-tagged-corpus-CSUI Nusantara schema', schema='nusantara_seq_label', subset_id='idn_tagged_corpus_csui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{dinakaramani2014designing,\\n  title={Designing an Indonesian part of speech tagset and manually tagged Indonesian corpus},\\n  author={Dinakaramani, Arawinda and Rashel, Fam and Luthfi, Andry and Manurung, Ruli},\\n  booktitle={2014 International Conference on Asian Language Processing (IALP)},\\n  pages={66--69},\\n  year={2014},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{kurniawan2018towards,\\n  author={Kurniawan, Kemal and Aji, Alham Fikri},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Toward a Standardized and More Accurate Indonesian Part-of-Speech Tagging}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={303-307},\\n  doi={10.1109/IALP.2018.8629236}}\\n', description='Idn-tagged-corpus-CSUI is a POS tagging dataset contains about 10,000 sentences, collected from the PAN Localization Project tagged with 23 POS tag classes.\\nThe POS tagset is created through a detailed study and analysis of existing tagsets and the manual tagging of an Indonesian corpus.\\nIdn-tagged-corpus-CSUI dataset is splitted into 3 sets with 8000 train, 1000 validation, 1029 test data.\\n', homepage='https://bahasa.cs.ui.ac.id/postag/corpus', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_general_mt_en_id/indo_general_mt_en_id.py', dataset_name='indo_general_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind'], config=NusantaraConfig(name='indo_general_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Indonesian General Domain MT Nusantara schema', schema='nusantara_t2t', subset_id='indo_general_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='\"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language,\\nand therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic.\\nIn this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and\\nconversation,to train and benchmark some variants of transformer-based NMT models across the domains.\\nWe show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models,\\nand perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\"\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indo_religious_mt_en_id/indo_religious_mt_en_id.py', dataset_name='indo_religious_mt_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='indo_religious_mt_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='Bible En-Id Nusantara schema', schema='nusantara_t2t', subset_id='indo_religious_mt_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    abstract = \"In the context of Machine Translation (MT) from-and-to English, Bahasa Indonesia has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the Web, which we split into several domains: news, religion, general, and conversation, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them , outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with Google Translate. Our datasets (with the standard split for training, validation, and testing), code, and models are available on https://github.com/gunnxx/indonesian-mt-data.\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='Indonesian Religious Domain MT En-Id consists of religious manuscripts or articles. These articles are different from news as they are not in a formal, informative style. Instead, they are written to advocate and inspire religious values, often times citing biblical or quranic anecdotes. An interesting property in the religion domain corpus is the localized names, for example, David to Daud, Mary to Maryam, Gabriel to Jibril, and more. In contrast, entity names are usually kept unchanged in other domains. We also find quite a handful of Indonesian translations of JW300 are missing the end sentence dot (.), even though the end sentence dot is present in their English counterpart. Some inconsistencies in the transliteration are also found, for example praying is sometimes written as \"salat\" or \"shalat\", or repentance as \"tobat\" or \"taubat\".\\n', homepage='https://github.com/gunnxx/indonesian-mt-data/tree/master/religious', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indocoref/indocoref.py', dataset_name='indocoref', tasks={<Tasks.COREFERENCE_RESOLUTION: 'COREF'>}, languages=['ind'], config=NusantaraConfig(name='indocoref_nusantara_kb', version=1.0.0, data_dir=None, data_files=None, description='Indocoref Nusantara schema', schema='nusantara_kb', subset_id='indocoref'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='KB', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{artari-etal-2021-multi,\\n  title        = {A Multi-Pass Sieve Coreference Resolution for {I}ndonesian},\\n  author       = {Artari, Valentina Kania Prameswara  and Mahendra, Rahmad  and Jiwanggi, Meganingrum Arista  and Anggraito, Adityo  and Budi, Indra},\\n  year         = 2021,\\n  month        = sep,\\n  booktitle    = {Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)},\\n  publisher    = {INCOMA Ltd.},\\n  address      = {Held Online},\\n  pages        = {79--85},\\n  url          = {https://aclanthology.org/2021.ranlp-1.10},\\n  abstract     = {Coreference resolution is an NLP task to find out whether the set of referring expressions belong to the same concept in discourse. A multi-pass sieve is a deterministic coreference model that implements several layers of sieves, where each sieve takes a pair of correlated mentions from a collection of non-coherent mentions. The multi-pass sieve is based on the principle of high precision, followed by increased recall in each sieve. In this work, we examine the portability of the multi-pass sieve coreference resolution model to the Indonesian language. We conduct the experiment on 201 Wikipedia documents and the multi-pass sieve system yields 72.74{\\\\%} of MUC F-measure and 52.18{\\\\%} of BCUBED F-measure.}\\n}\\n', description='Dataset contains articles from Wikipedia Bahasa Indonesia which fulfill these conditions:\\n- The pages contain many noun phrases, which the authors subjectively pick: (i) fictional plots, e.g., subtitles for films,\\n  TV show episodes, and novel stories; (ii) biographies (incl. fictional characters); and (iii) historical events or important events.\\n- The pages contain significant variation of pronoun and named-entity. We count the number of first, second, third person pronouns,\\n  and clitic pronouns in the document by applying string matching.We examine the number\\nof named-entity using the Stanford CoreNLP\\nNER Tagger (Manning et al., 2014) with a\\nmodel trained from the Indonesian corpus\\ntaken from Alfina et al. (2016).\\nThe Wikipedia texts have length of 500 to\\n2000 words.\\nWe sample 201 of pages from subset of filtered\\nWikipedia pages. We hire five annotators who are\\nundergraduate student in Linguistics department.\\nThey are native in Indonesian. Annotation is carried out using the Script d’Annotation des Chanes\\nde Rfrence (SACR), a web-based Coreference resolution annotation tool developed by Oberle (2018).\\nFrom the 201 texts, there are 16,460 mentions\\ntagged by the annotators\\n', homepage='https://github.com/valentinakania/indocoref/', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks={<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ntp_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP Nusantara schema', schema='nusantara_pairs', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment Nusantara schema', schema='nusantara_text', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks={<Tasks.SENTENCE_ORDERING: 'SO'>}, languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indonli/indonli.py', dataset_name='indonli', tasks={<Tasks.TEXTUAL_ENTAILMENT: 'TE'>}, languages=['ind'], config=NusantaraConfig(name='indonli_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='indonli Nusantara schema', schema='nusantara_pairs', subset_id='indonli'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{mahendra-etal-2021-indonli,\\n    title = \"{I}ndo{NLI}: A Natural Language Inference Dataset for {I}ndonesian\",\\n    author = \"Mahendra, Rahmad and Aji, Alham Fikri and Louvan, Samuel and Rahman, Fahrurrozi and Vania, Clara\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.821\",\\n    pages = \"10511--10527\",\\n}\\n', description='This dataset is designed for Natural Language Inference NLP task.  It is designed to provide a challenging test-bed\\nfor Indonesian NLI by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural\\nchanges, idioms, or temporal and spatial reasoning.\\n', homepage='https://github.com/ir-nlp-csui/indonli', license='CC-BY-SA 4.0. Attribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.No additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.Please contact authors for any information on the dataset.')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold0_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold1_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold2_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold3_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indosum/indosum.py', dataset_name='indosum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind'], config=NusantaraConfig(name='indosum_fold4_nusantara_t2t', version='1.0.0', data_dir=None, data_files=None, description='indosum Nusantara schema', schema='nusantara_t2t', subset_id='indosum_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8629109,\\n  author={Kurniawan, Kemal and Louvan, Samuel},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)}, \\n  title={Indosum: A New Benchmark Dataset for Indonesian Text Summarization}, \\n  year={2018},\\n  volume={},\\n  number={},\\n  pages={215-220},\\n  doi={10.1109/IALP.2018.8629109}}\\n', description='INDOSUM is a new benchmark dataset for Indonesian text summarization. \\nThe dataset consists of news articles and manually constructed summaries.\\n', homepage='https://github.com/kata-ai/indosum', license='Apache License, Version 2.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/minangnlp_mt/minangnlp_mt.py', dataset_name='minangnlp_mt', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['min', 'ind'], config=NusantaraConfig(name='minangnlp_mt_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='MinangNLP Machine Translation Nusantara schema', schema='nusantara_t2t', subset_id='minangnlp_mt'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-koto-2020-towards,\\n    title = \"Towards Computational Linguistics in {M}inangkabau Language: Studies on Sentiment Analysis and Machine Translation\",\\n    author = \"Koto, Fajri  and\\n      Koto, Ikhwan\",\\n    booktitle = \"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation\",\\n    month = oct,\\n    year = \"2020\",\\n    address = \"Hanoi, Vietnam\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.paclic-1.17\",\\n    pages = \"138--148\",\\n}\\n', description=\"In this work, we create Minangkabau–Indonesian (MIN-ID) parallel corpus by using Wikipedia. We obtain 224,180 Minangkabau and\\n510,258 Indonesian articles, and align documents through title matching, resulting in 111,430 MINID document pairs.\\nAfter that, we do sentence segmentation based on simple punctuation heuristics and obtain 4,323,315 Minangkabau sentences. We\\nthen use the bilingual dictionary to translate Minangkabau article (MIN) into Indonesian language (ID'). Sentence alignment is conducted using\\nROUGE-1 (F1) score (unigram overlap) (Lin, 2004) between ID’ and ID, and we pair each MIN sentencewith an ID sentence based on the highest ROUGE1.\\nWe then discard sentence pairs with a score of less than 0.5 to result in 345,146 MIN-ID parallel sentences.\\nWe observe that the sentence pattern in the collection is highly repetitive (e.g. 100k sentences are about biological term definition). Therefore,\\nwe conduct final filtering based on top-1000 trigram by iteratively discarding sentences until the frequency of each trigram equals to 100. Finally, we\\nobtain 16,371 MIN-ID parallel sentences and conducted manual evaluation by asking two native Minangkabau speakers to assess the adequacy and\\nfluency (Koehn and Monz, 2006). The human judgement is based on scale 1–5 (1 means poor quality and 5 otherwise) and conducted against 100 random\\nsamples. We average the weights of two annotators before computing the overall score, and we achieve 4.98 and 4.87 for adequacy and fluency respectively.\\nThis indicates that the resulting corpus is high-quality for machine translation training.\\n\", homepage='https://github.com/fajri91/minangNLP', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nerp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERP Nusantara schema', schema='nusantara_seq_label', subset_id='nerp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/news_en_id/news_en_id.py', dataset_name='news_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='news_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='News En-Id Nusantara schema', schema='nusantara_t2t', subset_id='news_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{guntara-etal-2020-benchmarking,\\n    title = \"Benchmarking Multidomain {E}nglish-{I}ndonesian Machine Translation\",\\n    author = \"Guntara, Tri Wahyu  and\\n      Aji, Alham Fikri  and\\n      Prasojo, Radityo Eko\",\\n    booktitle = \"Proceedings of the 13th Workshop on Building and Using Comparable Corpora\",\\n    month = may,\\n    year = \"2020\",\\n    address = \"Marseille, France\",\\n    publisher = \"European Language Resources Association\",\\n    url = \"https://aclanthology.org/2020.bucc-1.6\",\\n    pages = \"35--43\",\\n    language = \"English\",\\n    ISBN = \"979-10-95546-42-9\",\\n}\\n', description='News En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the news. The news dataset is collected from multiple sources: Pan Asia Networking Localization (PANL), Bilingual BBC news articles, Berita Jakarta, and GlobalVoices. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/gunnxx/indonesian-mt-data', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ace_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ace language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ban_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ban language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bjn_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bjn language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bug_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bug language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_eng_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for eng language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_ind_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for ind language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_jav_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for jav language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_mad_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for mad language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_min_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for min language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nij_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for nij language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_sun_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for sun language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_bbc_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for bbc language', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nusax_senti/nusax_senti.py', dataset_name='nusax_senti', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind', 'ace', 'ban', 'bjn', 'bbc', 'bug', 'jav', 'mad', 'min', 'nij', 'sun', 'eng'], config=NusantaraConfig(name='nusax_senti_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='nusax_senti with nusantara_text schema for all 12 languages', schema='nusantara_text', subset_id='nusax_senti'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@misc{winata2022nusax,\\n      title={NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages},\\n      author={Winata, Genta Indra and Aji, Alham Fikri and Cahyawijaya,\\n      Samuel and Mahendra, Rahmad and Koto, Fajri and Romadhony,\\n      Ade and Kurniawan, Kemal and Moeljadi, David and Prasojo,\\n      Radityo Eko and Fung, Pascale and Baldwin, Timothy and Lau,\\n      Jey Han and Sennrich, Rico and Ruder, Sebastian},\\n      year={2022},\\n      eprint={2205.15960},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n', description='NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak.\\n\\nNusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English.\\n', homepage='https://github.com/IndoNLP/nusax/tree/main/datasets/sentiment', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/posp/posp.py', dataset_name='posp', tasks={<Tasks.POS_TAGGING: 'POS'>}, languages=['ind'], config=NusantaraConfig(name='posp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='POSP Nusantara schema', schema='nusantara_seq_label', subset_id='posp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian Named Entity Tagger},\\n  author={Devin Hoesen and Ayu Purwarianti},\\n  booktitle={Proceedings of the 2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  year={2020}\\n}\\n', description='POSP is a POS Tagging dataset containing 8400 sentences, collected from Indonesian news website with 26 POS tag classes.\\nThe POS tag labels follow the Indonesian Association of Computational Linguistics (INACL) POS Tagging Convention.\\nPOSP dataset is splitted into 3 sets with 6720 train, 840 validation, and 840 test data.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='singgalang_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='singgalang Nusantara schema', schema='nusantara_seq_label', subset_id='singgalang'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/smsa/smsa.py', dataset_name='smsa', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='smsa_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='SMSA Nusantara schema', schema='nusantara_text', subset_id='smsa'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8904199,\\n    author={Purwarianti, Ayu and Crisdayanti, Ida Ayu Putu Ari},\\n    booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n    title={Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector},\\n    year={2019},\\n    pages={1-5},\\n    doi={10.1109/ICAICTA.2019.8904199}\\n}\\n\\n@inproceedings{wilie2020indonlu,\\n  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\\n  author={Wilie, Bryan and Vincentio, Karissa and Winata, Genta Indra and Cahyawijaya, Samuel and Li, Xiaohong and Lim, Zhi Yuan and Soleman, Sidik and Mahendra, Rahmad and Fung, Pascale and Bahar, Syafri and others},\\n  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\\n  pages={843--857},\\n  year={2020}\\n}\\n', description='SmSA is a sentence-level sentiment analysis dataset (Purwarianti and Crisdayanti, 2019) is a collection of comments and reviews\\nin Indonesian obtained from multiple online platforms. The text was crawled and then annotated by several Indonesian linguists\\nto construct this dataset. There are three possible sentiments on the SmSA dataset: positive, negative, and neutral\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/stif_indonesia/stif_indonesia.py', dataset_name='stif_indonesia', tasks={<Tasks.PARAPHRASING: 'PARA'>}, languages=['ind'], config=NusantaraConfig(name='stif_indonesia_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='STIF Indonesia Nusantara schema', schema='nusantara_t2t', subset_id='stif_indonesia'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{wibowo2020semi,\\n  title={Semi-supervised low-resource style transfer of indonesian informal to formal language with iterative forward-translation},\\n  author={Wibowo, Haryo Akbarianto and Prawiro, Tatag Aziz and Ihsan, Muhammad and Aji, Alham Fikri and Prasojo, Radityo Eko and Mahendra, Rahmad and Fitriany, Suci},\\n  booktitle={2020 International Conference on Asian Language Processing (IALP)},\\n  pages={310--315},\\n  year={2020},\\n  organization={IEEE}\\n}\\n', description='STIF-Indonesia is formal-informal (bahasa baku - bahasa alay/slang) style transfer for Indonesian. Texts were collected from Twitter. Then, native speakers were aksed to transform the text into formal style.\\n', homepage='https://github.com/haryoa/stif-indonesia', license='MIT')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/ted_en_id/ted_en_id.py', dataset_name='ted_en_id', tasks={<Tasks.MACHINE_TRANSLATION: 'MT'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='ted_en_id_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='TED En-Id Nusantara schema', schema='nusantara_t2t', subset_id='ted_en_id'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{qi2018and,\\n  title={When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?},\\n  author={Qi, Ye and Sachan, Devendra and Felix, Matthieu and Padmanabhan, Sarguna and Neubig, Graham},\\n  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},\\n  pages={529--535},\\n  year={2018}\\n}\\n\\n@inproceedings{cahyawijaya-etal-2021-indonlg,\\n    title = \"{I}ndo{NLG}: Benchmark and Resources for Evaluating {I}ndonesian Natural Language Generation\",\\n    author = \"Cahyawijaya, Samuel  and\\n      Winata, Genta Indra  and\\n      Wilie, Bryan  and\\n      Vincentio, Karissa  and\\n      Li, Xiaohong  and\\n      Kuncoro, Adhiguna  and\\n      Ruder, Sebastian  and\\n      Lim, Zhi Yuan  and\\n      Bahar, Syafri  and\\n      Khodra, Masayu  and\\n      Purwarianti, Ayu  and\\n      Fung, Pascale\",\\n    booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2021\",\\n    address = \"Online and Punta Cana, Dominican Republic\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2021.emnlp-main.699\",\\n    doi = \"10.18653/v1/2021.emnlp-main.699\",\\n    pages = \"8875--8898\",\\n    abstract = \"Natural language generation (NLG) benchmarks provide an important avenue to measure progress and develop better NLG systems. Unfortunately, the lack of publicly available NLG benchmarks for low-resource languages poses a challenging barrier for building NLG systems that work well for languages with limited amounts of data. Here we introduce IndoNLG, the first benchmark to measure natural language generation (NLG) progress in three low-resource{---}yet widely spoken{---}languages of Indonesia: Indonesian, Javanese, and Sundanese. Altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of NLG systems today. Concretely, IndoNLG covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (MT) tasks. We collate a clean pretraining corpus of Indonesian, Sundanese, and Javanese datasets, Indo4B-Plus, which is used to pretrain our models: IndoBART and IndoGPT. We show that IndoBART and IndoGPT achieve competitive performance on all tasks{---}despite using only one-fifth the parameters of a larger multilingual model, mBART-large (Liu et al., 2020). This finding emphasizes the importance of pretraining on closely related, localized languages to achieve more efficient learning and faster inference at very low-resource languages like Javanese and Sundanese.\",\\n}\\n', description='TED En-Id is a machine translation dataset containing Indonesian-English parallel sentences collected from the TED talk transcripts. We split the dataset and use 75% as the training set, 10% as the validation set, and 15% as the test set. Each of the datasets is evaluated in both directions, i.e., English to Indonesian (En → Id) and Indonesian to English (Id → En) translations.\\n', homepage='https://github.com/IndoNLP/indonlg', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/term_a/term_a.py', dataset_name='term_a', tasks={<Tasks.KEYWORD_TAGGING: 'KT'>}, languages=['ind'], config=NusantaraConfig(name='term_a_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='TermA Nusantara schema', schema='nusantara_seq_label', subset_id='term_a'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{winatmoko2019aspect,\\n  title={Aspect and opinion term extraction for hotel reviews using transfer learning and auxiliary labels},\\n  author={Winatmoko, Yosef Ardhito and Septiandri, Ali Akbar and Sutiono, Arie Pratama},\\n  journal={arXiv preprint arXiv:1909.11879},\\n  year={2019}\\n}\\n@inproceedings{fernando2019aspect,\\n  title={Aspect and opinion terms extraction using double embeddings and attention mechanism for indonesian hotel reviews},\\n  author={Fernando, Jordhy and Khodra, Masayu Leylia and Septiandri, Ali Akbar},\\n  booktitle={2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)},\\n  pages={1--6},\\n  year={2019},\\n  organization={IEEE}\\n}\\n', description='TermA is a span-extraction dataset collected from the hotel aggregator platform, AiryRooms\\n(Septiandri and Sutiono, 2019; Fernando et al.,\\n2019) consisting of thousands of hotel reviews,each containing a span label for aspect\\nand sentiment words representing the opinion of the reviewer on the corresponding aspect.\\nThe labels use Inside-Outside-Beginning tagging (IOB) with two kinds of tags, aspect and\\nsentiment.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/titml_idn/titml_idn.py', dataset_name='titml_idn', tasks={<Tasks.SPEECH_RECOGNITION: 'ASR'>}, languages=['ind'], config=NusantaraConfig(name='titml_idn_nusantara_asr', version=1.0.0, data_dir=None, data_files=None, description='TITML-IDN Nusantara schema', schema='nusantara_asr', subset_id='titml_idn'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='ASR', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{lestari2006titmlidn,\\n  title={A large vocabulary continuous speech recognition system for Indonesian language},\\n  author={Lestari, Dessi Puji and Iwano, Koji and Furui, Sadaoki},\\n  booktitle={15th Indonesian Scientific Conference in Japan Proceedings},\\n  pages={17--22},\\n  year={2006}\\n}\\n', description='TITML-IDN (Tokyo Institute of Technology Multilingual - Indonesian) is collected to build a pioneering Indonesian Large Vocabulary Continuous Speech Recognition (LVCSR) System. In order to build an LVCSR system, high accurate acoustic models and large-scale language models are essential. Since Indonesian speech corpus was not available yet, we tried to collect speech data from 20 Indonesian native speakers (11 males and 9 females) to construct a speech corpus for training the acoustic model based on Hidden Markov Models (HMMs). A text corpus which was collected by ILPS, Informatics Institute, University of Amsterdam, was used to build a 40K-vocabulary dictionary and a n-gram language model.\\n', homepage='http://research.nii.ac.jp/src/en/TITML-IDN.html', license='For research purposes only. If you use this corpus, you have to cite (Lestari et al, 2006).')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for eng language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ind language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for jav language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for min language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for sun language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ace language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for mly language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for map_bms language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/xl_sum/xl_sum.py', dataset_name='xl_sum', tasks={<Tasks.SUMMARIZATION: 'SUM'>}, languages=['ind', 'eng'], config=NusantaraConfig(name='xl_sum_nusantara_t2t', version=1.0.0, data_dir=None, data_files=None, description='xl_sum Nusantara schema', schema='nusantara_t2t', subset_id='xl_sum'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='T2T', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='2.0.0', citation='@inproceedings{hasan2021xl,\\n  title={XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages},\\n  author={Hasan, Tahmid and Bhattacharjee, Abhik and Islam, Md Saiful and Mubasshir, Kazi and Li, Yuan-Fang and Kang, Yong-Bin and Rahman, M Sohel and Shahriyar, Rifat},\\n  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},\\n  pages={4693--4703},\\n  year={2021}\\n}\\n', description='XL-Sum is a large-scale multilingual summarization dataset that covers 45 languages including Indonesian text summarization.\\nThe dataset is based on article-summary pairs from BBC, is highly abstractive, concise, and of high quality, as indicated by human and intrinsic evaluation.\\n', homepage='https://github.com/csebuetnlp/xl-sum', license='CC-BY-NC-SA 4.0')\n",
      "Nusantara NER public datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/nerp/nerp.py', dataset_name='nerp', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='nerp_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='NERP Nusantara schema', schema='nusantara_seq_label', subset_id='nerp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{hoesen2018investigating,\\n  title={Investigating bi-lstm and crf with pos tag embedding for indonesian named entity tagger},\\n  author={Hoesen, Devin and Purwarianti, Ayu},\\n  booktitle={2018 International Conference on Asian Language Processing (IALP)},\\n  pages={35--38},\\n  year={2018},\\n  organization={IEEE}\\n}\\n', description='The NERP dataset (Hoesen and Purwarianti, 2018) contains texts collected from several Indonesian news websites with five labels\\n- PER (name of person)\\n- LOC (name of location)\\n- IND (name of product or brand)\\n- EVT (name of the event)\\n- FNB (name of food and beverage).\\nNERP makes use of the IOB chunking format, just like the TermA dataset.\\n', homepage='https://github.com/IndoNLP/indonlu', license='Creative Common Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/singgalang/singgalang.py', dataset_name='singgalang', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='singgalang_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='singgalang Nusantara schema', schema='nusantara_seq_label', subset_id='singgalang'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8355036,\\n  author={Alfina, Ika and Savitri, Septiviana and Fanany, Mohamad Ivan},\\n  title={Modified DBpedia entities expansion for tagging automatically NER dataset},\\n  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  pages={216-221},\\n  year={2017},\\n  url={https://ieeexplore.ieee.org/document/8355036},\\n  doi={10.1109/ICACSIS.2017.8355036}}\\n\\n@INPROCEEDINGS{7872784,\\n  author={Alfina, Ika and Manurung, Ruli and Fanany, Mohamad Ivan},\\n  booktitle={2016 International Conference on Advanced Computer Science and Information Systems (ICACSIS)},\\n  title={DBpedia entities expansion in automatically building dataset for Indonesian NER},\\n  year={2016},\\n  pages={335-340},\\n  doi={10.1109/ICACSIS.2016.7872784}}\\n', description='Rule-based annotation Indonesian NER Dataset of 48,957 sentences or 1,478,286 tokens.\\nAnnotation conforms the Stanford-NER format (https://stanfordnlp.github.io/CoreNLP/ner.html) for 3 NER tags of Person, Organisation, and Place.\\nThis dataset consists of 41,297, 14,770, and 82,179 tokens of entity (respectively) from over 14, 6, and 5 rules.\\n', homepage='https://github.com/ir-nlp-csui/singgalang', license=\"You can use this dataset for free. You don't need our permission to use it. Please cite our paper if your work uses our data in your publication.\\nPlease note that you are not allowed to create a copy of this dataset and share it publicly in your own repository without our permission.\")\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_eng_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for eng language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ind_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ind language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_jav_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for jav language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_min_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for min language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_sun_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for sun language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_ace_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for ace language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_mly_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for mly language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/wikiann/wikiann.py', dataset_name='wikiann', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind', 'eng', 'jav', 'min', 'sun', 'ace', 'mly', 'map-bms'], config=NusantaraConfig(name='wikiann_map_bms_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='wikiann with nusantara_seq_label schema for map_bms language', schema='nusantara_seq_label', subset_id='wikiann'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.1.0', citation='@inproceedings{pan-etal-2017-cross,\\n    title = \"Cross-lingual Name Tagging and Linking for 282 Languages\",\\n    author = \"Pan, Xiaoman  and\\n      Zhang, Boliang  and\\n      May, Jonathan  and\\n      Nothman, Joel  and\\n      Knight, Kevin  and\\n      Ji, Heng\",\\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\\n    month = jul,\\n    year = \"2017\",\\n    address = \"Vancouver, Canada\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P17-1178\",\\n    doi = \"10.18653/v1/P17-1178\",\\n    pages = \"1946--1958\",\\n    abstract = \"The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework\\n    for 282 languages that exist in Wikipedia. Given a document in any of these languages, our framework is able\\n    to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to\\n    an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of\\n    new KB mining methods: generating {``}silver-standard{\\'\\'} annotations by\\n    transferring annotations from English to other languages through cross-lingual links and KB properties,\\n    refining annotations through self-training and topic selection,\\n    deriving language-specific morphology features from anchor links, and mining word translation pairs from\\n    cross-lingual links. Both name tagging and linking results for 282 languages are promising\\n    on Wikipedia data and on-Wikipedia data.\",\\n}\\n@inproceedings{rahimi-etal-2019-massively,\\n    title = \"Massively Multilingual Transfer for {NER}\",\\n    author = \"Rahimi, Afshin  and\\n      Li, Yuan  and\\n      Cohn, Trevor\",\\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2019\",\\n    address = \"Florence, Italy\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/P19-1015\",\\n    pages = \"151--164\",\\n}\\n', description='The wikiann dataset contains NER tags with labels from O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4), B-LOC (5), I-LOC (6). The Indonesian subset is used.\\nWikiANN (sometimes called PAN-X) is a multilingual named entity recognition dataset consisting of Wikipedia articles\\n annotated with LOC (location), PER (person), and ORG (organisation)\\n tags in the IOB2 format. This version corresponds to the balanced train, dev, and test splits of\\n  Rahimi et al. (2019), and uses the following subsets from the original WikiANN corpus\\n\\nLanguage\\tWikiAnn\\tISO 639-3\\nIndonesian\\tid\\tind\\nJavanese\\tjv\\tjav\\nMinangkabau\\tmin\\tmin\\nSundanese\\tsu\\tsun\\nAcehnese\\tace\\tace\\nMalay\\tms\\tmly\\nBanyumasan\\tmap-bms\\tmap-bms\\n\\n\\n', homepage='https://github.com/afshinrahimi/mmner', license='Apache-2.0 license')\n",
      "IndoLEM datasets\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold0_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold1_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold2_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold3_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ner_ugm/indolem_ner_ugm.py', dataset_name='indolem_ner_ugm', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ner_ugm_fold4_nusantara_seq_label', version='1.0.0', data_dir=None, data_files=None, description='indolem_ner_ugm Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_ner_ugm_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@inproceedings{koto-etal-2020-indolem,\\n    title = \"{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}\",\\n    author = \"Koto, Fajri  and\\n      Rahimi, Afshin  and\\n      Lau, Jey Han  and\\n      Baldwin, Timothy\",\\n    booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\\n    month = dec,\\n    year = \"2020\",\\n    address = \"Barcelona, Spain (Online)\",\\n    publisher = \"International Committee on Computational Linguistics\",\\n    url = \"https://aclanthology.org/2020.coling-main.66\",\\n    doi = \"10.18653/v1/2020.coling-main.66\",\\n    pages = \"757--770\"\\n}\\n@phdthesis{fachri2014pengenalan,\\n  title     = {Pengenalan Entitas Bernama Pada Teks Bahasa Indonesia Menggunakan Hidden Markov Model},\\n  author    = {FACHRI, MUHAMMAD},\\n  year      = {2014},\\n  school    = {Universitas Gadjah Mada}\\n}\\n', description='NER UGM is a Named Entity Recognition dataset that comprises 2,343 sentences from news articles, and was constructed at the University of Gajah Mada based on five named entity classes: person, organization, location, time, and quantity.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold0_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold0'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold1_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold1'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold2_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold2'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold3_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold3'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_nerui/indolem_nerui.py', dataset_name='indolem_nerui', tasks={<Tasks.NAMED_ENTITY_RECOGNITION: 'NER'>}, languages=['ind'], config=NusantaraConfig(name='indolem_nerui_fold4_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='Indolem NER UI Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_nerui_fold4'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@INPROCEEDINGS{8275098,\\n  author={Gultom, Yohanes and Wibowo, Wahyu Catur},\\n  booktitle={2017 International Workshop on Big Data and Information Security (IWBIS)},\\n  title={Automatic open domain information extraction from Indonesian text},\\n  year={2017},\\n  volume={},\\n  number={},\\n  pages={23-30},\\n  doi={10.1109/IWBIS.2017.8275098}}\\n\\n@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NER UI is a Named Entity Recognition dataset that contains 2,125 sentences obtained via an annotation assignment in an NLP course at the University of Indonesia in 2016.\\nThe corpus has three named entity classes: location, organisation, and person with training/dev/test distribution: 1,530/170/42 and based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_ntp/indolem_ntp.py', dataset_name='indolem_ntp', tasks={<Tasks.NEXT_SENTENCE_PREDICTION: 'NSP'>}, languages=['ind'], config=NusantaraConfig(name='indolem_ntp_nusantara_pairs', version=1.0.0, data_dir=None, data_files=None, description='Indolem NTP Nusantara schema', schema='nusantara_pairs', subset_id='indolem_ntp'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='PAIRS', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='NTP (Next Tweet prediction) is one of the comprehensive Indonesian benchmarks that given a list of tweets and an option, we predict if the option is the next tweet or not.\\nThis task is similar to the next sentence prediction (NSP) task used to train BERT (Devlin et al., 2019).\\nIn NTP, each instance consists of a Twitter thread (containing 2 to 4 tweets) that we call the premise, and four possible options for the next tweet, one of which is the actual response from the original thread.\\n\\nTrain: 5681 threads\\nDevelopment: 811 threads\\nTest: 1890 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_sentiment/indolem_sentiment.py', dataset_name='indolem_sentiment', tasks={<Tasks.SENTIMENT_ANALYSIS: 'SA'>}, languages=['ind'], config=NusantaraConfig(name='indolem_sentiment_nusantara_text', version=1.0.0, data_dir=None, data_files=None, description='indolem_sentiment Nusantara schema', schema='nusantara_text', subset_id='indolem_sentiment'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='TEXT', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\n\\nThis dataset is based on binary classification (positive and negative), with distribution:\\n* Train: 3638 sentences\\n* Development: 399 sentences\\n* Test: 1011 sentences\\n\\nThe data is sourced from 1) Twitter [(Koto and Rahmaningtyas, 2017)](https://www.researchgate.net/publication/321757985_InSet_Lexicon_Evaluation_of_a_Word_List_for_Indonesian_Sentiment_Analysis_in_Microblogs)\\nand 2) [hotel reviews](https://github.com/annisanurulazhar/absa-playground/).\\n\\nThe experiment is based on 5-fold cross validation.\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution Share-Alike 4.0 International')\n",
      "\n",
      "NusantaraMetadata(script='/home/samuel/nusantara-datasets/nusantara/nusa_datasets/indolem_tweet_ordering/indolem_tweet_ordering.py', dataset_name='indolem_tweet_ordering', tasks={<Tasks.SENTENCE_ORDERING: 'SO'>}, languages=['ind'], config=NusantaraConfig(name='indolem_tweet_ordering_nusantara_seq_label', version=1.0.0, data_dir=None, data_files=None, description='indolem_tweet_ordering Nusantara schema', schema='nusantara_seq_label', subset_id='indolem_tweet_ordering'), is_local=False, is_nusantara_schema=True, nusantara_schema_caps='SEQ_LABEL', is_large=False, is_resource=False, is_default=False, is_broken=False, nusantara_version='1.0.0', source_version='1.0.0', citation='@article{DBLP:journals/corr/abs-2011-00677,\\n  author    = {Fajri Koto and\\n               Afshin Rahimi and\\n               Jey Han Lau and\\n               Timothy Baldwin},\\n  title     = {IndoLEM and IndoBERT: {A} Benchmark Dataset and Pre-trained Language\\n               Model for Indonesian {NLP}},\\n  journal   = {CoRR},\\n  volume    = {abs/2011.00677},\\n  year      = {2020},\\n  url       = {https://arxiv.org/abs/2011.00677},\\n  eprinttype = {arXiv},\\n  eprint    = {2011.00677},\\n  timestamp = {Fri, 06 Nov 2020 15:32:47 +0100},\\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2011-00677.bib},\\n  bibsource = {dblp computer science bibliography, https://dblp.org}\\n}\\n', description='IndoLEM (Indonesian Language Evaluation Montage) is a comprehensive Indonesian benchmark that comprises of seven tasks for the Indonesian language. This benchmark is categorized into three pillars of NLP tasks: morpho-syntax, semantics, and discourse.\\nThis task is based on the sentence ordering task of Barzilay and Lapata (2008) to assess text relatedness. We construct the data by shuffling Twitter threads (containing 3 to 5 tweets), and assessing the predicted ordering in terms of rank correlation (p) with the original. The experiment is based on 5-fold cross validation.\\n\\nTrain: 4327 threads\\nDevelopment: 760 threads\\nTest: 1521 threads\\n', homepage='https://indolem.github.io/', license='Creative Commons Attribution 4.0')\n"
     ]
    }
   ],
   "source": [
    "conhelps = NusantaraConfigHelper()\n",
    "print('All Configs')\n",
    "print(conhelps)\n",
    "\n",
    "# filter and load datasets\n",
    "# ====================================================================\n",
    "print('Retrieve SMSA')\n",
    "print([helper for helper in conhelps.filtered(lambda x: (\"smsa\" in x.dataset_name and x.is_nusantara_schema))])\n",
    "smsa_datasets = [\n",
    "    helper.load_dataset()\n",
    "    for helper in conhelps.filtered(\n",
    "        lambda x: (\"smsa\" in x.dataset_name and x.is_nusantara_schema)\n",
    "    )\n",
    "]\n",
    "print(smsa_datasets)\n",
    "\n",
    "# examples of other filters\n",
    "# ====================================================================\n",
    "\n",
    "# get all source schema config helpers\n",
    "print('Source datasets')\n",
    "source_helpers = conhelps.filtered(lambda x: x.config.schema == \"source\")\n",
    "print(source_helpers)\n",
    "\n",
    "# get all nusantara config helpers\n",
    "print('Nusantara datasets')\n",
    "nusantara_helpers = conhelps.filtered(lambda x: x.is_nusantara_schema)\n",
    "print(nusantara_helpers)\n",
    "\n",
    "# nusantara NER public tasks\n",
    "print('Nusantara NER public datasets')\n",
    "nc_ner_public_helpers = conhelps.filtered(\n",
    "    lambda x: (\n",
    "        x.is_nusantara_schema\n",
    "        and Tasks.NAMED_ENTITY_RECOGNITION in x.tasks\n",
    "        and not x.is_local\n",
    "    )\n",
    ")\n",
    "print(nc_ner_public_helpers)\n",
    "\n",
    "# indolem datasets\n",
    "print('IndoLEM datasets')\n",
    "nc_indolem_helpers = conhelps.filtered(\n",
    "    lambda x: (\"indolem\" in x.dataset_name and x.is_nusantara_schema)\n",
    ")\n",
    "print(nc_indolem_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14640d3-6f18-49f9-a026-ca57982bb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('https://docs.google.com/spreadsheets/d/17o83IvWxmtGLYridZis0nEprHhsZIMeFtHGtXV35h6M/export?format=csv&gid=879729812', skiprows=1)\n",
    "meta_df = meta_df[meta_df['Implemented'] > 0].rename({\n",
    "    'No.': 'id', 'Name': 'name', 'Subsets': 'subsets', 'Link': 'source_link', 'Description': 'description',\n",
    "    'HF Link': 'hf_link', 'License': 'license', 'Year': 'year', 'Collection Style': 'collection_style',\n",
    "    'Language': 'language', 'Dialect': 'dialect', 'Domain': 'domain', 'Form': 'modality', 'Tasks': 'tasks',\n",
    "    'Volume': 'volume', 'Unit': 'unit', 'Ethical Risks': 'ethical_risk', 'Provider': 'provider',\n",
    "    'Paper Title': 'paper_title', 'Paper Link': 'paper_link', 'Access': 'access', 'Derived From': 'derived_from', \n",
    "    'Test Split': 'is_splitted', 'Notes': 'notes', 'Dataloader': 'dataloader', 'Implemented': 'implemented'\n",
    "}, axis=1)\n",
    "meta_df['is_splitted'] = meta_df['is_splitted'].apply(lambda x: True if x =='Yes' else False)\n",
    "# [\n",
    "#  'No.', 'Name', 'Subsets', 'Link', 'HF Link', 'License', 'Year',\n",
    "#  'Language', 'Dialect', 'Domain', 'Form', 'Collection Style',\n",
    "#  'Description', 'Volume', 'Unit', 'Ethical Risks', 'Provider',\n",
    "#  'Paper Title', 'Paper Link', 'Access', 'Derived From', 'Tasks',\n",
    "#  'Test Split', 'Notes', 'Dataloader', 'Implemented'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f23f4fb-2a0a-404f-95ed-08b1e4d4094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MetaDict:\n",
    "    data: dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce44a6d9-0b40-49f9-9b2d-5c91b69a0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_meta_map = {}\n",
    "for cfg_meta in conhelps:\n",
    "    # Assign metadata to meta dataframe\n",
    "    meta_df.loc[meta_df.dataloader == cfg_meta.dataset_name, [\n",
    "        'is_large', 'is_resource', 'is_default', 'is_broken',\n",
    "        'is_local', 'citation', 'license', 'homepage', 'tasks'\n",
    "    ]] = [\n",
    "        cfg_meta.is_large, cfg_meta.is_resource, cfg_meta.is_default, cfg_meta.is_broken, \n",
    "        cfg_meta.is_local, cfg_meta.citation, cfg_meta.license, cfg_meta.homepage, '|'.join([task.value for task in cfg_meta.tasks])\n",
    "    ]\n",
    "    \n",
    "    if cfg_meta.dataset_name not in name_to_meta_map:\n",
    "        name_to_meta_map[cfg_meta.dataset_name] = {}\n",
    "    if cfg_meta.config.schema not in name_to_meta_map[cfg_meta.dataset_name]:\n",
    "        name_to_meta_map[cfg_meta.dataset_name][cfg_meta.config.schema] = []\n",
    "    name_to_meta_map[cfg_meta.dataset_name][cfg_meta.config.schema].append(cfg_meta)\n",
    "\n",
    "for dset_name in name_to_meta_map.keys():\n",
    "    meta_df.loc[meta_df.dataloader == dset_name, 'metadata'] = MetaDict(data=name_to_meta_map[dset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04571177-ca67-4e86-a1a9-1ae0fc24d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indolem_sentiment_dataset (/home/samuel/.cache/huggingface/datasets/indolem_sentiment_dataset/indolem_sentiment_nusantara_text/1.0.0/b9050e6fcb7b7fa40f4dd502c92dc8c1df0ef30e067f1664af76c908c7b47467)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a582631421e4032bb6cd273c87ce592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset nusa_x_senti (/home/samuel/.cache/huggingface/datasets/nusa_x_senti/nusax_senti_ind_nusantara_text/1.0.0/3c834957d94e799c678f9be42ee6def4fcdbfdd0407b6add0d1bc875067b2ff9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613d8f2b34724203b2c96c85b774c3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset smsa (/home/samuel/.cache/huggingface/datasets/smsa/smsa_nusantara_text/1.0.0/424796f944d7120578eadd5678a5bd371cffc381056363bd88c6b7648399248f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393987b2190248cda2bcf77ed2952516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'indolem_sentiment_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 3638\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1011\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 399\n",
       "     })\n",
       " }),\n",
       " 'nusax_senti_ind_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 100\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 400\n",
       "     })\n",
       " }),\n",
       " 'smsa_nusantara_text': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 11000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 1260\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text', 'label'],\n",
       "         num_rows: 500\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all Indonesian sentiment analysis task\n",
    "lang = 'ind'\n",
    "task = Tasks.SENTIMENT_ANALYSIS\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & \n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fafbb2-0a92-44f8-abb2-c2c1bd95264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset indo_general_mt_en_id (/home/samuel/.cache/huggingface/datasets/indo_general_mt_en_id/indo_general_mt_en_id_nusantara_t2t/1.0.0/8997ff3f81a5107662a8a4d0e405a1e053a076327735146c76b56dd6c263e4c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dcd5b41f864140b9bbdf4a210e91ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'indo_general_mt_en_id_nusantara_t2t': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 1821716\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['id', 'text_1', 'text_2', 'text_1_name', 'text_2_name'],\n",
       "         num_rows: 2000\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter & load all splitted English sentiment analysis task\n",
    "lang = 'eng'\n",
    "task = Tasks.MACHINE_TRANSLATION\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & \n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "                \n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123a219f-007f-44c0-b490-376eb94c873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    POS\n",
       "Name: tasks, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " meta_df.loc[\n",
    "    (meta_df.name.str.contains('CSUI'))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a39d59c-4f2f-4349-a79b-bdcb3f780dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_meta in conhelps:\n",
    "    if len(cfg_meta.tasks) > 1:\n",
    "        print(cfg_meta.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef7b46-2598-40ac-9cbc-61ff2f64d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter & load all Indonesian sentiment analysis task\n",
    "lang = 'ind'\n",
    "task = Tasks.SENTIMENT_ANALYSIS\n",
    "\n",
    "filtered_df = meta_df.loc[\n",
    "    (meta_df.tasks.str.contains(task.value)) & \n",
    "    (meta_df.language.str.contains(lang)) & meta_df.is_splitted\n",
    "]\n",
    "\n",
    "schema = f'nusantara_{TASK_TO_SCHEMA[task].lower()}'\n",
    "datasets = {}\n",
    "for metas in filtered_df.metadata:\n",
    "    if schema in metas.data:\n",
    "        for meta in metas.data[schema]:\n",
    "            if len(meta.languages) > 1:\n",
    "                if lang in meta.config.name:\n",
    "                    datasets[meta.config.name] = meta.load_dataset()\n",
    "            else:\n",
    "                datasets[meta.config.name] = meta.load_dataset()\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9716d4-1f33-47a9-8564-435f2d74ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "If there is multiple tasks on a dataset, split it and filter schema out of it resulting in\n",
    "config meta from the original dataset meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_nusantara)",
   "language": "python",
   "name": "env_nusantara"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
